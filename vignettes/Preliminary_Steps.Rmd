---
title: "Recommended Preliminary Steps"
author: "Isabella Stallworthy"
date: "`r Sys.Date()`"
output:
    html_vignette:
        df_print: kable
        toc: false
vignette: >
  %\VignetteIndexEntry{Recommended Preliminary Steps}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown_notangle}
editor_options:
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = TRUE,
  eval = TRUE
)

options(rmarkdown.html_vignette.check_title = FALSE)
```

<br>

These five recommended preliminary steps are designed to assist the user in preparing and inspecting their data to ensure appropriate use of the package. Users should first view the <a href="https://istallworthy.github.io/devMSMs/articles/Terminology.html">Terminology</a> vignette and complete the <a href="https://istallworthy.github.io/devMSMs/articles/Data_Requirements.html">Data Requirements</a> and <a href="https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html">Specifying Core Inputs</a> vignettes.   
  
The code contained in this vignette is also available, integrated code from the other vignettes, in the <a href="https://github.com/istallworthy/devMSMs/blob/main/examplePipelineRevised.Rmd">examplePipeline.rmd file</a>.  

The helper functions (summarized in Table 1) for the following recommended preliminary steps can be found at this <a href="https://github.com/istallworthy/devMSMsHelpers">Github</a>. Of note, *devMSMs* must also be installed and loaded to use these helper functions (see <a href="https://istallworthy.github.io/devMSMs/">Installation</a>).   

<br>

Table 1. Summary of *devMSMs* helper functions.
```{r, echo = FALSE}
helper_functions = data.frame(
  Function = c(
    "`formatLongData()`",
    "`formatWideData()`",
    "`imputeData()`",
    "`inspectData()`"
  ),
  Purpose = c(
    "Format long data with the correct column names, variable classes, and missingness indicators.",
    "Format wide data with the correct column names, variable classes, and missingness indicators.",
    "Wrapper for `mice::mice` to multiply impute wide data.",
    "Summarizes data and the distribution of the sample across user-specified exposure histories."
  ),
  `Required Input` = c(
    "(long) `data`, `exposure`, `exposure_time_pts`, `outcome`",
    "(wide) `data`, `exposure`, `exposure_time_pts`, `outcome`",
    "(wide) `data`, `exposure`, `outcome`",
    "`data`, `exposure`, `exposure_time_pts`, `outcome`"
  ),
  Output = c(
    "A data frame of formatted long data.\n\nSummary statistics.",
    "A data frame of formatted wide data.\n\nSummary statistics.",
    "A `mids` object of imputed data", 
    "Weights object\n\nHistogram & summary of balancing weights."
  )
)

library(tinytable)
tt(helper_functions, theme = "striped") |>
  format(markdown = TRUE)
```
  

<br>

The user who has already formatted their data in wide format according to the Data Requirements vignette and imputed to accommodate any missing data (P3) can focus only on subsections P4 Identifying Optional Exposure Epochs and P5 Verifying History Distributions, prior to using the package. Following completion of this vignette, users should use one of the *Workflows* vignettes to implement *devMSMs* with their longitudinal data.  
<br>
  
We first install the *devMSMs* and *devMSMsHelpers* packages.  
```{r, eval = FALSE}
# install.packages("devtools")
require(devtools, quietly = TRUE)
devtools::install_github("istallworthy/devMSMs", quiet = TRUE)
devtools::install_github("istallworthy/devMSMsHelpers", quiet = TRUE)
```
```{r, echo = FALSE, message = FALSE, warning = FALSE}
if(!require("devtools")) install.packages("devtools", quiet = TRUE)
if(!require("devMSMs")) devtools::install_github("istallworthy/devMSMs", quiet = TRUE)
if(!require("devMSMsHelpers")) devtools::install_github("istallworthy/devMSMsHelpers", quiet = TRUE)
```
```{r setup}
library(devMSMs)
library(devMSMsHelpers)
```
<br>

We advise users implement the appropriate preliminary steps, with the goal of assigning to 'data' one of the following wide data formats (see Figure 1) for use in the package:  
  
* a single data frame of data in wide format with no missing data  

* a mids object (output from `mice::mice()`) of data imputed in wide format  

* a list of data imputed in wide format as data frames.  
<br>

As shown in Figure 1, for use of the *devMSMs* package, data in any of the above 3 formats, must be wide and contain an “ID” column for subject identifier and exposure, outcome, and all confounders as separate columns (as shown in Figure 1). Column names can include only underscore special characters and time-varying variables should have a suffix that consists of a period followed by the time point (e.g., “variable.6”). All variables should be classed as integer, numeric, or a factor (not character). Auxiliary or nuisance covariates that are not confounders (e.g, assessment version) can be included in the dataset for use and specification in the final modeling step (*Workflow* vignettes Step 5).   

<br>
<br>
  
![Figure 1. Abridged example structure of a wide dataset formatted as required for the devMSMs. Column A denotes the ID variable, column B (green) denotes a time in-variant confounder (e.g., race, birth information), columns C - F denote two time-varying confounders (lighter yellow) at two different time points (e.g., age.1, age.2 and income.1, income.2, where .1 represents wave 1 and .2 represents wave 2). Columns G - I denote the exposure and outcome of interest (darker yellow), where G and H are time-varying values on each exposure, and column I is the outcome value at the final wave/timepoint. Missing data are denoted as *NA* and will need to be imputed (Step P2).](figures/sample data.png){width=900px} 
  

<br>

### Core Inputs
Please see the <a href="https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html">Specifying Core Inputs vignette</a> for more detail on the following core inputs. Here, we use ESETA1, a measure of economic strain experienced by the family, as the exposure and StrDif_Tot, or behavior problems measured by the SDQ, as the outcome.  

```{r}
set.seed(1234)

home_dir <- NA
#home_dir <- '/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/isa' #note: no / after

exposure <- "ESETA1"

exposure_time_pts <- c(6, 15, 24, 35, 58)

outcome <- "StrDif_Tot.58"

tv_confounders <- c(
  "SAAmylase.6","SAAmylase.15", "SAAmylase.24",
  "MDI.6", "MDI.15",                                            
  "RHasSO.6", "RHasSO.15", "RHasSO.24","RHasSO.35", "RHasSO.58",                                         
  "WndNbrhood.6","WndNbrhood.24", "WndNbrhood.35", "WndNbrhood.58",                                       
  "IBRAttn.6", "IBRAttn.15", "IBRAttn.24",                                   
  "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58",                                           
  "HOMEETA1.6", "HOMEETA1.15", "HOMEETA1.24", "HOMEETA1.35", "HOMEETA1.58",                               
  "InRatioCor.6", "InRatioCor.15", "InRatioCor.24", "InRatioCor.35", "InRatioCor.58",                         
  "ESETA1.6", "ESETA1.15", "ESETA1.24", "ESETA1.35", "ESETA1.58",               
  "CORTB.6", "CORTB.15", "CORTB.24",                                                                  
  "EARS_TJo.24", "EARS_TJo.35",                                        
  "LESMnPos.24", "LESMnPos.35",                                  
  "LESMnNeg.24", "LESMnNeg.35",       
  "StrDif_Tot.35", "StrDif_Tot.58",    
  "fscore.35", "fscore.58"
) 

ti_confounders <- c(
  "state", "BioDadInHH2", "PmAge2", "PmBlac2", "TcBlac2", "PmMrSt2", "PmEd2", "KFASTScr",
  "RMomAgeU", "RHealth", "HomeOwnd", "SWghtLB", "SurpPreg", "SmokTotl", "DrnkFreq",
  "peri_health", "caregiv_health", "gov_assist"
)
```
<br>

Some helper functions have optional arguments to suppress saving output locally (`save.out = FALSE`) and printing it to the console ( `verbose = FALSE`). The defaults to both arguments are TRUE. Users must supply a path to a home directory if `save.out = TRUE`.  

```{r}
save.out = FALSE

verbose = TRUE
```

<br>

As shown in Figure 2, users have several options for reading in data. They can begin this workflow with the following options:  
<br>
  
* (P1) long data: complete or with missingness that can be formatted and converted to wide data and (P3) imputed as needed 
* (P2) wide data: complete or missingness that can be formatted and (P3) imputed as needed  
* (P3) data already imputed in wide format can be read in as a list 

<br>

![Figure 2. Schematic of recommended preliminary steps showing the transformation of the 3 different kinds of starting data (enumerated in bold) to the three kinds of data accepted by *devMSMs*.](figures/prelim steps overview.png){width=900px}  
  
<br>
<br>

### P1. Single Long Data Frame
Users beginning with a single data frame in long format (with or without missingness) can utilize a helper function `formatLongData()` to summarize exposure and outcome data and convert to required variable names.  

First, we load the simulated longitudinal data in long format (with missingness) that accompanies *devMSMs*. These data are simulated based on data from the Family Life Project (FLP), a longitudinal study following 1,292 families representative of two geographic areas (three counties in North Carolina and three counties in Pennsylvania) with high rural child poverty (Vernon-Feagans et al., 2013; Burchinal et al., 2008). We take the example exposure of economic strain (ESETA1) measured at 6, 15, 24, 35, and 58 months in relation to the outcome of behavior problems (StrDif_Tot) measured at 58 months.  
```{r}
data("sim_data_long_miss", package = "devMSMs")

data_long <- sim_data_long_miss

head(data_long, n = c(5, 10))
```
<br>
  
#### P1a. Format Long Data
For long data that is not correctly formatted, `formatLongData()` allows the users to supply existing variables for time (`time_var`), ID (`id_var`), and missing data (`missing`) for re-naming according to what is required by the package. It also allows the user to submit variables that should be factors and integers, and the function classes any factor confounders (`factor_confounders`) as factors, integer confounders (`integer_confounders`) as integers in the data, and all others as numeric.  

Below, we format the simulated long FLP data.  
```{r}
factor_confounders = c("state", "TcBlac2","BioDadInHH2","HomeOwnd", "PmBlac2",       
                       "PmMrSt2", "SurpPreg", "RHealth", "SmokTotl", "DrnkFreq",
                       "RHasSO")

integer_confounders = c("KFASTScr", "PmEd2", "RMomAgeU", "SWghtLB", "peri_health", "caregiv_health" , 
                        "gov_assist", "B18Raw", "EARS_TJo", "MDI")

data_long_f <- formatLongData(data = data_long, exposure = exposure, 
                              exposure_time_pts = exposure_time_pts, outcome = outcome, 
                              time_var = "WAVE", 
                              id_var = "ID",                                
                              missing = NA,
                              factor_confounders = factor_confounders,    
                              integer_confounders = integer_confounders, 
                              home_dir = home_dir, 
                              save.out = save.out) 

head(data_long_f, n = c(5, 10))
```

We get a descriptive statistics summary of the exposure, ESETA1, and the outcome, StrDif_Tot.58, for our visual inspections.  

<br>

#### P1b. Tranform Formatted Long Data to Wide
Users with correctly formatted data in long format have the option of using the following code to transform their data into wide format, to proceed to using the package (if there is no missing data) or imputing (with < 20% missing data MAR).  

We then transform our newly formatted long data into wide format, specifying `idvar` as "ID", `timevar` as "WAVE", and supplying the time points (encompassing exposure, confounder, and outcome time points) in the data as 6, 15, 24, 35, and 58 to `times`.    

```{r}
require("stats", quietly = TRUE)

v <- sapply(strsplit(tv_confounders[!grepl("\\:", tv_confounders)], "\\."), "[", 1)
v <- v[!duplicated(v)]

data_wide_f <- stats::reshape(data = data_long_f, 
                            idvar = "ID",
                            v.names = v, 
                            timevar = "WAVE",
                            times = c(6, 15, 24, 35, 58), 
                            direction = "wide")

data_wide_f <- data_wide_f[, colSums(is.na(data_wide_f)) < nrow(data_wide_f)]

head(data_wide_f, n = c(5, 10))
```
  
<br> 
<br>

### P2. Single Wide Data Frame
Alternatively, users could start with a single data frame of wide data (with or without missingness).  

Below, we we load in a single complete, wide data frame simulated from FLP as an example.    
```{r}
data("sim_data_wide", package = "devMSMs")

data_wide <- sim_data_wide

head(data_wide,  n = c(5, 10))
```

<br>

Data with missingness is more common with human data. Below we read in simulated wide FLP data with missingness.   
```{r}
data("sim_data_wide_miss", package = "devMSMs")

data_wide <- sim_data_wide_miss

head(data_wide,  n = c(5, 10))
```
<br>

#### P2a. Format Wide Data
Users beginning with a single unformatted data frame in long format can utilize a helper function `formatWideData()` to summarize exposure and outcome data and convert to required variable names. `formatWideData()` allows the users to supply existing variables for ID (`id_var`) and missing data (`missing`) for re-naming according to what is required by the package. It also allows the user to submit variables that should be factors and integers, and the function classes any factor confounders (`factor_confounders`) as factors, integer confounders (`integer_confounders`) as integers in the data, and all others as numeric.  

Below, we format the simulated wide FLP data by listing out variables to make into factors and integers in wide format (e.g., "variable.t"), as well as the ID and missingness indicators.  
```{r}
factor_confounders <- c("state", "TcBlac2","BioDadInHH2","HomeOwnd", "PmBlac2",       
                        "PmMrSt2", "SurpPreg", "RHealth", "SmokTotl", "DrnkFreq",
                        "RHasSO.6", "RHasSO.15", "RHasSO.24", "RHasSO.35", "RHasSO.58")

integer_confounders = c("KFASTScr", "PmEd2", "RMomAgeU", "SWghtLB", "peri_health", "caregiv_health" , 
                        "gov_assist", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58", 
                        "EARS_TJo.24", "EARS_TJo.35", "MDI.6", "MDI.15")

data_wide_f <- formatWideData(data = data_wide, exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, 
                              id_var = "ID",
                              missing = NA, 
                              factor_confounders = factor_confounders,
                              integer_confounders = integer_confounders,
                              home_dir = home_dir, save.out = save.out) 

head(data_wide_f, n = c(5, 10))
```

<br>
<br>

### P3. Formatted Wide Data with Missingness
The functions of the *devMSMs* package accept data in the form of a single data frame with no missing values or *m* imputed datasets in the form of either a mids object (output from the mice package or via `imputeData()`) or a list of imputed datasets. Most developmental data from humans will have some amount of missing data. Given that the creation of IPTW balancing weights requires complete data, we recommend imputing data. Imputation assumes a missing data mechanism of missing at random (MAR) and no more than 20% missing data in total (Leyrat et al., 2021). Given existing work demonstrating its superiority, *devMSMS* implements the ‘within’ approach for imputed data, conducting all steps on each imputed dataset before pooling estimates using Rubin’s rules to create final average predictions and contrast comparisons in *Worfklows* vignettes Step 5 (Leyrat et al, 2021; Granger et al., 2019).  

As shown below, users can use a helper function to impute their wide data or impute elsewhere and read in the imputed data as a list for use with *devMSMs*.  

<br>

#### P3a. Multiply Impute Formatted, Wide Data Frame using MICE
Users have the option of using the helper `imputeData()` function to impute their correctly formatted wide data. This step can take a while to run. The user can specify how many imputed datasets to create (default m = 5). `imputeData()` draws on the `mice()` function from the *mice* package (van Buuren & Oudshoorn, 2011) to conduct multiple imputation by chained equations (mice). All other variables present in the dataset are used to impute missing data in each column.  

The user can specify the imputation method through the `method` field drawing from the following list: “pmm” (predictive mean matching), “midastouch” (weighted predictive mean matching), “sample” (random sample from observed values), “rf” (random forest) or “cart” (classification and regression trees). Random forest imputation is the default given evidence for its efficiency and superior performance (Shah et al., 2014). Please review the *mice* documentation for more details.  
Additionally, users can specify an integer value to `seed` in order to offset the random number generator in *mice()* and make reproducible imputations.  

The parameter `read_imps_from_file` will allow you to read already imputed data in from local storage (TRUE) so as not to have to re-run this imputation code multiple times (FALSE; default). Users may use this parameter to supply their own mids object of imputed data from the *mice* package  (with the title ‘all_imp.rds’). Be sure to inspect the console for any warnings as well as the resulting imputed datasets. Any variables that have missing data following imputation may need to be removed due to high collinearity and/or low variability.   

The required inputs for this function are a data frame in wide format (formatted according to pre-requirements listed above), m number of imputed datasets to create, a path to the home directory (if `save.out = TRUE`), exposure (e.g., “variable”), and outcome (e.g., “variable.t”). The home directory path, exposure, and outcome should already be defined if the user completed the <a href="https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html">Specifying Core Inputs vignette</a>.

The optional inputs are as follows.  

The user can specify an imputation method compatible with `mice()` (see above). Additionally, the user can specify in `maxit` the number of interactions for `mice::mice()` to conduct (default is 5). The user can also specify `para_proc`, a logical indicator indicating whether or not to speed up imputing using parallel processing (default = TRUE). This draws on 2 cores using functions from the *parallel*, *doRNG*, and *doParallel* packages.   

The user may also specify any additional inputs accepted by `mice::mice()` and we advise consulting the  <a href:="https://www.rdocumentation.org/packages/mice/versions/3.16.0/topics/mice">[*mice* documentation]</a> for more information.     
  
The user can also indicate if they have already created imputed datasets from this function and wish to read them in (`read_imps_from_file = TRUE` rather than recreate them (default).  

For this example, we create 2 imputed datasets using the default random forest method and 0 iterations (just for illustrative purposes), set a seed for reproducibility, and assign the output to `data` for use with *devMSMs*. This code takes some time to run. (Note: given the challenges of imputing data from .rda files, we have set `m = 2` and `maxit = 0` here just for illustrative purposes. We recommend setting both `m = 5` and `maxit = 5` (*mice* default) when running data.)  
 
```{r}
s <- 1234

m <- 2

method <- "rf" 

maxit <- 0

imputed_data <- imputeData(data = data_wide_f, exposure = exposure, outcome = outcome, 
                           m = m, method = method, maxit = maxit, para_proc = FALSE, 
                           seed = s, read_imps_from_file = FALSE, 
                           home_dir = home_dir, save.out = save.out)

head(mice::complete(imputed_data, 1), n = c(5, 10))

data <- imputed_data

#testing
lapply(1:imputed_data$m, function(x) {summary(mice::complete(imputed_data, x)$SmokTot)})
```

We inspect the output to the console for any warnings from `mice()`.  

The mice object can now be assigned to `data` for use in the *deveMSMs* package (see *Workflows* vignettes).  

<br>

#### P3b. Read in as a List of Wide Imputed Data Saved Locally 
Alternatively, if a user has imputed datasets already created from wide, formatted data using a program other than *mice*, they can read in, as a list, files saved locally as .csv files (labeled “1”:m) in a single folder. This list can be assigned to `data` for use in the *deveMSMs* package (see *Workflows* vignettes).  

Below, we load in a list of imputed data simulated from FLP, as an example. (See the example Rmarkdown file for code to do this with files saved locally.)  
```{r}
data("sim_data_imp_list", package = "devMSMs")

data <- sim_data_imp_list

head(data[[1]],  n = c(5, 10))
```

<br>
<br>

### P4. Optional: Specify Exposure Epochs
Users have the option to specify exposure epochs, or meaningful periods of developmental time that many encompass the time points at which the exposure was measured. The user has the option to draw on theory and the structure of their data to specify developmental epochs of exposure that differ from the time points at which exposure was collected.  

To specify epochs, users utilize the optional `epochs` argument by providing a data frame that contains two variables: for epochs: provide, in quotations, a list of user-created names for each epoch; for values: as a list, for each named epoch, provide a single integer or a list of integers (from the exposure time points) that constitute each epoch. Each named epoch must have a corresponding value (but the values for each epoch can differ in their number of entries, as shown below). The user should ensure that all epoch values are included in the `exposure_time_pts` field.   

The exposure epochs will be arguments in the `fitModel()` and `compareHistories()` *devMSMs* functions (see *Workflows* vignettes) and their specification should be kept consistent throughout use of the package and its vignettes. THey will constitute the main effects variables when modeling the relation between exposure and outcome (*Workflows* vignettes Step 5a) and form the basis for estimating and comparing exposure histories (*Workflows* vignettes Step 5b). If no epochs are specified, the exposure time points will be used at the aforementioned steps.  

Below, we specify Infancy, Toddlerhood, and Childhood epochs that correspond to 6 and 15; 24 and 35; and 58 months, respectively.  
```{r}
epochs <- data.frame(epochs = c("Infancy", 
                                "Toddlerhood", 
                                "Childhood"), 
                     values = I(list(c(6, 15), 
                                     c(24, 35), 
                                     c(58)
                     ))) 
epochs
```

<br>

### P5. Recommended: Specify & Inspect Exposure Histories
Exposure histories are the units with which users will test their substantive hypotheses, and their construction should be determined by both theoretical and practical reasoning. We strongly recommend users verify and inspect exposure histories a priori in relation to their data and hypotheses.   
<br>

### P5a. Identify High and Low Cutoff Values (For Continuous Exposures)
First, for continuously distributed exposures (regardless of whether or not exposure epochs are specified), we recommend users indicate high and low cutoff values as an optional input to the `compareHistories()`) *devMSMs* function (see *Workflows* vignettes).  

To do so, they specify to `hi_lo_cut`, as a list, a quantile value (0-1) above which will be considered high levels exposure, followed by a quantile value (0-1) below which will be considered low levels of exposure (default is median split). These values may have to be revised following inspection of the sample distribution across the resulting exposure histories in the subsequent steps. These final values will be used in creating exposure histories in Step 5 of the *Workflows* vignettes.  

Below, we specify the 60th and 30th percentiles to demarcate high and low levels of economic strain exposure, respectively.  
```{r}
hi_lo_cut <- c(0.6, 0.3) 
```
<br>


### P5b. Specify Hypotheses-Relevant Exposure Histories 
We strongly recommend users be selective about which histories, or developmental sequences of high and low exposure (at exposure time points or epochs), are vital for testing their hypotheses. We recommend that the user estimates and compares only a subset of all possible exposure histories using the `reference` and `comparison` fields (rather than comparing all possible exposure histories). 

The user can specify a custom subset of exposure histories using the `reference` and `comparison` fields as optional inputs to the `compareHistories()` *devMSMs* function (see *Workflows* vignettes). To conduct these customized comparisons, users must provide at least one unique valid history (e.g., “l-l-l”) as a reference by, in quotations, provide a string (or a list of strings) of lowercase l’s and h’s (each separated by -), each corresponding to each exposure epoch (or time point), that signify the sequence of exposure levels (“low” or “high”, respectively).   

If you supply a reference history, in comparisons provide at least one unique and valid history for comparison by, in quotations, providing a string (or list of strings) of l’s and h’s (each separated by “-”), with each corresponding to each exposure epoch, that signify the sequence of exposure levels (“low” or “high”, respectively) that constitutes the comparison exposure history/histories to be compared to the reference in Step 5b of the *Workflows* vignettes. If you supply one or more comparisons, at least one reference must be specified. Each reference exposure history will be compared to each comparison history and all comparisons will be supplied for multiple comparison correction. If no reference or comparison is specified, all histories will be compared to each other in Step 5b of the *Workflows* vignettes.   

These final reference and comparison values established at this step should be used for estimating and comparing exposure histories in Step 5b of the *Workflows* vignettes. If there are  more than 4 exposure main effects (either as epochs or exposure time points), the user is required to select a subset of history comparisons (Step 5b of the *Workflows* vignettes), given that the base code (see the `hypotheses()` function from the *marginaleffects* package) cannot accommodate all pairwise history comparisons for more than 5 time points).  

Below, we specify low economic strain at all epochs ("l-l-l") as our reference event in comparison to high levels at all epochs ("h-h-h") as well as all histories that contain 1 dose of exposure to high economic strain at different epochs.  
```{r}
reference <- c("l-l-l")

comparison <- c("h-h-h", "l-l-h", "h-l-l", "l-h-l") 
```

<br>

### P5c. Inspect Exposure Histories and Data
For all users, we highly recommend use of the helper `inspectData()` function (with the a complete dataset in long or wide format or imputed data in the case of missingness) to summarize exposure, outcome, and confounders and inspect the sample distribution among exposure histories. Based on any user-specified exposure epochs and high and low quantile values (for continuous exposures), this function outputs a table showing the sample distribution across all histories.  

We strongly suggest visually inspecting this table and revising the designation of epochs and/or high and low quantile values (for continuous exposures) until each history contains a reasonable number of participants. While there is no gold standard required number per history cell, users should guard against extrapolation beyond the scope of the data. For example, in our data, when using 75th and 25th percentile cutoffs, there were histories that represented less than two cases and thus we re-evaluated our cutoffs. Users may wish to revise any epoch designation and high and low cutoff values, where applicable. The function conducts summaries and history distribution inspection for each imputed dataset if imputed data are supplied.   

The required inputs for `inspectData()` are: complete data (as a data frame in wide or long format, a list of imputed data frames in wide format, or a mids object), exposure (e.g., “variable”), and outcome (e.g., “variable.t”).   

Optional inputs are a home directory (if `save.out = TRUE`), epochs, high/low cutoff values for continuous exposures, and specification of reference and comparison histories. 

The helper `inspectData()` function outputs the following files into the home directory: a correlation plot of all variables in the dataset, tables of exposure and outcome descriptive statistics, and two summary tables of the confounders considered at each time point.

```{r}
inspectData(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, 
            ti_confounders = ti_confounders, tv_confounders = tv_confounders,
            epochs = epochs, hi_lo_cut = hi_lo_cut, reference = reference, comparison = comparison, 
            home_dir = home_dir, verbose = verbose, save.out = save.out) 
```
Here, we see summaries of the data types as well as reasonable cell counts in each of our specified histories, for each imputed dataset. 

<br>


### References
Arel-Bundock, Vincent. 2023. marginaleffects: Predictions, Comparisons, Slopes, Marginal  Means, and Hypothesis Tests. 
https://CRAN.R-project.org/package=marginaleffects.

Burchinal, M., Howes, C., Pianta, R., Bryant, D., Early, D., Clifford, R., & Barbarin, O. (2008). Predicting Child Outcomes at the End of Kindergarten from the Quality of Pre-Kindergarten Teacher–Child Interactions and Instruction. Applied Developmental Science, 12(3), 140–153. https://doi.org/10.1080/10888690802199418  

Granger, E., Sergeant, J. C., & Lunt, M. (2019). Avoiding pitfalls when combining multiple imputation and propensity scores. Statistics in Medicine, 38(26), 5120–5132. https://doi.org/10.1002/sim.8355

Leyrat, C., Carpenter, J. R., Bailly, S., & Williamson, E. J. (2021). Common Methods for Handling Missing Data in Marginal Structural Models: What Works and Why. American Journal of Epidemiology, 190(4), 663–672. https://doi.org/10.1093/aje/kwaa225

Shah, A. D., Bartlett, J. W., Carpenter, J., Nicholas, O., & Hemingway, H. (2014). Comparison of Random Forest and Parametric Imputation Models for Imputing Missing Data Using MICE: A CALIBER Study. American Journal of Epidemiology, 179(6), 764–774. https://doi.org/10.1093/aje/kwt312

Vernon-Feagans, L., Cox, M., Willoughby, M., Burchinal, M., Garrett-Peters, P., Mills-Koonce, R., Garrett-Peiers, P., Conger, R. D., & Bauer, P. J. (2013). The Family Life Project: An Epidemiological and Developmental Study of Young Children Living in Poor Rural Communities. Monographs of the Society for Research in Child Development, 78(5), i–150.  

van Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011. “mice: Multivariate Imputation by Chained Equations in r.” Journal of Statistical Software 45 (3): 1–67. https://doi.org/10.18637/jss.v045.i03.



