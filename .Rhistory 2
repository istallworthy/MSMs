if(new[x,y+1]<=as.numeric(quantile(new[,y+1],probs=lo_cutoff, na.rm=T))){
return("l")}
}), collapse="-")
})
time_varying_wide=apply(expand.grid(time_varying_covariates, as.character(time_pts)), 1, paste, sep="", collapse=".")
time_varying_wide=sort(time_varying_wide)
time_varying_wide=c(id, time_varying_wide)
time_varying_wide=time_varying_wide[!time_varying_wide %in% time_var_exclude] #rem
dat_wide=suppressWarnings(stats::reshape(data=data,idvar=id,v.names= time_varying_covariates, timevar="WAVE", times=c(time_pts), direction="wide"))
new=data.frame(ID=dat_wide[,id])
colnames(new)<-id
for (e in 1:nrow(exposure_epochs)){
epoch=exposure_epochs[e,1]
temp=data.frame(row.names=1:nrow(dat_wide))
new_var=paste0(exposure, "_", epoch)
#finds data from each time point in each epoch, horizontally aligns all exposure values within the epoch for averaging
for (l in 1:length(as.numeric(unlist(exposure_epochs[e,2])))){
level=as.numeric(unlist(exposure_epochs[e,2]))[l]
z=dat_wide[,which(grepl(paste0(exposure, ".", level), names(dat_wide)))]
temp=cbind(temp, z) }
new=new%>%dplyr::mutate(!!new_var :=rowMeans(temp, na.rm=T))
new[,new_var]=as.numeric(new[,new_var])}
new$history<- lapply(1:nrow(new), function(x){
paste(lapply(1:nrow(exposure_epochs), function(y){
if(is.nan(new[x,y+1])){
return(NA)}
if(new[x,y+1]>=as.numeric(quantile(new[,y+1],probs=hi_cutoff, na.rm=T))){
return("h")}
if(new[x,y+1]<=as.numeric(quantile(new[,y+1],probs=lo_cutoff, na.rm=T))){
return("l")}
}), collapse="-")
})
View(new)
time_varying_wide=apply(expand.grid(time_varying_covariates, as.character(time_pts)), 1, paste, sep="", collapse=".")
time_varying_wide=sort(time_varying_wide)
time_varying_wide=c(id, time_varying_wide)
time_varying_wide=time_varying_wide[!time_varying_wide %in% time_var_exclude] #rem
dat_wide=suppressWarnings(stats::reshape(data=data,idvar=id,v.names= time_varying_covariates, timevar="WAVE", times=c(time_pts), direction="wide"))
new=data.frame(ID=dat_wide[,id])
colnames(new)<-id
for (e in 1:nrow(exposure_epochs)){
epoch=exposure_epochs[e,1]
temp=data.frame(row.names=1:nrow(dat_wide))
new_var=paste0(exposure, "_", epoch)
#finds data from each time point in each epoch, horizontally aligns all exposure values within the epoch for averaging
for (l in 1:length(as.numeric(unlist(exposure_epochs[e,2])))){
level=as.numeric(unlist(exposure_epochs[e,2]))[l]
z=dat_wide[,which(grepl(paste0(exposure, ".", level), names(dat_wide)))]
temp=cbind(temp, z) }
new=new%>%dplyr::mutate(!!new_var :=rowMeans(temp, na.rm=T))
new[,new_var]=as.numeric(new[,new_var])}
for (e in 1:nrow(exposure_epochs)){
epoch=exposure_epochs[e,1]
temp=data.frame(row.names=1:nrow(dat_wide))
new_var=paste0(exposure, "_", epoch)
#finds data from each time point in each epoch, horizontally aligns all exposure values within the epoch for averaging
for (l in 1:length(as.numeric(unlist(exposure_epochs[e,2])))){
level=as.numeric(unlist(exposure_epochs[e,2]))[l]
z=dat_wide[,which(grepl(paste0(exposure, ".", level), names(dat_wide)))]
temp=cbind(temp, z) }
new=new%>%dplyr::mutate(!!new_var :=rowMeans(temp, na.rm=T))
new[,new_var]=as.numeric(new[,new_var])
}
exposure_levels=apply(gtools::permutations(2, nrow(exposure_epochs), c("l", "h"), repeats.allowed=TRUE), 1, paste, sep="", collapse="-")
exposure_levels
data <- formatDataStruct(object)
time_varying_wide=apply(expand.grid(time_varying_covariates, as.character(time_pts)), 1, paste, sep="", collapse=".")
time_varying_wide=sort(time_varying_wide)
time_varying_wide=c(id, time_varying_wide)
time_varying_wide=time_varying_wide[!time_varying_wide %in% time_var_exclude] #rem
dat_wide=suppressWarnings(stats::reshape(data=data,idvar=id,v.names= time_varying_covariates, timevar="WAVE", times=c(time_pts), direction="wide"))
new=data.frame(ID=dat_wide[,id])
colnames(new)<-id
load_all()
data <- formatDataStruct(object)
time_varying_wide=apply(expand.grid(time_varying_covariates, as.character(time_pts)), 1, paste, sep="", collapse=".")
time_varying_wide=sort(time_varying_wide)
time_varying_wide=c(id, time_varying_wide)
time_varying_wide=time_varying_wide[!time_varying_wide %in% time_var_exclude] #rem
dat_wide=suppressWarnings(stats::reshape(data=data,idvar=id,v.names= time_varying_covariates, timevar="WAVE", times=c(time_pts), direction="wide"))
new=data.frame(ID=dat_wide[,id])
colnames(new)<-id
for (e in 1:nrow(exposure_epochs)){
epoch=exposure_epochs[e,1]
temp=data.frame(row.names=1:nrow(dat_wide))
new_var=paste0(exposure, "_", epoch)
#finds data from each time point in each epoch, horizontally aligns all exposure values within the epoch for averaging
for (l in 1:length(as.numeric(unlist(exposure_epochs[e,2])))){
level=as.numeric(unlist(exposure_epochs[e,2]))[l]
z=dat_wide[,which(grepl(paste0(exposure, ".", level), names(dat_wide)))]
temp=cbind(temp, z) }
new=new%>%dplyr::mutate(!!new_var :=rowMeans(temp, na.rm=T))
new[,new_var]=as.numeric(new[,new_var])
}
load_all()
data <- formatDataStruct(object)
View(new)
tot_hist=apply(gtools::permutations(2, nrow(exposure_epochs), c("l", "h"), repeats.allowed=TRUE), 1, paste, sep="", collapse="-")
new$history<- lapply(1:nrow(new), function(x){
paste(lapply(1:nrow(exposure_epochs), function(y){
if(is.nan(new[x,y+1])){
return(NA)}
if(new[x,y+1]>=as.numeric(quantile(new[,y+1],probs=hi_cutoff, na.rm=T))){
return("h")}
if(new[x,y+1]<=as.numeric(quantile(new[,y+1],probs=lo_cutoff, na.rm=T))){
return("l")}
}), collapse="-")
})
View(new)
his_summ=as.data.frame(as.data.frame(new)%>%dplyr::group_by(history)%>%dplyr::summarize(n=dplyr::n()))
View(his_summ)
his_summ=his_summ[!grepl("NULL", unlist(his_summ$history)),]
his_summ=his_summ[!grepl("NA", unlist(his_summ$history)),]
View(his_summ)
his_summ=as.data.frame(as.data.frame(new)%>%dplyr::group_by(history)%>%dplyr::summarize(n=dplyr::n()))
View(his_summ)
his_summ=his_summ[!grepl("NULL", unlist(his_summ$history)),]
his_summ=his_summ[!grepl("NA", unlist(his_summ$history)),]
lo_cutoff*100
length(tot_his)
length(tot_hist)
his_summ$history
his_summ=his_summ[1:7,]
!tot_hist %in% his_summ$history
tot_hist[!tot_hist %in% his_summ$history]
View(his_summ)
load_all()
data$PmMrSt2
devtools::document()
devtools::document()
devtools::document()
load_all()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
load_all()
balance_stats_final <- assessBalance(object, full_forms, data_for_model_with_weights, histories=0)
traceback()
devtools::document()
devtools::document()
devtools::document()
balance_stats_final <- assessBalance(object, full_forms, data_for_model_with_weights, histories=0)
View(unbalanced_covars)
load_all()
preBalanceChecking(object, wide_long_datasets, full_forms, histories=0)
balance_stats <- assessBalance(object, short_forms, data_for_model_with_weights, histories=0)
prebal<-read.csv(paste0(home_dir, "pre balance/", exposure, "_prebalance_stat_summary.csv"))
View(prebal)
View(unbalanced_covars)
colnames(prebal)[colnames(prebal)=="avg_bal"]<-"avg_pre_bal"
colnames(prebal)[colnames(prebal)=="balanced_avg"]<-"pre_balanced_avg"
View(prebal)
prebal<-read.csv(paste0(home_dir, "pre balance/", exposure, "_prebalance_stat_summary.csv"), row.names = F)
prebal<-read.csv(paste0(home_dir, "pre balance/", exposure, "_prebalance_stat_summary.csv"), row.names = NULL)
View(prebal)
View(prebal)
prebal<-read.csv(paste0(home_dir, "pre balance/", exposure, "_prebalance_stat_summary.csv"), row.names = NULL, header=F, sep",")
prebal<-read.csv(paste0(home_dir, "pre balance/", exposure, "_prebalance_stat_summary.csv"), row.names = NULL, header=F, sep=",")
View(prebal)
prebal<-read.csv(paste0(home_dir, "pre balance/", exposure, "_prebalance_stat_summary.csv"), row.names = NULL)
View(prebal)
colnames(prebal)[colnames(prebal)=="avg_bal"]<-"avg_pre_bal"
colnames(prebal)[colnames(prebal)=="balanced_avg"]<-"pre_balanced_avg"
View(prebal)
comp=merge(unbalanced_covars, prebal, by=c("exposure", "exp_time","covar_time", "covariate"))
View(comp)
sum(comp$pre_balanced_avg)
comp$balanced_avg-comp$pre_balanced_avg
sum(comp$balanced_avg-comp$pre_balanced_avg)==-1
sum(comp$balanced_avg-comp$pre_balanced_avg==-1)
comp[sum(comp$balanced_avg-comp$pre_balanced_avg==-1),]
comp[sum(comp$balanced_avg-comp$pre_balanced_avg==-1),]
cat(knitr::kable(comp[sum(comp$balanced_avg-comp$pre_balanced_avg==-1),], format='pipe'),sep="\n")
sum(comp$balanced_avg-comp$pre_balanced_avg==-1)
cat(knitr::kable(comp[comp$balanced_avg-comp$pre_balanced_avg==-1,], format='pipe'),sep="\n")
colnames(comp)<-c("exposure", "exposure time point", "covariate time point", "covariate", "avg_bal_stat", "balanced", "avg_pre_bal_stat", "pre-balanced")
cat(knitr::kable(comp[comp$balanced_avg-comp$pre_balanced_avg==-1,], format='pipe'),sep="\n")
prebal<-read.csv(paste0(home_dir, "pre balance/", exposure, "_prebalance_stat_summary.csv"), row.names = NULL)
colnames(prebal)[colnames(prebal)=="avg_bal"]<-"avg_pre_bal"
colnames(prebal)[colnames(prebal)=="balanced_avg"]<-"pre_balanced_avg"
comp=merge(unbalanced_covars, prebal, by=c("exposure", "exp_time","covar_time", "covariate"))
cat(paste0("Prior to weighting, ", sum(comp$pre_balanced_avg), " out of ",nrow(comp), "(", round((sum(comp$pre_balanced_avg)/nrow(comp))*100,2), "%) covariates were imbalanced compared to ",
sum(comp$balanced_avg),  " out of ",nrow(comp), "(", round((sum(comp$balanced_avg)/nrow(comp))*100,2), "%) after weighting.",
sum(comp$balanced_avg-comp$pre_balanced_avg==-1), " covariates were balanced prior to weighting and are now imbalanced after weighting:"), "\n")
# colnames(comp)<-c("exposure", "exposure time point", "covariate time point", "covariate", "avg_bal_stat", "balanced", "avg_pre_bal_stat", "pre-balanced")
cat(knitr::kable(comp[comp$balanced_avg-comp$pre_balanced_avg==-1,], format='pipe'),sep="\n")
cat(paste0("Prior to weighting using the full balancing formula, ", sum(comp$pre_balanced_avg), " out of ",nrow(comp), "(", round((sum(comp$pre_balanced_avg)/nrow(comp))*100,2), "%) covariates were imbalanced compared to ",
sum(comp$balanced_avg),  " out of ",nrow(comp), "(", round((sum(comp$balanced_avg)/nrow(comp))*100,2), "%) after weighting.",
sum(comp$balanced_avg-comp$pre_balanced_avg==-1), " covariates were balanced prior to weighting and are now imbalanced after weighting:"), "\n")
cat(paste0("Prior to weighting using the full balancing formula, ", sum(comp$pre_balanced_avg), " out of ",nrow(comp), " (", round((sum(comp$pre_balanced_avg)/nrow(comp))*100,2), "%) covariates were balanced compared to ",
sum(comp$balanced_avg),  " out of ",nrow(comp), " (", round((sum(comp$balanced_avg)/nrow(comp))*100,2), "%) after weighting. ",
sum(comp$balanced_avg-comp$pre_balanced_avg==-1), " covariates were balanced prior to weighting and are now imbalanced after weighting:"), "\n")
cat(knitr::kable(comp[comp$balanced_avg-comp$pre_balanced_avg==-1,], format='pipe'),sep="\n")
load_all()
object$weights_method="npcbps" #try different weights methods and re-run
data_for_model_with_weights<- createWeights(object, wide_long_datasets, new_short_forms, read_in_from_file="yes")
balance_stats_final <- assessBalance(object, full_forms, data_for_model_with_weights, histories=0)
object <- msmObject(
##### Directories Information (required) ####
# directories to long dataset
data_path ="/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/merged_tutorial_filtered.csv",
home_dir ="/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/",
#### Dataset Information (required) ####
#individual identifier
ID = "S_ID", #string
#time points of interest and name of time variable in long dataset
time_pts=c(6, 15, 24, 35, 58), #list of integers
time_var="TAge", #string
#marker for missing data
missing="NA", #string or integer(s)
#list out all variables that are time-varying; including ANY variables collected at only a single time point (with missin for other time points )
time_varying_variables= c("ALI_Le","SAAmylase", "EARS_TJo", "MDI",  "LESMnPos","LESMnNeg", "pcx_engaged", "pcx_CompTwo", "StrDif_Tot", "RHasSO", "WndNbrhood","EF_avg_perc", "IBRAttn","B18Raw", "HOMEETA1","InRatioCor", "ESETA1", "CORTB"),
#list all continuous variables here; all others assumed ordinal for imputation; default is none
# continuous_variables=c("GrosPay1", "RMomAgeU", "RMAge1st", "SwghtLB","RWghtLb", "IBQDnovm", "MDI", "AGE", "WIND", "PCX_POS", "PCX_NEG", "BSI", "TIMEofDAY", "CORTBASE", "sAABASE", "ESETA1", "HOMEETA1", "CTSETA1", "INR"),
continuous_variables=c("PmAge2", "ALI_Le", "SAAmylase", "EARS_Tjo", "IBRAttn", "LESMnPos", "LESMnNeg","B18Raw", "HOMEETA1", "pcx_engaged", "PmMrSt2",
"pcx_CompTwo", "StrDif_Tot", "WndNbrhood", "InRatioCor", "EF_avg_perc", "gov_asst", "mat_health", "peri_health", "ESETA1", "CORTB"),
#list any covariates that are factors here; default is none, or that all variables are continuous
factor_covariates=c("state","TcBlac2", "PmBlac2", "RHasSO"), #list of characters
#### Imputation Specification (optional) ####
#number of imputations for step 4; default is 5
m=5, #integer
imp_method= "rf", #imputation method; pmm, midastouch, sample, cart , rf (default)
#### Exposure Information (required) ####
#exposure of interest that potentially have causal effects on outcome and exposure time point(s) (corresponding to values in time_var)
exposure=c("ESETA1"), #list of strings
# exposure_time_pts=c(6, 15, 24, 35, 58, 90, 154), #list of integers
exposure_time_pts=c(6, 15, 24, 35, 58), #list of integers
#### Balancing Information (optional) ###
short_form_lag=1, #integer specifying the maximum time lag for time-varying covariates for the initial round of balancing weights
weights_method="bart", #method for calculating weights: cbps, npcbps, bart, ps
balance_thresh=0.1, #correlation value above which covariates are not considered balanced with respect to exposure/outcome;used for finding potential confounds and asessing balance;
weights_percentile_cutoff=0.95, #percentile cutoff value for truncating weights to avoid heavy tails; default is 0.95;
#### History Comparison Information (required & optional) ####
#developmental time periods (and their corresponding time points) that constitute regime/history units of interest --these should be meaningful periods of time that may collapse over exposure time points to result in more manageable combinations for exploring effects of exposure histories (e.g, chronically high exposure vs. exposure only in infancy) on outcomes
exposure_epochs=data.frame(epochs=c("Infancy", "Toddlerhood", "Childhood"), #user-created names of epochs as a list of strings
values=I(list(c(6,15), c(24,35), c(58)))), #time point(s) encompassed in each epoch that correspond to data as a list of numeric lists
#inspect the following exposure levels denoting all possible histories of high ("h") and low ("l") exposure over the epochs
# apply(gtools::permutations(2, nrow(object$exposure_epochs), c("l", "h"), repeats.allowed=TRUE), 1, paste, sep="", collapse="-")
#select one of the above histories, or permutations of high ("h") and low ("l") levels of exposure (one leve for each of the exposure epochs) as your reference event, or the history/sequence to which you would like to compare the other histories
reference=NA, #optional: set a reference history of high ("h") and low ("l") levels of exposure separate by a "-"; the default is set to the history denoting low ("l") exposure at all time points; character string of "h" and "l" separated by a "-"
comparisons=NA, #optional: set a comparison history from list above; the default is to include all non-reference histories as comparisons; character string of "h" and "l" separated by a "-"
hi_cutoff=.60, #optional integer value for quantile value constituting the threshold for "high" levels of an exposure for outcome modeling; default set to 0.75
lo_cutoff=.30, #optional integer value for quantile value constituting the threshold for "low" levels of an exposure for outcome modeling; default set to 0.25
mc_method="BH", #optional method for multiple comparison correction for linear hypothesis tests; default is Benjamini-Hochburg, options are "holm", "hochberg","hommel", "bonferroni", "BH", "BY", "fdr", "none" (see stats::p.adjust() documentation)
#### Outcome Information (required) ####
#outcomes of interest and outcome time point
# outcomes=c("CORTBASE", "sAABASE"), #list of strings
outcome=c("StrDif_Tot"), #list of strings
outcome_time_pt=58, #integer value
#### Inclusion Information (optional) ####
#list any time-varying variables that you wish to include concurrently in the balancing forms (over-riding default of excluding concurrent time-varying variables as they cannot be distinguished from colliders)
keep_concurrent_tv_vars=NULL,
#### Exclusion Information (optional) ####
#list any time-varying variables that may get imputed but should NOT be present in the dataset because hey were not collected at certain times
time_var_exclude=c("ALI_Le.6", "ALI_Le.15","ALI_Le.24","ALI_Le.58","SAAmylase.35", "SAAmylase.58","CORTB.58",
"EARS_TJo.6","EARS_TJo.15", "EARS_TJo.58", "IBRAttn.35", "IBRAttn.58", "MDI.24", "MDI.35", "MDI.58", "LESMnPos.6",
"LESMnPos.15","LESMnPos.58", "LESMnNeg.6", "LESMnNeg.15", "LESMnNeg.58", "B18Raw.35","pcx_engaged.58", "pcx_CompTwo.6", "pcx_CompTwo.15",
"pcx_CompTwo.24", "pcx_CompTwo.35","StrDif_Tot.6", "StrDif_Tot.15","StrDif_Tot.24", "WndNbrhood.15", "EF_avg_perc.6", "EF_avg_perc.15",
"EF_avg_perc.24"), #default set to none
### Plotting Information (optional) ###
#optional list of alternative labels for exposures that will be used only for plotting
# exposure_labels=c("Home Resources", "Conflict in the Home", "Threat"),
exposure_labels=c("Economic Strain"),
#optional list of alternative labels for outcomes that will be used only for plotting
# outcome_labels=c("Cortisol","Salivary Alpha Amalayse"),
outcome_labels=c("Behavioral Problems"),
#optional string ("h" or "l") denoting which level of exposure at each exposure epoch to use when calculating dose (default is "h")
dose_level="l",
#the plots color data by dose (i.e., number of epochs) of high exposure; optional list of colors (equal to number of epochs +1) or brewer palette (see RColorBrewer::display.brewer.all() or https://r-graph-gallery.com/38-rcolorbrewers-palettes.html)
colors=(c("Dark2")) #list of string(s); default is 'Dark2'); c("blue4", "darkgreen", "darkgoldenrod", "red2")
)
object <- msmObject(
##### Directories Information (required) ####
# directories to long dataset
data_path ="/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/merged_tutorial_filtered.csv",
home_dir ="/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/",
#### Dataset Information (required) ####
#individual identifier
ID = "S_ID", #string
#time points of interest and name of time variable in long dataset
time_pts=c(6, 15, 24, 35, 58), #list of integers
time_var="TAge", #string
#marker for missing data
missing="NA", #string or integer(s)
#list out all variables that are time-varying; including ANY variables collected at only a single time point (with missin for other time points )
time_varying_variables= c("ALI_Le","SAAmylase", "EARS_TJo", "MDI",  "LESMnPos","LESMnNeg", "pcx_engaged", "pcx_CompTwo", "StrDif_Tot", "RHasSO", "WndNbrhood","EF_avg_perc", "IBRAttn","B18Raw", "HOMEETA1","InRatioCor", "ESETA1", "CORTB"),
#list all continuous variables here; all others assumed ordinal for imputation; default is none
# continuous_variables=c("GrosPay1", "RMomAgeU", "RMAge1st", "SwghtLB","RWghtLb", "IBQDnovm", "MDI", "AGE", "WIND", "PCX_POS", "PCX_NEG", "BSI", "TIMEofDAY", "CORTBASE", "sAABASE", "ESETA1", "HOMEETA1", "CTSETA1", "INR"),
continuous_variables=c("PmAge2", "ALI_Le", "SAAmylase", "EARS_Tjo", "IBRAttn", "LESMnPos", "LESMnNeg","B18Raw", "HOMEETA1", "pcx_engaged", "PmMrSt2",
"pcx_CompTwo", "StrDif_Tot", "WndNbrhood", "InRatioCor", "EF_avg_perc", "gov_asst", "mat_health", "peri_health", "ESETA1", "CORTB"),
#list any covariates that are factors here; default is none, or that all variables are continuous
factor_covariates=c("state","TcBlac2", "PmBlac2", "RHasSO"), #list of characters
#### Imputation Specification (optional) ####
#number of imputations for step 4; default is 5
m=5, #integer
imp_method= "rf", #imputation method; pmm, midastouch, sample, cart , rf (default)
#### Exposure Information (required) ####
#exposure of interest that potentially have causal effects on outcome and exposure time point(s) (corresponding to values in time_var)
exposure=c("ESETA1"), #list of strings
# exposure_time_pts=c(6, 15, 24, 35, 58, 90, 154), #list of integers
exposure_time_pts=c(6, 15, 24, 35, 58), #list of integers
#### Balancing Information (optional) ###
short_form_lag=1, #integer specifying the maximum time lag for time-varying covariates for the initial round of balancing weights
weights_method="bart", #method for calculating weights: cbps, npcbps, bart, ps
balance_thresh=0.1, #correlation value above which covariates are not considered balanced with respect to exposure/outcome;used for finding potential confounds and asessing balance;
weights_percentile_cutoff=0.95, #percentile cutoff value for truncating weights to avoid heavy tails; default is 0.95;
#### History Comparison Information (required & optional) ####
#developmental time periods (and their corresponding time points) that constitute regime/history units of interest --these should be meaningful periods of time that may collapse over exposure time points to result in more manageable combinations for exploring effects of exposure histories (e.g, chronically high exposure vs. exposure only in infancy) on outcomes
exposure_epochs=data.frame(epochs=c("Infancy", "Toddlerhood", "Childhood"), #user-created names of epochs as a list of strings
values=I(list(c(6,15), c(24,35), c(58)))), #time point(s) encompassed in each epoch that correspond to data as a list of numeric lists
#inspect the following exposure levels denoting all possible histories of high ("h") and low ("l") exposure over the epochs
# apply(gtools::permutations(2, nrow(object$exposure_epochs), c("l", "h"), repeats.allowed=TRUE), 1, paste, sep="", collapse="-")
#select one of the above histories, or permutations of high ("h") and low ("l") levels of exposure (one leve for each of the exposure epochs) as your reference event, or the history/sequence to which you would like to compare the other histories
reference=NA, #optional: set a reference history of high ("h") and low ("l") levels of exposure separate by a "-"; the default is set to the history denoting low ("l") exposure at all time points; character string of "h" and "l" separated by a "-"
comparisons=NA, #optional: set a comparison history from list above; the default is to include all non-reference histories as comparisons; character string of "h" and "l" separated by a "-"
hi_cutoff=.60, #optional integer value for quantile value constituting the threshold for "high" levels of an exposure for outcome modeling; default set to 0.75
lo_cutoff=.30, #optional integer value for quantile value constituting the threshold for "low" levels of an exposure for outcome modeling; default set to 0.25
mc_method="BH", #optional method for multiple comparison correction for linear hypothesis tests; default is Benjamini-Hochburg, options are "holm", "hochberg","hommel", "bonferroni", "BH", "BY", "fdr", "none" (see stats::p.adjust() documentation)
#### Outcome Information (required) ####
#outcomes of interest and outcome time point
# outcomes=c("CORTBASE", "sAABASE"), #list of strings
outcome=c("StrDif_Tot"), #list of strings
outcome_time_pt=58, #integer value
#### Inclusion Information (optional) ####
#list any time-varying variables that you wish to include concurrently in the balancing forms (over-riding default of excluding concurrent time-varying variables as they cannot be distinguished from colliders)
keep_concurrent_tv_vars=NULL,
#### Exclusion Information (optional) ####
#list any time-varying variables that may get imputed but should NOT be present in the dataset because hey were not collected at certain times
time_var_exclude=c("ALI_Le.6", "ALI_Le.15","ALI_Le.24","ALI_Le.58","SAAmylase.35", "SAAmylase.58","CORTB.58",
"EARS_TJo.6","EARS_TJo.15", "EARS_TJo.58", "IBRAttn.35", "IBRAttn.58", "MDI.24", "MDI.35", "MDI.58", "LESMnPos.6",
"LESMnPos.15","LESMnPos.58", "LESMnNeg.6", "LESMnNeg.15", "LESMnNeg.58", "B18Raw.35","pcx_engaged.58", "pcx_CompTwo.6", "pcx_CompTwo.15",
"pcx_CompTwo.24", "pcx_CompTwo.35","StrDif_Tot.6", "StrDif_Tot.15","StrDif_Tot.24", "WndNbrhood.15", "EF_avg_perc.6", "EF_avg_perc.15",
"EF_avg_perc.24"), #default set to none
### Plotting Information (optional) ###
#optional list of alternative labels for exposures that will be used only for plotting
# exposure_labels=c("Home Resources", "Conflict in the Home", "Threat"),
exposure_labels=c("Economic Strain"),
#optional list of alternative labels for outcomes that will be used only for plotting
# outcome_labels=c("Cortisol","Salivary Alpha Amalayse"),
outcome_labels=c("Behavioral Problems"),
#optional string ("h" or "l") denoting which level of exposure at each exposure epoch to use when calculating dose (default is "h")
dose_level="l",
#the plots color data by dose (i.e., number of epochs) of high exposure; optional list of colors (equal to number of epochs +1) or brewer palette (see RColorBrewer::display.brewer.all() or https://r-graph-gallery.com/38-rcolorbrewers-palettes.html)
colors=(c("Dark2")) #list of string(s); default is 'Dark2'); c("blue4", "darkgreen", "darkgoldenrod", "red2")
)
devtools::document()
devtools::document()
# source("") #string
object <- msmObject(
##### Directories Information (required) ####
home_dir ="/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/",
data_file ="merged_tutorial_filtered.csv", #long dataset
#### Dataset Information (required) ####
#individual identifier
ID = "S_ID", #string
#time points of interest and name of time variable in long dataset
time_pts=c(6, 15, 24, 35, 58), #list of integers
time_var="TAge", #string
#marker for missing data
missing="NA", #string or integer(s)
#list out all variables that are time-varying; including ANY variables collected at only a single time point (with missin for other time points )
time_varying_variables= c("ALI_Le","SAAmylase", "EARS_TJo", "MDI",  "LESMnPos","LESMnNeg", "pcx_engaged", "pcx_CompTwo", "StrDif_Tot", "RHasSO", "WndNbrhood","EF_avg_perc", "IBRAttn","B18Raw", "HOMEETA1","InRatioCor", "ESETA1", "CORTB"),
#list all continuous variables here; all others assumed ordinal for imputation; default is none
continuous_variables=c("PmAge2", "ALI_Le", "SAAmylase", "EARS_Tjo", "IBRAttn", "LESMnPos", "LESMnNeg","B18Raw", "HOMEETA1", "pcx_engaged", "PmMrSt2",
"pcx_CompTwo", "StrDif_Tot", "WndNbrhood", "InRatioCor", "EF_avg_perc", "gov_asst", "mat_health", "peri_health", "ESETA1", "CORTB"),
#list any covariates that are factors here; default is none, or that all variables are continuous
factor_covariates=c("state","TcBlac2", "PmBlac2", "RHasSO"), #list of characters
#### Imputation Specification (optional) ####
#number of imputations for step 4; default is 5
m=5, #integer
imp_method= "rf", #imputation method; pmm, midastouch, sample, cart , rf (default)
#### Exposure Information (required) ####
#exposure of interest that potentially have causal effects on outcome and exposure time point(s) (corresponding to values in time_var)
exposure=c("ESETA1"), #list of strings
exposure_time_pts=c(6, 15, 24, 35, 58), #list of integers corresponding to values in time variable (long ormat)
#### Balancing Information (optional) ###
short_form_lag=1, #integer specifying the maximum time lag for time-varying covariates for the short formula
weights_method="bart", #method for calculating weights: cbps, npcbps, bart, ps
balance_thresh=0.1, #correlation value above which covariates are not considered balanced with respect to exposure/outcome;used for finding potential confounds and asessing balance;
weights_percentile_cutoff=0.95, #percentile cutoff value for truncating weights to avoid heavy tails; default is 0.95;
#### History Comparison Information (required & optional) ####
#developmental time periods (and their corresponding time points) that constitute regime/history units of interest --these should be meaningful periods of time that may collapse over exposure time points to result in more manageable combinations for exploring effects of exposure histories (e.g, chronically high exposure vs. exposure only in infancy) on outcomes
exposure_epochs=data.frame(epochs=c("Infancy", "Toddlerhood", "Childhood"), #user-created names of epochs as a list of strings
values=I(list(c(6,15), c(24,35), c(58)))), #time point(s) encompassed in each epoch that correspond to data as a list of numeric lists
#inspect the following exposure levels denoting all possible histories of high ("h") and low ("l") exposure over the epochs
# apply(gtools::permutations(2, nrow(object$exposure_epochs), c("l", "h"), repeats.allowed=TRUE), 1, paste, sep="", collapse="-")
#select one of the above histories, or permutations of high ("h") and low ("l") levels of exposure (one leve for each of the exposure epochs) as your reference event, or the history/sequence to which you would like to compare the other histories
reference=NA, #optional: set a reference history of high ("h") and low ("l") levels of exposure separate by a "-"; the default is set to the history denoting low ("l") exposure at all time points; character string of "h" and "l" separated by a "-"
comparisons=NA, #optional: set a comparison history from list above; the default is to include all non-reference histories as comparisons; character string of "h" and "l" separated by a "-"
hi_cutoff=.60, #optional integer value for quantile value constituting the threshold for "high" levels of a continuous exposure for outcome modeling; default set to 0.75
lo_cutoff=.30, #optional integer value for quantile value constituting the threshold for "low" levels of a continuous exposure for outcome modeling; default set to 0.25
mc_method="BH", #optional method for multiple comparison correction for linear hypothesis tests; default is Benjamini-Hochburg, options are "holm", "hochberg","hommel", "bonferroni", "BH", "BY", "fdr", "none" (see stats::p.adjust() documentation)
#### Outcome Information (required) ####
#outcome of interest and outcome time point
outcome=c("StrDif_Tot"), #list of strings
outcome_time_pt=58, #integer value
#### Inclusion Information (optional) ####
#list any time-varying variables that you wish to include concurrently in the balancing forms (over-riding default of excluding concurrent time-varying variables as they cannot be distinguished from colliders)
keep_concurrent_tv_vars=NULL,
#### Exclusion Information (optional) ####
#list any time-varying variables that may get imputed but should NOT be present in the final dataset after imputation because hey were not collected at certain times
time_var_exclude=c("ALI_Le.6", "ALI_Le.15","ALI_Le.24","ALI_Le.58","SAAmylase.35", "SAAmylase.58","CORTB.58",
"EARS_TJo.6","EARS_TJo.15", "EARS_TJo.58", "IBRAttn.35", "IBRAttn.58", "MDI.24", "MDI.35", "MDI.58", "LESMnPos.6",
"LESMnPos.15","LESMnPos.58", "LESMnNeg.6", "LESMnNeg.15", "LESMnNeg.58", "B18Raw.35","pcx_engaged.58", "pcx_CompTwo.6", "pcx_CompTwo.15",
"pcx_CompTwo.24", "pcx_CompTwo.35","StrDif_Tot.6", "StrDif_Tot.15","StrDif_Tot.24", "WndNbrhood.15", "EF_avg_perc.6", "EF_avg_perc.15",
"EF_avg_perc.24"), #default set to none
### Plotting Information (optional) ###
#optional list of alternative labels for exposures that will be used only for plotting
exposure_labels=c("Economic Strain"),
#optional list of alternative labels for outcomes that will be used only for plotting
outcome_labels=c("Behavioral Problems"),
#optional string ("h" or "l") denoting which level of exposure at each exposure epoch to use when calculating dose (default is "h")
dose_level="l",
#the plots color data by dose (i.e., number of epochs) of high exposure; optional list of colors (equal to number of epochs +1) or brewer palette (see RColorBrewer::display.brewer.all() or https://r-graph-gallery.com/38-rcolorbrewers-palettes.html)
colors=(c("Dark2")) #list of string(s); default is 'Dark2'); c("blue4", "darkgreen", "darkgoldenrod", "red2")
)
#Creates the necessary directories in your home directory and formats your dataset --coudl embed this in msmObject
data <- formatDataStruct(object) #this function is in the AssessDataStruct.R file
data <- formatDataStruct(object) #this function is in the AssessDataStruct.R file
#identifies the total number covariates available in the dataset and prints them for user inspection
all_potential_covariates <- identifyCovariates(object, data) #this function is in the selectCovariates.R file
data_to_impute <- dataToImpute(object, all_potential_covariates) #this function is in the selectCovariates.R file
imputed_datasets <- imputeData(object, data_to_impute, read_imps_from_file="yes")
imputed_datasets <- imputeData(object, data_to_impute, read_imps_from_file="yes")
imputed_datasets <- imputeData(object, data_to_impute, read_imps_from_file="yes")
imputed_datasets <- imputeData(object, data_to_impute, read_imps_from_file="yes")
imputed_datasets <- imputeData(object, data_to_impute, read_imps_from_file="yes")
imputed_datasets <- imputeData(object, data_to_impute, read_imps_from_file="yes")
imputed_datasets <- imputeData(object, data_to_impute, read_imps_from_file="yes")
imputed_datasets <- imputeData(object, data_to_impute, read_imps_from_file="yes")
wide_long_datasets <- formatForWeights(object, data, imputed_datasets)
full_forms <- createForms(object, wide_long_datasets, all_potential_covariates)
traceback()
View(wide_long_datasets)
View(data)
View(imputed_datasets)
load_all()
full_forms <- createForms(object, wide_long_datasets, all_potential_covariates)
vars_to_include=c(all_potential_covariates[as.numeric(sapply(strsplit(all_potential_covariates, "\\."), "[", 2))<time #all lagged tv covars only
| is.na(sapply(strsplit(all_potential_covariates, "\\."), "[", 2))]) #inc baseline covars
all_potential_covariates
vars_to_include=c(all_potential_covariates[as.numeric(sapply(strsplit(all_potential_covariates, "\\."), "[", 2))<time #all lagged tv covars only
| is.na(sapply(strsplit(all_potential_covariates, "\\."), "[", 2))]) #inc baseline covars
strsplit(all_potential_covariates, "\\."), "[", 2)
strsplit(all_potential_covariates, "\\.")
sapply(strsplit(all_potential_covariates, "\\."), "[", 2)
as.numeric(sapply(strsplit(all_potential_covariates, "\\."), "[", 2))
time=exposure_time_pts[x]
as.numeric(sapply(strsplit(all_potential_covariates, "\\."), "[", 2))<time
vars_to_include=c(all_potential_covariates[as.numeric(sapply(strsplit(all_potential_covariates, "\\."), "[", 2))<time #all lagged tv covars only
| is.na(sapply(strsplit(all_potential_covariates, "\\."), "[", 2))]) #inc baseline
x>1
vars_to_include=vars_to_include[!vars_to_include %in% c(ID, "WAVE",
time_varying_covariates, #exclude time-varying covariates in long form (already in wide form)
paste(exposure, time, sep="."), #excludes exposure from concurrent time (it is the DV of the balancing form)
apply(expand.grid(time_varying_covariates[!time_varying_covariates %in% keep_concurrent_tv_vars], as.character(time)), 1, paste, sep="", collapse="."),#exclude any time-varying confounders current time point --cannot distinguish from mediators!
# apply(expand.grid(outcome, as.character(time_pts)), 1, paste, sep="", collapse="."), #exclude outcome at current time point
paste(outcome, time, sep="."), #exclude outcome at current time point
apply(expand.grid(outcome, as.character(time_pts[time_pts>time])), 1, paste, sep="", collapse="."),#excludes future outcome
# exclude_covariates[grepl(paste(exposure, time, sep="."), exclude_covariates)==F], #exclude any covariates specified by the user
# exclude_covariates[!exclude_covariates %in% exposure], #exclude any covariates specified by the user (not counting exposure)
time_var_exclude, #exclude any time points that should not be there bc of planned missingness
# concurrent_colliders, #exclude colliders specified at exposure time pt
# apply(expand.grid(colliders, as.character(outcome_time_pt)), 1, paste, sep="", collapse="."), #exclude colliders at outcome time points
# lagged_colliders #any lagged colliders as indicated
)]
vars_to_include=vars_to_include[!vars_to_include %in% c(ID, "WAVE",
time_varying_covariates, #exclude time-varying covariates in long form (already in wide form)
paste(exposure, time, sep="."), #excludes exposure from concurrent time (it is the DV of the balancing form)
apply(expand.grid(time_varying_covariates[!time_varying_covariates %in% keep_concurrent_tv_vars], as.character(time)), 1, paste, sep="", collapse="."),#exclude any time-varying confounders current time point --cannot distinguish from mediators!
# apply(expand.grid(outcome, as.character(time_pts)), 1, paste, sep="", collapse="."), #exclude outcome at current time point
paste(outcome, time, sep="."), #exclude outcome at current time point
apply(expand.grid(outcome, as.character(time_pts[time_pts>time])), 1, paste, sep="", collapse="."),#excludes future outcome
# exclude_covariates[grepl(paste(exposure, time, sep="."), exclude_covariates)==F], #exclude any covariates specified by the user
# exclude_covariates[!exclude_covariates %in% exposure], #exclude any covariates specified by the user (not counting exposure)
time_var_exclude #exclude any time points that should not be there bc of planned missingness
# concurrent_colliders, #exclude colliders specified at exposure time pt
# apply(expand.grid(colliders, as.character(outcome_time_pt)), 1, paste, sep="", collapse="."), #exclude colliders at outcome time points
# lagged_colliders #any lagged colliders as indicated
)]
load_all()
full_forms <- createForms(object, wide_long_datasets, all_potential_covariates)
preBalanceChecking(object, wide_long_datasets, full_forms, histories=0)
traceback()
load_all()
preBalanceChecking(object, wide_long_datasets, full_forms, histories=0)
load_all()
short_forms <- createShortForms(object, full_forms, keep=NULL)
object$weights_method="npcbps" #iterate through different weights methods and re-run
data_for_model_with_weights<- createWeights(object, wide_long_datasets, short_forms, read_in_from_file="yes")
balance_stats <- assessBalance(object, short_forms, data_for_model_with_weights, histories=0)
load_all()
short_forms <- createShortForms(object, full_forms, keep=NULL)
balance_stats_full <- assessBalance(object, full_forms, data_for_model_with_weights, histories=0)
new_short_forms <- updateForms(object, short_forms, data_for_model_with_weights, balance_stats_full)
data_for_model_with_weights<- createWeights(object, wide_long_datasets, new_short_forms, read_in_from_file="yes")
balance_stats_final <- assessBalance(object, full_forms, data_for_model_with_weights, histories=0)
data_for_model_with_weights_cutoff <- truncateWeights(object, data_for_model_with_weights)
load_all()
data_for_model_with_weights_cutoff <- truncateWeights(object, data_for_model_with_weights)
load_all()
data_for_model_with_weights_cutoff <- truncateWeights(object, data_for_model_with_weights)
load_all()
data_for_model_with_weights_cutoff <- truncateWeights(object, data_for_model_with_weights)
all_models <- fitModel(object, data_for_model_with_weights_cutoff, balance_stats_final, model="m1")
