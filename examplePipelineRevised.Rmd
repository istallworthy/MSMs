---
title: "exampleTutorialRevised"
author: "Isa Stallworthy"
date: "`r Sys.Date()`"
output: html_document
---

Recommended workflow for using the devMSMs package with longitudinal data.

Step-by-step guidance in the Supplement: 
https://docs.google.com/document/d/1WQGtfYAF4e6mREl5_fSgvmSG7nBzvT6w_iVQgROeAno/edit?pli=1, starting around page 11. 

Goals of this round of testing:
- make sure functions run with your data using both minimal and optional inputs
- assess the user output in the console and the items saved out from each function
- make sure the Supplement provides sufficient detail for running this .rmd file

A note on running functions in R. 
For the required arguments  (e.g., arg1, arg2) in a function, you can supply them directly to the function as variables in your global environment.
arg1 = 8
arg2 = 9.5
E.g., function(arg1, arg2).

For optional arguments (e.g., arg3) in a function, you should assign them with an = to indicate to the function that they are being specified. 
arg3 = 4.5
E.g., function(arg1, arg2, arg3 = arg3)
or 
E.g., function(arg1, arg2, arg3 = 4.5)

In the chunks throughout this rmd, I show an example for running the function with all the optional inputs (all inputs) and one with just the required inputs (minimum inputs). Would love help figuring out which examples to use in our empirical data/supplement.

Please use the Supplement and/or type ?functionName into the console for more guidance on required vs optional arguments for each function. These two sources should match but let me know if you see discrepancies. 

PLEASE Slack me right away with any issues or confusion you encounter --there will likely be bumps in the road as we test this!
Feel free to put feedback in your version of this .rmd, in the notes Google doc, or in the Supplement as comments. 


## Getting started
```{r}

#install devtools
install.packages("devtools")
library(devtools)


#get devMSMs from github
install_github("istallworthy/devMSMs")
library(devMSMs)

#get helper files from github
install_github("istallworthy/devMSMsHelpers")
library(devMSMsHelpers)

#note: if I update Github to fix something, you may need to first uninstall deveMSMs by running the following code:
# remove.packages("devMSMs") or remove.packages("devMSMsHelpers")
#prior to re-installing using the code above. Sorry, this is annoying!

#conducting package checks & tests from documentation --just for IS to run; comment out when testing the workflow
# devtools::check()
```


## Specifying Required Package Core Inputs
```{r}

# The user should change all fields in this code chunk to match their wide data.

set.seed(1234)

home_dir <- '/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/isa' #no / after

exposure <- "ESETA1"

exposure_time_pts <- c(6, 15, 24, 35, 58)

outcome <- "EF_avg_perc.58"

tv_confounders <- c("SAAmylase.6","SAAmylase.15", "SAAmylase.24",
                    "MDI.6", "MDI.15",                                            
                    # "RHasSO.6", "RHasSO.15", "RHasSO.24", #removed for low variability 
                    "RHasSO.35", "RHasSO.58",                                         
                    "WndNbrhood.6","WndNbrhood.24", "WndNbrhood.35", "WndNbrhood.58",                                       
                    "IBRAttn.6", "IBRAttn.15", "IBRAttn.24",                                   
                    "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58",                                           
                    "HOMEETA1.6", "HOMEETA1.15", "HOMEETA1.24", "HOMEETA1.35", "HOMEETA1.58",                               
                    "InRatioCor.6", "InRatioCor.15", "InRatioCor.24", "InRatioCor.35", "InRatioCor.58",                                 
                    "ESETA1.6", "ESETA1.15", "ESETA1.24", "ESETA1.35", "ESETA1.58",                                         
                    "CORTB.6", "CORTB.15", "CORTB.24",                                                                                
                    "EARS_TJo.24", "EARS_TJo.35",                                        
                    "LESMnPos.24", "LESMnPos.35",                                  
                    "LESMnNeg.24", "LESMnNeg.35",       
                    "ALI_Le.35",
                    "StrDif_Tot.35", "StrDif_Tot.58",   
                    "EF_avg_perc.35", "EF_avg_perc.58") 

ti_confounders <- c("state", "BioDadInHH2", "PmAge2", "PmBlac2", "TcBlac2", "PmMrSt2", "PmEd2", "KFASTScr",
                    "RMomAgeU", "RHealth", "HomeOwnd", "SWghtLB", "SurpPreg", "SmokTotl", "DrnkFreq",
                    "peri_health", "mat_health", "gov_asst") 

```


## Read in a single .csv file 
At this stage, data can be in long or wide format, complete or incomplete. 
```{r}

# data <- read.csv("/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/meriah/imputations/ESETA1-CORTB.154_imp1.csv") #change this to match your folder

#reading a long data file here for use in subsequent steps
data_long <- read.csv("/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/merged_tutorial_filtered.csv", header = TRUE)


```



## STEP P: Preliminary Steps for Reading in, Formatting, & Inspecting Data
Choose from the following preliminary steps to assign to 'data' one of the following for use in the package:
- a single data frame of data in wide format with no missing data 
- a mids object (output from mice::mice()) of data imputed in wide format
- a list of data imputed in wide format

Data columns shoudl be either numeric or factor form. Note that at present, the code can only take factors with 2 levels. 

### P1. Format Data
#### P1a. Format single data frame of long data 
```{r}

# if you have long data with wrong time, id, and/or missing indicators and need to format
data_long_f <- formatLongData(home_dir, data_long, exposure, exposure_time_pts, outcome, tv_confounders, 
                            time_var = "TAge", #list original time variable here if it's not "WAVE"
                            id_var = "S_ID", #list original id variable here if it's not "ID"
                            missing = NA, #list missing value here
                            factor_confounders = c("state","TcBlac2", "PmBlac2", "RHasSO"),
                            save.out = TRUE) #list factor variables here


# #making exposure binary for testing purposes only 
# a <- as.numeric(unlist(data_long_f %>% select(contains(exposure))))
# data_long_f[, colnames(data_long_f) %in% exposure] <- as.factor(ifelse(a > median(a, na.rm = TRUE), 1, 0))

```

#### P1b. Convert single data frame from long to wide format
```{r}

v <- sapply(strsplit(tv_confounders, "\\."), "[", 1)
v <- v[!duplicated(v)]
data_wide <- stats::reshape(data = data_long_f, 
                            idvar = "ID", #list ID variable
                            v.names = v, 
                            timevar = "WAVE", # list time variable
                            times = c(6, 15, 24, 35, 58), # exhaustive list of all time points in data 
                            direction = "wide")
data_wide <- data_wide[,colSums(is.na(data_wide)) < nrow(data_wide)]


#removing vars w/no variability; specific to FLP data 
data_wide <- data_wide %>% dplyr::select(-c(RHasSO.6, RHasSO.15 , RHasSO.24))


#if you have no missing data and want to use the package with a single wide data frame
data <- data_wide

```


### P2. Impute Data to Account for Missingness
#### P2a. Multiply impute single wide data frame using mice
```{r}

#impute wide data w/ mice
m <- 1 
method <- "pmm"; # provide an imputation method pmm, midastouch, sample, cart , rf (default)

imputed_data <- imputeData(data_wide, m, method, home_dir, exposure, outcome, 
                           para_proc = TRUE, read_imps_from_file = "no", save.out = TRUE)


#if you want to use the package with imputed data
data <- imputed_data



#OR, read in a saved mids object
imputed_data <- readRDS(paste0(home_dir, "/imputed_data.rds")) #place your .rds file in your home directory and change the name of file here

#if you want to use the package with imputed data
data <- imputed_data



#optional: extract first imputed dataset for testing
library(mice)
data <- mice::complete(imputed_data, 1) #just for testing purposes
data$"PmMrSt2" = as.factor(data$"PmMrSt2")
# library(dplyr)
# data <- data %>%
#   dplyr::select(-c(contains(c(":", "Childhood", "Infancy", "Toddlerhood", "pcx")))) #removing these --came from old dataset

```


#### P2b. Read in wide imputed data saved locally as .csvs
```{r}

#read in imputed csv files to list
folder <- "/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/isa/imputations/" #change this to match your local folder
files <- list.files(folder, full.names = TRUE, pattern = "\\.csv")


#if you want to use the package with a list of imputed data from above
data <- lapply(files, function(file) {
  imp_data <- read.csv(file)
  imp_data
})

```


### P3. Optional: Identify Exposure Epochs
```{r}

#change this to match your data/theory 
epochs <- data.frame(epochs=c("Infancy", 
                              "Toddlerhood", 
                              "Childhood"), 
                     values=I(list(c(6,15), 
                                   c(24,35), 
                                   c(58)
                     ))) 

```


### P4. Recommended: Specify and Inspect Exposure Histories
#### P4a. Create cutoff values for continuous exposures
```{r}

#optional list of quantiles specifying high and low cutoff values, respectively, for continuous exposures; default is median
hi_lo_cut <- c(0.6, 0.3)

```

#### P4b. Specify hyotheses-relevant exposure histories
```{r}

#optional reference history (required if comparisons are specified)
reference <- NA 
reference <- "l-l-l"

#optional comparison history/histories
comparison <- NULL 
comparison <- "h-h-h" #single
comparison <- c("h-h-h", "h-h-l") #multiple

```

#### P4c. Inspect exposure histories
```{r}

#all inputs
inspectData(data, home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, #required input
            epochs, hi_lo_cut, reference, comparison, verbose = TRUE, save.out = TRUE) #optional input


#or some optional inputs
inspectData(data, home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders,
            hi_lo_cut = hi_lo_cut) #assign w/ = any subset of optional inputs


#or minimum inputs
inspectData(data, home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders)

```



## PHASE 1: Balance Confounders

### STEP 1: Pre-Balance Checking
#### 1a. Create full formulas
```{r}

#optional concurrent confounders
concur_conf = NULL 
concur_conf = "B18Raw.15"

#optional custom formulas
custom <- NULL
#note: below is an example of just one of the entries in the list of a custom formula --you would need to make a list that contains entries for each exposure time point that mimics the output of createFormulas. <--Run createFormulas to see what output looks like 
custom <- list(formulas = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_asst + HomeOwnd + KFASTScr + ...
                                     mat_health + peri_health + PmAge2 + PmBlac2 + PmEd2 + PmMrSt2 + RHealth +...
                                     RMomAgeU + SmokTotl + state + SurpPreg + SWghtLB + TcBlac2"))
names(custom) <-c("full_form-6")
custom <- full_formulas


#required
type = "full"

#all inputs
full_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type, 
                                concur_conf = concur_conf, keep_conf = NULL, custom = custom, verbose = TRUE, save.out = TRUE)

#or minimum inputs
full_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type)

```

#### 1b. Exploratory prebalance assessment
```{r}

#optional balance threshold specification
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) 

#optional list of important confounders
imp_conf <- NULL
imp_conf <- c("PmAge2", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58") 

#required
type <- "prebalance"
formulas <- full_formulas

#all inputs
prebalance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome,  tv_confounders, type, formulas, 
                                  balance_thresh = balance_thresh, imp_conf = imp_conf, verbose = TRUE, save.out = TRUE)

#or minimum inputs
prebalance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome,  tv_confounders, type, formulas)

```


### STEP 2: Determine optimal weighting method
#### 2a. Create short formulas
```{r}

#optional list of concurrent confounder
concur_conf <-  NULL 
concur_conf <- "B18Raw.15"

#optional list of tv confounders to always retain (lag t-1)
keep_conf  <-  NULL 
keep_conf <- "InRatioCor.6"

#optional custom formulas
custom <- list(formulas = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_asst + HomeOwnd + KFASTScr + ...
                                     mat_health + peri_health + PmAge2 + PmBlac2 + PmEd2 + PmMrSt2 + RHealth +...
                                     RMomAgeU + SmokTotl + state + SurpPreg + SWghtLB + TcBlac2"))
names(custom) <-c("full_form-6")
custom <- short_formulas
custom <- NULL


#required
type <- "short" 

#all inputs
short_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type, 
                                 concur_conf = concur_conf, keep_conf = keep_conf, custom = custom, verbose = TRUE, save.out = TRUE)

#or minimum inputs
short_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type)

```

#### 2b. Create weights with all weighting methods
```{r}

## Create balancing weights with simplified formulas

#required
formulas <- short_formulas

# optional weighting method "ps", "glm", "gbm", "bart", "super", "cbps"  (default is cbps)
method = "ps"; 

#all input
weights.ps <- createWeights(home_dir, data, exposure, outcome, formulas, 
                            method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

#or minimum input
weights.ps <- createWeights(home_dir, data, exposure, outcome, formulas)



method = "cbps"
weights.cbps <- createWeights(home_dir, data, exposure, outcome, formulas, 
                              method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

method = "glm"
weights.glm <- createWeights(home_dir, data, exposure, outcome, formulas, 
                             method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

method = "gbm"
weights.gbm <- createWeights(home_dir, data, exposure, outcome, formulas, 
                             method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

method = "bart"
weights.bart <- createWeights(home_dir, data, exposure, outcome, formulas, 
                              method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

method = "super"
SL.library = "SL.glm" #required for superLearner method; see SuperLearner::listWrappers() for options
weights.super <- createWeights(home_dir, data, exposure, outcome, formulas, 
                               method, read_in_from_file = "no", SL.library = SL.library, verbose = FALSE, save.out = TRUE)

```

#### 2c. Assess all weighting methods
```{r}

#optional balance threshold specification
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) 

#optional list of important confounders
imp_conf <- c("PmAge2", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58") 
imp_conf <- NULL


#required
type <- "weighted"
formulas <- short_formulas

weights <- weights.ps 


#all inputs
balance_stats.ps <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                    balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

#minimum inputs
balance_stats.ps <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights)


weights <- weights.cbps 
balance_stats.cbps <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                  balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

weights <- weights.glm 
balance_stats.glm <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                   balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

weights <- weights.gbm
balance_stats.gbm <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                   balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

weights <- weights.bart
balance_stats.bart <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                    balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

weights <- weights.super 
balance_stats.super <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                     balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

```


### STEP 3: Re-specify weights using optimal weighting method
#### 3a. Assess balance using full formulas
```{r}

#optional balance threshold specification
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) 

#optional list of important confounders
imp_conf <- NULL
imp_conf <- c("PmAge2", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58") 


#required
type <- "weighted"
formulas <- full_formulas

weights <- weights.ps

#all inputs
balance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                               balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

#minimum inputs
balance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights)

```

#### 3b. Update short formulas 
```{r}

#optional custom formulas
custom <- list(formulas = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_asst + HomeOwnd + KFASTScr +  mat_health + peri_health + PmAge2 + PmBlac2 + PmEd2 + PmMrSt2 + RHealth + RMomAgeU + SmokTotl + state + SurpPreg + SWghtLB + TcBlac2"))
names(custom) <-c("full_form-6")
custom <- updated_formulas
custom <- NULL

#optional list of concurrent confounder
concur_conf <-  NULL 
concur_conf <- "B18Raw.15"

#optional list of tv confounders to always retain (lag t-1)
keep_conf <- NULL 
keep_conf <- "InRatioCor.6"


#required
type <- "update"
bal_stats <- balance_stats

#all inputs
updated_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type, bal_stats, 
                                   concur_conf, keep_conf, verbose = TRUE, save.out = TRUE)

#minimum inputs
updated_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type, bal_stats)

```

#### 3c. Re-create weights
```{r}

#required
formulas <- updated_formulas

method <- "ps"

#all inputs
final_weights <- createWeights(home_dir, data, exposure, outcome, formulas, 
                               method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

#minimum inputs
final_weights <- createWeights(home_dir, data, exposure, outcome, formulas)

```

#### 3d. Truncate weights
##### Main
```{r}

# optional quantile of weights above which weights are trimmed (default is 0.95)
quantile <- 0.95 

#required
weights <- final_weights


#all inputs
trim_weights <- trimWeights(home_dir, exposure, outcome, weights, 
                            quantile, verbose = TRUE, save.out = TRUE)

#minimum inputs
trim_weights <- trimWeights(home_dir, exposure, outcome, weights)

```
##### Sensitvity analyses
```{r}

#sensitivity tests   
quantile <- 0.92 #optional quantile of weights above which weights are trimmed (default is 0.95)
trim_weights.s1 <- trimWeights(home_dir, exposure, outcome, weights, quantile, 
                               verbose = TRUE, save.out = TRUE) 

quantile <- 0.98 #optional quantile of weights above which weights are trimmed (default is 0.95)
trim_weights.s2 <- trimWeights(home_dir, exposure, outcome, weights, quantile, 
                               verbose = TRUE, save.out = TRUE) 

```


### STEP 4: Final Balance Assessment
#### Main
```{r}

#optional balance threshold specification
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) 

#optional list of important confounders
imp_conf <- c("PmAge2", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58") 
imp_conf <- NULL

#required
type <- "weighted"
formulas <- full_formulas
weights <- trim_weights


#all input
final_balance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                     balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE) 

#minimum input
final_balance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights)

```
#### Sensitvity analyses
```{r}

#sensitivity tests
weights <- trim_weights.s1
final_balance_stats.s1 <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                        balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE) 

weights <- trim_weights.s2
final_balance_stats.s2 <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                        balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE) 

```


## PHASE 2: Assess Substantive Associations between Exposure and Outcome

### STEP 5: Fit marginal structural model & summarize results
#### 5a. Fit marginal structural model
##### Main
```{r}

#optional family/link information for glm
family <- gaussian 
link <- "identity" 

# max interaction order (required for interaction models m2-3)
int_order = 3
int_order = NA

#covariates (required for covariate models m1, m3)
covariates <- c("ESETA1.6", "gov_asst", "B18Raw.6") 
covariates = NULL

#optional specification of epochs
epochs <- data.frame(epochs=c("Infancy", "Toddlerhood", "Childhood"), 
                     values=I(list(c(6,15), c(24,35), c(58)))) 


#required
weights <- trim_weights


# all inputs
#required
model <- "m3"
models <- fitModel(home_dir, data, weights, exposure, exposure_time_pts, outcome, model, 
                   family, link, int_order, covariates, epochs, verbose = TRUE, save.out = TRUE)   

#minimum inputs
model <- "m0"
models <- fitModel(home_dir, data, weights, exposure, exposure_time_pts, outcome, model)

#some optional inputs
models <- fitModel(home_dir, data, weights, exposure, exposure_time_pts, outcome, model,
                   int_order = int_order)

```
##### Sensitvity analyses
```{r}

#sensitivity tests
weights <- trim_weights.s1
models.s1 <- fitModel(home_dir, data, weights, exposure, exposure_time_pts, outcome, model, 
                      family, link, int_order, covariates, epochs, verbose = TRUE, save.out = TRUE) 

weights <- trim_weights.s2
models.s2 <- fitModel(home_dir, data, weights, exposure, exposure_time_pts, outcome, model, 
                      family, link, int_order, covariates, epochs, verbose = TRUE, save.out = TRUE) 

```

#### 5b. Estimate, compare, & visualize histories
##### Main
```{r}

#optional specification of epochs; only specify this if you did in model fitting (5a) --must be identical
epochs <- data.frame(epochs=c("Infancy", "Toddlerhood", "Childhood"), 
                     values=I(list(c(6,15), c(24,35), c(58)))) 

#optional list of quantiles specifying high and low cutoff values for continuous exposures; 
hi_lo_cut <- c(0.6, 0.3) #default are median split

#optional reference history (required if comparisons are specified)
reference <- NA 
reference <- "l-l-l"

#optional comparison history/historis
comparison <- NULL 
comparison <- "h-h-h" #single
comparison <- c("h-h-h", "h-h-l") #multiple

#optional multiple comparion method
mc_comp_method <- "bonferroni" # default is Benjamini-Hochburg, ("holm", "hochberg","hommel", "bonferroni", "BH", "BY", "fdr", "none" (see stats::p.adjust() documentation)

#optional specification of dose level (high or low) for dose count
dose_level <- "h" #(default is "h")

#optional exposure label for plotting
exp_lab <- "Economic Strain" 

#optional outcome label for plotting 
out_lab <- "Executive Functioning" 

# optional list of colors (equal to number of epochs +1) or brewer palette for plotting
colors <- c("Dark2")  #(see RColorBrewer::display.brewer.all() or https://r-graph-gallery.com/38-rcolorbrewers-palettes.html) for plotting default is 'Dark2'); 
colors <- c("blue4", "darkgreen", "darkgoldenrod", "red2") #list number-of-epochs-+1 colors


#required
model <- models #output from fitModel


#all inputs
results <- compareHistories(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, model, 
                            epochs, hi_lo_cut, reference, comparison, mc_comp_method , dose_level, exp_lab, out_lab, colors, verbose = FALSE, save.out = TRUE) 


#minimum inputs
reference <- "l-l-l-l-l"
comparison <- c("h-h-h-h-h", "l-h-h-h-h") #multiple
results <- compareHistories(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, model,
                            reference = reference, comparison = comparison) # for our data, specify ref and comp bc too many comparisons for exposure time point; 

```
##### Sensitvity analyses
```{r}

#sensitivity tests
model <- models.s1 
results.s1 <- compareHistories(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, model, 
                               epochs, hi_lo_cut, reference, comparison, mc_comp_method , dose_level, exp_lab, out_lab, colors, verbose = TRUE, save.out = TRUE) 

model <- models.s2 
results.s2 <- compareHistories(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, model, 
                               epochs, hi_lo_cut, reference, comparison, mc_comp_method , dose_level, exp_lab, out_lab, colors, verbose = TRUE, save.out = TRUE) 

```


## Package citations :) 
```{r}

grateful::cite_packages(out.dir = home_dir, omit = "devMSMs", include.Rstudio = TRUE, out.format = "docx")

```

