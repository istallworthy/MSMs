---
title: "exampleTutorialRevised"
author: "Isa Stallworthy"
date: "`r Sys.Date()`"
output: html_document
---


Recommended workflow for using the devMSMs package with longitudinal data.

Step-by-step guidance in the Supplement: 
https://docs.google.com/document/d/1WQGtfYAF4e6mREl5_fSgvmSG7nBzvT6w_iVQgROeAno/edit?pli=1, starting around page 11. 


### Getting started
```{r}

#install devtools
install.packages("devtools")
library(devtools)


#get devMSMs from github
install_github("istallworthy/devMSMs")
library(devMSMs)

```


### P1. Specifying Package Core Inputs
```{r}

# Github: https://github.com/istallworthy/devMSMs

library(devtools)
library(roxygen2)
load_all()


home_dir <- '/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/isa' #no / after

exposure <- "ESETA1"

exposure_time_pts <- c(6, 15, 24, 35, 58)

outcome <- "EF_avg_perc.58"

tv_confounders <- c("SAAmylase.6","SAAmylase.15", "SAAmylase.24",
                    "MDI.6", "MDI.15",                                            
                    # "pcx_engaged.6","pcx_engaged.15", "pcx_engaged.24", "pcx_engaged.35", "pcx_CompTwo.58",
                    "RHasSO.6", "RHasSO.15", "RHasSO.24", "RHasSO.35", "RHasSO.58",                                           
                    "WndNbrhood.6","WndNbrhood.24", "WndNbrhood.35", "WndNbrhood.58",                                       
                    "IBRAttn.6", "IBRAttn.15", "IBRAttn.24",                                   
                    "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58",                                           
                    "HOMEETA1.6", "HOMEETA1.15", "HOMEETA1.24", "HOMEETA1.35", "HOMEETA1.58",                                       
                    "InRatioCor.6", "InRatioCor.15", "InRatioCor.24", "InRatioCor.35", "InRatioCor.58",                                 
                    "ESETA1.6", "ESETA1.15", "ESETA1.24", "ESETA1.35", "ESETA1.58",                                         
                    "CORTB.6", "CORTB.15", "CORTB.24",                                                                                
                    "EARS_TJo.24", "EARS_TJo.35",                                        
                    "LESMnPos.24", "LESMnPos.35",                                  
                    "LESMnNeg.24", "LESMnNeg.35",       
                    "ALI_Le.35",
                    "StrDif_Tot.35", "StrDif_Tot.58",   
                    "EF_avg_perc.35", "EF_avg_perc.58") 

ti_confounders <- c("state", "BioDadInHH2", "PmAge2", "PmBlac2", "TcBlac2", "PmMrSt2", "PmEd2", "KFASTScr",
                    "RMomAgeU", "RHealth", "HomeOwnd", "SWghtLB", "SurpPreg", "SmokTotl", "DrnkFreq",
                    "peri_health", "mat_health", "gov_asst") 

```


### Testing data (this is just for our purposes)
```{r}
data_orig <- read.csv("/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/merged_tutorial_filtered.csv", header = TRUE)
# 
data_orig <- data_orig %>%   select(-c(contains(":")))

#example mids imputed data
# saveRDS(imputed_data, file = file.path(home_dir, "imputed_data.rds"))
data_mids <- readRDS(paste0(home_dir, "/imputed_data.rds"))

#example path to imputed data
# data_path <- "/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/imputations/"

library(dplyr)
data_df <- data_mids[[1]]
data_df <- data_df %>% dplyr::select(-c(contains(c(":", "Childhood", "Infancy", "Toddlerhood", "pcx"))))

data <- data_df #single df
data <- data_mids #'imputed' data
```


### Preliminary steps (optional)
#### If you have wide data ....
```{r}
#### P2. Data Formatting
#optional function to format long data data
data_long <- formatLongData(home_dir, data_orig, exposure, exposure_time_pts, outcome, tv_confounders, 
                            time_var = "TAge", 
                            id_var = "S_ID", 
                            missing = NA, 
                            factor_confounders = c("state","TcBlac2", "PmBlac2", "RHasSO"))

  

#format data from long to wide
v <- sapply(strsplit(tv_confounders, "\\."), "[",1)
v <- v[!duplicated(v)]
data_wide <- stats::reshape(data = data_long, 
                            idvar = "ID", 
                            v.names = v, 
                            timevar = "WAVE", 
                            times = c(6, 15, 24, 35, 58), 
                            direction = "wide")
data_wide <- data_wide[,colSums(is.na(data_wide)) < nrow(data_wide)]




#### P5 Optional Imputation

#impute wide data to account for missingness
data_wide = data_wide[, !colnames(data_wide) %in% c("RHasSO.6","RHasSO.15", "RHasSO.24")]
m <- 1
method <- "pmm"; #pmm, midastouch, sample, cart , rf (default)
imputed_data <- imputeData(data_wide, m, method, home_dir, exposure, outcome, tv_confounders, ti_confounders, 
                           para_proc = FALSE, read_imps_from_file = "no")

data = complete(imputed_data, 1)


#read in imputed csv files to list

# List imputed files
folder <- "/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/imputations/"
files <- list.files(folder, full.names = TRUE, pattern = "\\.csv")
# Read and process imputed datasets as list
data <- lapply(files, function(file) {
  imp_data <- readr::read.csv(file)
  imp_data
})


```


### Preliminary recommended data inspection
```{r}
#### P3, P4 Optional Inputs and Inspecting Data
set.seed(1234)

#optional function visualize & summarize confounders with long or wide data either as a single df or imputed (will use imp=0) and view exposure histories 
# can take a single df (wide/long) and will uses first imputation from mids/imp input
epochs <- data.frame(epochs=c("Infancy", 
                              "Toddlerhood", 
                              "Childhood"), 
                     values=I(list(c(6,15), c(24,35), c(58)))) 

#optional list of quantiles specifying high and low cutoff values for continuous expsures; default is median
hi_lo_cut <- c(0.6, 0.3)

#optional reference history (required if comparisons are specified)
reference <- NA #optional reference history for custom comparisons (e.g, "l-l-l") 
reference <- "l-l-l"

#optional comparison history/histories
comparison <- NULL 
comparison <- "h-h-h" #single
comparison <- c("h-h-h", "h-h-l") #multiple

#all inputs
inspectData(data, home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, #required input
            epochs, hi_lo_cut, reference, comparison, verbose = TRUE, save.out = TRUE) #optional input

#minimum inputs
inspectData(data, home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders)

```


## PHASE 1: Balance Confounders

### STEP 1: Pre-Balance Checking
#### 1a. Create full formulas
```{r}

#optional concurrent confounders
concur_conf = NULL 
concur_conf = "B18Raw.15"

#optional custom formulas
custom <- NULL
#note: below is an example of just one of the entries in the list of a custom formula --you would need to make a list that contains entries for each exposure time point that mimicks the output of createFormulas. <--Run that to see what it looks like.
custom <- list(formulas = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_asst + HomeOwnd + KFASTScr +  mat_health + peri_health + PmAge2 + PmBlac2 + PmEd2 + PmMrSt2 + RHealth + RMomAgeU + SmokTotl + state + SurpPreg + SWghtLB + TcBlac2"))
names(custom) <-c("full_form_ESETA1-EF_avg_perc.58-6")
custom <- full_formulas


type = "full"

#all inputs
full_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type, 
                                concur_conf = concur_conf, keep_conf = NULL, custom = custom, verbose = TRUE, save.out = TRUE)

#minimum inputs
full_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type)
```

#### 1b. Exploratory prebalance assessment
```{r}

#optional balance threshold specification
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) 

#optional list of important confounders
imp_conf <- NULL
imp_conf <- c("PmAge2", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58") 


type <- "prebalance"
formulas <- full_formulas

#all inputs
prebalance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome,  tv_confounders, type, formulas, 
                                  balance_thresh = balance_thresh, imp_conf = imp_conf, verbose = TRUE, save.out = TRUE)

#minimum inputs
prebalance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome,  tv_confounders, type, formulas)

```


### STEP 2: Determine optimal weighting method
#### 2a. Create short formulas
```{r}

#optional list of concurrent confounder
concur_conf <-  NULL 
concur_conf <- "B18Raw.15"

#optional list of tv confounders to always retain (lag t-1)
keep_conf  <-  NULL 
keep_conf <- "InRatioCor.6"

#optional custom formulas
custom <- list(formulas = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_asst + HomeOwnd + KFASTScr +  mat_health + peri_health + PmAge2 + PmBlac2 + PmEd2 + PmMrSt2 + RHealth + RMomAgeU + SmokTotl + state + SurpPreg + SWghtLB + TcBlac2"))
names(custom) <-c("short_form_ESETA1-EF_avg_perc.58-6")
custom <- short_formulas
custom <- NULL


type <- "short" 

#all inputs
short_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type, 
                                 concur_conf = concur_conf, keep_conf = keep_conf, custom = custom, verbose = TRUE, save.out = TRUE)

#minimum inputs
short_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type)

```

#### 2b. Create weights with all weighting methods
```{r}

## Create balancing weights with simplified formulas
formulas <- short_formulas

method = "ps"; # optional weighting method "ps", "glm", "gbm", "bart", "super", "cbps"  (default is cbps)

#all input
weights.ps <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, 
                            method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

#minimum input
weights.cbps <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas)



method = "cbps"
weights.cbps <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, 
                              method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

method = "glm"
weights.glm <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, 
                             method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

method = "gbm"
weights.gbm <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, 
                             method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

method = "bart"
weights.bart <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, 
                              method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

method = "super"
weights.super <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, 
                               method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)
```

#### 2c. Assess all weighting methods
```{r}

#optional balance threshold specification
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) 

#optional list of important confounders
imp_conf <- c("PmAge2", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58") 
imp_conf <- NULL

type <- "weighted"
formulas <- short_formulas

weights <- weights.cbps 

#all inputs
balance_stats.cbps <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                  balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

#minimum inputs
balance_stats.cbps <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights)


weights <- weights.ps 
balance_stats.ps <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                    balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

weights <- weights.glm 
balance_stats.glm <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                   balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

weights <- weights.gbm
balance_stats.gbm <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                   balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

weights <- weights.bart
balance_stats.bart <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                    balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

weights <- weights.super 
balance_stats.super <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                     balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

```


### STEP 3: Re-specify weights using optimal weighting method
#### 3a. Assess balance using full formulas
```{r}

#optional balance threshold specification
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) 

#optional list of important confounders
imp_conf <- NULL
imp_conf <- c("PmAge2", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58") 


type <- "weighted"
formulas <- full_formulas
weights <- weights.cbps

#all inputs
balance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                               balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE)

#minimum inputs
balance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights)

```

#### 3b. Update short formulas 
```{r}

#optional custom formulas
custom <- list(formulas = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_asst + HomeOwnd + KFASTScr +  mat_health + peri_health + PmAge2 + PmBlac2 + PmEd2 + PmMrSt2 + RHealth + RMomAgeU + SmokTotl + state + SurpPreg + SWghtLB + TcBlac2"))
names(custom) <-c("update_form_ESETA1-EF_avg_perc.58-6")
custom <- updated_formulas
custom <- NULL

#optional list of concurrent confounder
concur_conf <-  NULL 
concur_conf <- "B18Raw.15"

#optional list of tv confounders to always retain (lag t-1)
keep_conf <- NULL 
keep_conf <- "InRatioCor.6"

type <- "update"
bal_stats <- balance_stats

#all inputs
updated_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type, bal_stats, 
                                   concur_conf, keep_conf, verbose = TRUE, save.out = TRUE)

#minimum inputs
updated_formulas <- createFormulas(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, ti_confounders, type, bal_stats)

```

#### 3c. Re-create weights
```{r}

formulas <- updated_formulas
method <- "cbps"

#all inputs
final_weights <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, 
                               method, read_in_from_file = "no", verbose = TRUE, save.out = TRUE)

#minimum inputs
final_weights <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas)

```

#### 3d. Truncate weights
```{r}
quantile <- 0.95 # optional quantile of weights above which weights are trimmed (default is 0.95)

weights <- final_weights

#all inputs
trim_weights <- trimWeights(home_dir, exposure, outcome, weights, 
                            quantile, verbose = TRUE, save.out = TRUE)

#minimum inputs
trim_weights <- trimWeights(home_dir, exposure, outcome, weights)
                            
                            
#sensitivity tests   
quantile <- 0.92 #optional quantile of weights above which weights are trimmed (default is 0.95)
trim_weights.s1 <- trimWeights(home_dir, exposure, outcome, weights, quantile, 
                               verbose = TRUE, save.out = TRUE) 

quantile <- 0.98 #optional quantile of weights above which weights are trimmed (default is 0.95)
trim_weights.s2 <- trimWeights(home_dir, exposure, outcome, weights, quantile, 
                               verbose = TRUE, save.out = TRUE) 

```


### STEP 4: Final Balance Assessment
```{r}

#optional balance threshold specification
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) 

#optional list of important confounders
imp_conf <- c("PmAge2", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58") 
imp_conf <- NULL

type <- "weighted"
formulas <- full_formulas
weights <- trim_weights

#all input
final_balance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                     balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE) 

#minimum input
final_balance_stats <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights)
                                     

#sensitivity tests
weights <- trim_weights.s1
final_balance_stats.s1 <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                        balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE) 

weights <- trim_weights.s2
final_balance_stats.s2 <- assessBalance(home_dir, data, exposure, exposure_time_pts, outcome, tv_confounders, type, formulas, weights, 
                                        balance_thresh, imp_conf, verbose = TRUE, save.out = TRUE) 

```


## PHASE 2: Assess Substantive Associations between Exposure and Outcome

### STEP 5: Fit marginal structural model & summarize results
#### 5a. Fit marginal structural model
```{r}

#optional family/link information for glm
family <- gaussian 
link <- "identity" 

# max interaction order (required for interaction models m2-3)
int_order = 3
int_order = NA

#covariates (required for covariate models m1, m3)
covariates <- c("ESETA1.6", "gov_asst", "B18Raw.6") 
covariates = NULL

#optional specification of epochs
epochs <- data.frame(epochs=c("Infancy", "Toddlerhood", "Childhood"), 
                             values=I(list(c(6,15), c(24,35), c(58)))) 


weights <- trim_weights

# all inputs
model <- "m3"
models <- fitModel(home_dir, data, weights, exposure, exposure_time_pts, outcome, tv_confounders, model, 
                   family, link, int_order, covariates, epochs, verbose = TRUE, save.out = TRUE)   

#minimum inputs
model <- "m0"
models <- fitModel(home_dir, data, weights, exposure, exposure_time_pts, outcome, tv_confounders, model)


#sensitivity tests
weights <- trim_weights.s1
models.s1 <- fitModel(home_dir, data, weights, exposure, exposure_time_pts, outcome, tv_confounders, model, 
                      family, link, int_order, covariates, epochs, verbose = TRUE, save.out = TRUE) 

weights <- trim_weights.s2
models.s2 <- fitModel(home_dir, data, weights, exposure, exposure_time_pts, outcome, tv_confounders, model, 
                      family, link, int_order, covariates, epochs, verbose = TRUE, save.out = TRUE) 

```

#### 5b. Estimate, compare, & visualize histories
```{r}

#optional specification of epochs; only specify this if you did in model fitting (5a) --must be identical
epochs <- data.frame(epochs=c("Infancy", "Toddlerhood", "Childhood"), 
                             values=I(list(c(6,15), c(24,35), c(58)))) 

#optional list of quantiles specifying high and low cutoff values for continuous exposures; 
hi_lo_cut <- c(0.6, 0.3) #default are median split

#optional reference history (required if comparisons are specified)
reference <- NA 
reference <- "l-l-l"

#optional comparison history/historis
comparison <- NULL 
comparison <- "h-h-h" #single
comparison <- c("h-h-h", "h-h-l") #multiple

#optional multiple comparion method
mc_comp_method<- "bonferroni" # default is Benjamini-Hochburg, ("holm", "hochberg","hommel", "bonferroni", "BH", "BY", "fdr", "none" (see stats::p.adjust() documentation)
  
#optional specification of dose level (high or low) for dose count
dose_level <- "h" #(default is "h")

#optional exposure label for plotting
exp_lab <- "Economic Strain" 
rm(exp_lab)

#optional outcome label for plotting 
out_lab <- "Executive Functioning" 

# optional list of colors (equal to number of epochs +1) or brewer palette for plotting
colors <- c("Dark2")  #(see RColorBrewer::display.brewer.all() or https://r-graph-gallery.com/38-rcolorbrewers-palettes.html) for plotting default is 'Dark2'); 
colors <- c("blue4", "darkgreen", "darkgoldenrod", "red2")


model <- models #output from fitModel

#all inputs
results <- compareHistories(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, model, 
                            epochs, hi_lo_cut, reference, comparison, mc_comp_method , dose_level, exp_lab, out_lab, colors, verbose = TRUE, save.out = TRUE) 

#minimum inputs
reference <- "l-l-l-l-l"
comparison <- c("h-h-h-h-h", "l-h-h-h-h") #multiple
results <- compareHistories(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, model,
                            reference = reference, comparison = comparison) # for our data, specify ref and comp bc too many comparisons for exposure time point; 

#sensitivity tests
model <- models.s1 #output from fitModel
results.s1 <- compareHistories(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, model, 
                               epochs, hi_lo_cut, reference, comparison, mc_comp_method , dose_level, exp_lab, out_lab, colors, verbose = TRUE, save.out = TRUE) 

model <- models.s2 #output from fitModel
results.s2 <- compareHistories(home_dir, exposure, exposure_time_pts, outcome, tv_confounders, model, 
                               epochs, hi_lo_cut, reference, comparison, mc_comp_method , dose_level, exp_lab, out_lab, colors, verbose = TRUE, save.out = TRUE) 

```

Package citations
```{r}
grateful::cite_packages(out.dir = home_dir, omit = "devMSMs", include.Rstudio = TRUE, out.format = "docx")
```

