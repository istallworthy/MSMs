---
title: "exampleTutorialRevised"
author: "Isa Stallworthy"
date: "`r Sys.Date()`"
output: html_document
---


Recommended workflow for using the devMSMs package with longitudinal data.

data can be a single dataframe, mids object, or folder of imputed datasets in wide format labeled 0-k (0=or)), with the first column as an ID column for the subject identifier, missing values as NA, and continuous/factor variables appropriately classed.
All time-varying variables must be named in the format of the variable name and time point separated by a period, var.t (e.g., income.6) and should include exposure and outcome variables. 
Exposure should be listed without the time point(s). Exposure time points are assumed to equal or fully encompass time time points of all other covariates. 
Outcome should be listed followed by a period and the outcome time point (e.g., EF.58)
All functions will have the option to output user guidance in the console or not
Home directory will be working directory
Assumes time-varying confounders time points are equal to (or a subset of) the time points at which the exposure was measured

### Core inputs
```{r}
<<<<<<< HEAD
<<<<<<< Updated upstream
=======
library(devtools)
library(roxygen2)

home_dir <- '/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing'

>>>>>>> Stashed changes
=======

home_dir <- '/Users/isabella/Desktop/BSL Lab/MSMs/Tutorial paper/testing'

>>>>>>> main
exposure <- "ESETA1"
outcome <- "EF_avg_perc.58"

tv_confounders <- c("SAAmylase.6","SAAmylase.15", "SAAmylase.24",
                    "MDI.6", "MDI.15",                                            
                    "pcx_engaged.6","pcx_engaged.15", "pcx_engaged.24", "pcx_engaged.35", "pcx_CompTwo.58",                                       
                    "RHasSO.6", "RHasSO.15", "RHasSO.24", "RHasSO.35", "RHasSO.58",                                           
                    "WndNbrhood.6","WndNbrhood.24", "WndNbrhood.35", "WndNbrhood.58",                                       
                    "IBRAttn.6", "IBRAttn.15", "IBRAttn.24",                                   
                    "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58",                                           
                    "HOMEETA1.6", "HOMEETA1.15", "HOMEETA1.24", "HOMEETA1.35", "HOMEETA1.58",                                       
                    "InRatioCor.6", "InRatioCor.15", "InRatioCor.24", "InRatioCor.35", "InRatioCor.58",                                      
                    "ESETA1.6", "ESETA1.15", "ESETA1.24", "ESETA1.35", "ESETA1.58",                                         
                    "CORTB.6", "CORTB.15", "CORTB.24",                                                                                
                    "EARS_TJo.24", "EARS_TJo.35",                                        
                    "LESMnPos.24", "LESMnPos.35",                                  
                    "LESMnNeg.24", "LESMnNeg.35",       
                    "ALI_Le.35",
                    "StrDif_Tot.35", "StrDif_Tot.58",   
                    "EF_avg_perc.35", "EF_avg_perc.58") 

ti_confounders <- c("state", "BioDadInHH2", "PmAge2", "PmBlac2", "TcBlac2", "PmMrSt2", "PmEd2", "KFASTScr",
                    "RMomAgeU", "RHealth", "HomeOwnd", "SWghtLB", "SurpPreg", "SmokTotl", "DrnkFreq",
                    "peri_health", "mat_health", "gov_asst") 

```

### Testing data
```{r}
data_orig <- read_csv("/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/merged_tutorial_filtered.csv")
data_long <- data_orig
```


### Preliminary steps (optional)
```{r}

#optional function to format long data data
data_long <- formatLongData(home_dir, 
                            data_long, 
                            exposure, 
                            outcome, 
                            tv_confounders, 
                            time_var = "TAge", 
                            id_var = "S_ID", 
                            missing = NA, 
                            factor_confounders = c("state","TcBlac2", "PmBlac2", "RHasSO"))

  
#optional function visualize & summarize confounders with long or wide data either as a single df or imputed (will use imp=0) and view exposure histories 
# can take a single df (wide/long) and will uses first imputation from mids/imp input
epochs <- data.frame(epochs=c("Infancy", 
                              "Toddlerhood", 
                              "Childhood"), # optional subsetting of time points into more coarse epochs that will constitute exposure  histories
                     values=I(list(c(6,15), c(24,35), c(58)))) 
hi_lo_cut <- c(0.6, 0.3) #optional list of quantiles specifying high and low cutoff values for continuous expsures; default are c(0.75, 0.25)
inspectData(data_long, home_dir, exposure, outcome, tv_confounders, ti_confounders, epochs, hi_lo_cut)
# inspectConfounders(data_wide, home_dir, exposure, outcome, tv_confounders, ti_confounders, epochs, hi_lo_cut)
# inspectConfounders(data_mids, home_dir, exposure, outcome, tv_confounders, ti_confounders, epochs, hi_lo_cut)
# inspectConfounders(data_path, home_dir, exposure, outcome, tv_confounders, ti_confounders, epochs, hi_lo_cut)


#format data from long to wide for imputation
v <- sapply(strsplit(tv_confounders, "\\."), "[",1)
v <- v[!duplicated(v)]
data_wide <- stats::reshape(data = data_long, 
                            idvar = "ID", 
                            v.names = v, 
                            timevar = "WAVE", 
                            times = c(6,15,24,35,58), 
                            direction = "wide")
data_wide <- data_wide[,colSums(is.na(data_wide))<nrow(data_wide)]


#impute wide data to account for missingness
m <- 5
method <- "rf"; #pmm, midastouch, sample, cart , rf (default)
imputed_data <- imputeData(data_wide, m, method, home_dir, exposure, outcome, tv_confounders, ti_confounders, read_imps_from_file="no")

 
data <- imputed
```


### Pre-balance checking
```{r}

## Create full formulas
concur_conf = NA #optional list of time-varying confounders (var.t) to include in formulas concurrently (default is only lagged); exposure variables will be omitted at concurrent time poin
keep_conf = NA #optional list of any time-varying confounders to always retain in all formulas at lag-1t (deafult is none)
bal_stats = NA #output from balance checking, only if type = "update"
type = "full" # "full" =all tv covars; "short" =only t-1 tv covars; "update" = update short forms w/ imbalanced tv covars t>1
<<<<<<< HEAD
<<<<<<< Updated upstream
full_formulas <- createFormulas(exposure, outcome, tv_confounders, ti_confounders, type, bal_stats, concur_conf, keep_conf, ug=F )
=======
full_formulas <- createFormulas(home_dir, exposure, outcome, tv_confounders, ti_confounders, type, bal_stats, concur_conf, keep_conf, custom = NULL, ug = F )
>>>>>>> Stashed changes
=======
full_formulas <- createFormulas(home_dir, exposure, outcome, tv_confounders, ti_confounders, type, bal_stats, concur_conf, keep_conf, ug=F )
>>>>>>> main


imp_conf <- NULL
balance_thresh <- c(0.05) 

## Conduct exploratory pre-balance checking
type <- "prebalance"
formulas <- full_formulas
<<<<<<< Updated upstream
balance_thresh <- 0.1 #optional threshold below which confounders are considered imbalanced (corr or smd); default is 0.1
<<<<<<< HEAD
prebalance_stats <- assessBalance(data, exposure, outcome, tv_confounders, type, formulas, weights = NULL, balance_thresh)
=======
# custom <- list(formulas = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_asst + HomeOwnd + KFASTScr +  mat_health + peri_health + PmAge2 + PmBlac2 + PmEd2 + PmMrSt2 + RHealth + RMomAgeU + 
#                                     SmokTotl + state + SurpPreg + SWghtLB + TcBlac2"))
# names(custom) <-c("full_form_ESETA1-EF_avg_perc.58-6")
imp_conf <- c("PmAge2", "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58") #optional list of important confounders that will be held to a stricter balance thresh
balance_thresh <- c(0.05, 0.1) #optional list of balance thresholds for importnt & less important confoundres, respectively; one entry will be applied to all confounders; default is 0.1 for all
prebalance_stats <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights = NULL, balance_thresh, imp_conf)
>>>>>>> Stashed changes
=======
prebalance_stats <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights = NULL, balance_thresh)
>>>>>>> main

```


### Determine optimal weighting method
```{r}

## Create simplified formulas
concur_conf = NA #optional list of time-varying confounders (var.t) to include in formulas concurrently (default is only lagged); exposure variables will be omitted at concurrent time point 
keep_conf = NA #optional list of any time-varying confounders to always retain in all formulas at lag-1 (deafault is none)
bal_stats = NA #output from balance checking only if type = "update"
type = "short" # "full" =all tv covars; "short" =only t-1 tv covars; "update" = update short forms w/ imbalanced tv covars t>1
short_formulas <- createFormulas(home_dir, exposure, outcome, tv_confounders, ti_confounders, type, bal_stats, concur_conf, keep_conf, ug=F )


## Create balancing weights with simplified formulas
formulas= short_formulas
<<<<<<< HEAD
<<<<<<< Updated upstream
method = "cbps"; # optional weighting method "glm", "gbm", "bart", "super", "cbp (default is cbps)
weights <- createWeights(data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 
=======

method = "ps"; # optional weighting method "glm", "gbm", "bart", "super", "cbps"  (default is cbps)
weights.ps <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 

=======
>>>>>>> main
method = "cbps"; # optional weighting method "glm", "gbm", "bart", "super", "cbps"  (default is cbps)
weights.cbps <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 

method = "glm"; # optional weighting method "glm", "gbm", "bart", "super", "cbps" (default is cbps)
weights.glm <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 

method = "gbm"; # optional weighting method "glm", "gbm", "bart", "super", "cbps"  (default is cbps)
weights.gbm <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 

method = "bart"; # optional weighting method "glm", "gbm", "bart", "super", "cbps"  (default is cbps)
weights.bart <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 

method = "super"; # optional weighting method "glm", "gbm", "bart", "super", "cbps" (default is cbps)
weights.super <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 
<<<<<<< HEAD
>>>>>>> Stashed changes
=======
>>>>>>> main


## Assess balance using simplified formulas
type <- "weighted"
<<<<<<< HEAD
formulas <- short_formulas
<<<<<<< Updated upstream
weights <- weights 
=======
>>>>>>> main
balance_thresh <- 0.1 #optional threshold below which confounders are considered imbalanced (corr or smd); default is 0.1
formulas <- short_formulas
weights <- weights.cbps 
balance_stats.cbps <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- weights.glm 
balance_stats.glm <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- weights.gbm
balance_stats.gbm <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- weights.bart
balance_stats.bart <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- weights.super 
balance_stats.super <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)


## Iterate through creating weights/assessing balance for all possible weights methods to identify the best one 
formulas= short_formulas
method = "cbps"; # optional weighting method "glm", "gbm", "bart", "super", "cbp (default is cbps)
<<<<<<< HEAD
best_method_weights <-createWeights(data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 
=======
weights <- weights.ps 
balance_stats.ps <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- weights.cbps 
balance_stats.cbps <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- weights.glm 
balance_stats.glm <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- weights.gbm
balance_stats.gbm <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- weights.bart
balance_stats.bart <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- weights.super 
balance_stats.super <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)


## Iterate through creating weights/assessing balance for all possible weights methods to identify the best one 
formulas= short_formulas
method = "cbps"; # optional weighting method "ps" glm", "gbm", "bart", "super", "cbp (default is cbps)
best_method_weights <-createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 
>>>>>>> Stashed changes
=======
best_method_weights <-createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 
>>>>>>> main

```


### Re-specify weights using optimal method
```{r}

## Assess balance of optimal weights using full formulas
type <- "weighted"
formulas <- full_formulas
weights <- best_method_weights
balance_thresh <- 0.1 #optional threshold below which confounders are considered imbalanced (corr or smd); default is 0.1
balance_stats <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)


## Update short formulas with any t->1 tv confounders that were not balanced
concur_conf = NA #optional list of time-varying confounders (var.t) to include in formulas concurrently (default is only lagged)
keep_conf = NA #optional list of any time-varying confounders (var.t) to always retain in all formulas at lag-1; exposure variables will be omitted at concurrent time point (default is none)
bal_stats = NULL #output from balance checking only if type = "update"
type = "update" # "full" =all tv covars; "short" =only t-1 tv covars; "update" = update short forms w/ imbalanced tv covars t>1
bal_stats = balance_stats
updated_formulas <- createFormulas(home_dir, exposure, outcome, tv_confounders, ti_confounders, type, bal_stats, concur_conf, keep_conf, ug = F ) #not sure if it's necessary but ug=T for more user output/guidance?


# Re-specify weights with optimal method an dupdated formulas 
formulas= final_formulas
method = "cbps"; # optional weighting method "glm", "gbm", "bart", "super", "cbp (default is cbps)
final_weights <- createWeights(home_dir, data, exposure, outcome, tv_confounders, formulas, method, read_in_from_file = "no") 


# Truncate weights to reduce heavy tails --
weights <- final_weights
quantile <- 0.95 # optional quantile of weights above which weights are trimmed (default is 0.95)
<<<<<<< HEAD
<<<<<<< Updated upstream
trim_weights <- trimWeights(final_weights, quantile) #this is just a wrapper function for the trim function to allow for summaries and plotting
=======
trim_weights <- trimWeights(home_dir, final_weights, quantile) #this is just a wrapper function for the trim function to allow for summaries and plotting
>>>>>>> main

#sensitivity tests   
quantile <- 0.92 #optional quantile of weights above which weights are trimmed (default is 0.95)
trim_weights.s1 <- trimWeights(home_dir, final_weights, quantile) #this is just a wrapper function for the trim function to allow for summaries and plotting

quantile <- 0.98 #optional quantile of weights above which weights are trimmed (default is 0.95)
<<<<<<< HEAD
trim_weights.s2 <- trimWeights(final_weights, quantile) #this is just a wrapper function for the trim function to allow for summaries and plotting
=======
trim_weights <- trimWeights(home_dir, weights, quantile) #this is just a wrapper function for the trim function to allow for summaries and plotting

#sensitivity tests   
quantile <- 0.92 #optional quantile of weights above which weights are trimmed (default is 0.95)
trim_weights.s1 <- trimWeights(home_dir, weights, quantile) #this is just a wrapper function for the trim function to allow for summaries and plotting

quantile <- 0.98 #optional quantile of weights above which weights are trimmed (default is 0.95)
trim_weights.s2 <- trimWeights(home_dir, weights, quantile) #this is just a wrapper function for the trim function to allow for summaries and plotting
>>>>>>> Stashed changes
=======
trim_weights.s2 <- trimWeights(home_dir, final_weights, quantile) #this is just a wrapper function for the trim function to allow for summaries and plotting
>>>>>>> main

```


### Final balance assessment
```{r}

## Assess balance of final, trimmed weights 
type <- "weighted"
formulas <- full_formulas
balance_thresh <- 0.1 #optional threshold below which confounders are considered imbalanced (corr or smd); default is 0.1
weights <- trim_weights
final_balance_stats <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

#sensitivity tests
weights <- trim_weights.s1
final_balance_stats.s1 <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

weights <- trim_weights.s2
final_balance_stats.s2 <- assessBalance(home_dir, data, exposure, outcome, tv_confounders, type, formulas, weights, balance_thresh)

```


### Fit marginal structural model & summarize
```{r}

## Fit marginal structural model of user's choice
model <- "m0"
# *m0:Baseline model regressing the outcome on the main effects of exposure at each exposure epoch (e.g., infancy, toddlerhood, childhood)
# *m1: Covariate model regressing the outcome on the main effects of exposure at each exposure epoch as well as any covariate confounders measured at baseline that remained imbalanced after weighting
# *m2: Interaction model regressing the outcome on the main effects of exposure at each exposure epoch as well as all interactions between exposure epochs (e.g., infancy:toddlerhood)
# *m3: Full model regressing the outcome on the main effects of exposure at each exposure epoch, all baseline covariate confounders that remained imbalanced, as well as all exposure epoch interactions (default).
<<<<<<< Updated upstream
family <- NA #optional family reflective of outcome distribution
link <- NA #optional link function
<<<<<<< HEAD
covariates <- NA #optional list of covariates (e.g., those remaining imbalanced) for covariate models (m1, m3)
=======
family <- gaussian #optional family reflective of outcome distribution
link <- "identity" #optional link function
int_order = NA
covariates <- c("KFASTScr", "SWghtLB", "ESETA1.6") #optional list of covariates (e.g., those remaining imbalanced) for covariate models (m1, m3)
>>>>>>> Stashed changes
=======
covariates <- c("KFASTScr", "SWghtLB", "ESETA1.24") #optional list of covariates (e.g., those remaining imbalanced) for covariate models (m1, m3)
>>>>>>> main
epochs <- data.frame(epochs=c("Infancy", "Toddlerhood", "Childhood"), # optional subsetting of time points into more coarse epochs 
                             values=I(list(c(6,15), c(24,35), c(58)))) 

weights <- trim_weights
<<<<<<< HEAD
<<<<<<< Updated upstream
model <- fitModel(data, weights, exposure, outcome, model, family, link, covariates, epochs)  
=======
model <- fitModel(home_dir, data, weights, exposure, outcome, tv_confounders, model, family, link, int_order, covariates, epochs)  
>>>>>>> main

#sensitivity tests
weights <- trim_weights.s1
model.s1 <- fitModel(home_dir, data, weights, exposure, outcome, model, family, link, covariates, epochs)  

weights <- trim_weights.s2
<<<<<<< HEAD
model.s2 <- fitModel(data, weights, exposure, outcome, model, family, link, covariates, epochs)  
=======
models <- fitModel(home_dir, data, weights, exposure, outcome, tv_confounders, model, family, link, int_order, covariates, epochs)


#sensitivity tests
weights <- trim_weights.s1
model.s1 <- fitModel(home_dir, data, weights, exposure, outcome, tv_confounders, model, family, link, int_order, covariates, epochs)

weights <- trim_weights.s2
model.s2 <- fitModel(home_dir, data, weights, exposure, outcome, tv_confounders, model, family, link, int_order, covariates, epochs)
>>>>>>> Stashed changes
=======
model.s2 <- fitModel(home_dir, data, weights, exposure, outcome, model, family, link, covariates, epochs)  
>>>>>>> main



## Estimate, compare, & visualize effects of exposure histories on outcome
hi_lo_cut <- c(0.6, 0.3) #optional list of quantiles specifying high and low cutoff values for continuous exposures; default are c(0.75, 0.25)
ref <- NA #optional reference history for custom comparisons (e.g, "l-l-l") (must be specified if comp is specified)
comp <- NA #optional list of histories/history for custom comparisons (e.g., c("h-h-h", "h-h-l")) (deafult is all comparisons)
mc_method <- #optional specification of mc method; default is Benjamini-Hochburg, ("holm", "hochberg","hommel", "bonferroni", "BH", "BY", "fdr", "none" (see stats::p.adjust() documentation)
dose_lev <- "l" #optional specification of dose level to tally for dose count (default is "h")
exp_labe <- "Economic Strain" #optional exposure label for plotting (default is var name)
out_lab <- "Executive Functioning" #optional outcome label for plotting (default is var name)
 colors=(c("Dark2")) # optional list of colors (equal to number of epochs +1) or brewer palette (see RColorBrewer::display.brewer.all() or https://r-graph-gallery.com/38-rcolorbrewers-palettes.html) for plotting default is 'Dark2'); c("blue4", "darkgreen", "darkgoldenrod", "red2")
model <- model #output from fitModel
results <- compareHistories(home_dir, data, model, hi_lo_cut, ref, comp, mc_comp_method, dose_lev, exp_lab, out_lab, colors )

#sensitivity tests
model <- model.s1 #output from fitModel
results.s1 <- compareHistories(home_dir, data, model, hi_lo_cut, ref, comp, mc_comp_method, dose_lev, exp_lab, out_lab, colors )

model <- model.s2 #output from fitModel
results.s2 <- compareHistories(home_dir, data, model, hi_lo_cut, ref, comp, mc_comp_method, dose_lev, exp_lab, out_lab, colors )

```


