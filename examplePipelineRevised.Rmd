---
title: "Recommended Workflow for using devMSMs with Longitudinal Data"
author: "Isabella C. Stallworthy", "Meriah L. DeJoseph", "Emily R. Padrutt", "Noah Greifer", "Daniel Berry"
date: "`r Sys.Date()`"
output: html_document
---

This workflow supplements the manuscript, xxxx. Please see this manuscript for a full conceptual and practical introduction to MSMs in the context of developmental data. 

There is step-by-step guidance to this workflow and details about each function in the Supplement: 
https://docs.google.com/document/d/1WQGtfYAF4e6mREl5_fSgvmSG7nBzvT6w_iVQgROeAno/edit?pli=1, starting around page 11. 


***Goals of this round of testing:
- make sure functions run with your data using both minimal and optional inputs
- assess the user output in the console and the items saved out from each function
- make sure the Supplement provides sufficient detail for running the entirety of this .rmd file
***

The code in each code chunk is set up identifying all possible inputs to each function (required and optional) to aid the user's use of the full range of package functionality. Example possible values for the optional input are shown for each function, including a NULL/NA option if the user does not wish to specify an optional input. The user should select one of each optional input values. Alternatively, the user could modify the call to the function and remove the optional input argument(s) entirely. 

Please use the Supplement and/or type ?functionName into the console for more guidance on the arguments for each function. These two sources should match but let me know if you see discrepancies. 

***PLEASE Slack me right away with any issues or confusion you encounter --there will likely be bumps in the road as we test this!
Feel free to put feedback on the Slack channel, in the notes Google doc, or in the Supplement as comments. 
***

## Getting started
Until devMSMs is available on CRAN, you will need to install it directly from Github. 
You will always need to install the devMSMs helper functions from Github (devMSMsHelpers) if you wish to conduct the preliminary steps below. 

```{r}

#first, install devtools
install.packages("devtools")
library(devtools)

#install devMSMs from github
install_github("istallworthy/devMSMs")
library(devMSMs)

#install helper files from github. Note: you need to install devMSMs for devMSMsHelpers::inspectData() to work. 
install_github("istallworthy/devMSMsHelpers")
library(devMSMsHelpers)

#note: if I update Github to fix something, you may need to first uninstall the package(s) by running the following code:
# remove.packages("devMSMs") or 
# remove.packages("devMSMsHelpers")
#prior to re-installing using the code above. Sorry, this is annoying! There may also be a short lag between when I update something on Github and when it becomes available for install. 

#conducting package checks & tests from documentation --just for IS to run; comment out when testing the workflow
#devtools::check()
```


## Specifying Required Package Core Inputs
The user should change all fields in this code chunk to match their home directory and wide data.

```{r}

#set seed for reproducibility 
set.seed(1234)

#required if you wish to use save.out = TRUE in the functions
home_dir <- NA
home_dir <- '/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/isa' #note: no / after

#required
exposure <- "ESETA1"

#required
exposure_time_pts <- c(6, 15, 24, 35, 58)

#required
outcome <- "StrDif_Tot.58"

#required; list in wide format
tv_confounders <- c("SAAmylase.6","SAAmylase.15", "SAAmylase.24",
                    "MDI.6", "MDI.15",                                            
                    "RHasSO.6", "RHasSO.15", "RHasSO.24","RHasSO.35", "RHasSO.58",                                         
                    "WndNbrhood.6","WndNbrhood.24", "WndNbrhood.35", "WndNbrhood.58",                                       
                    "IBRAttn.6", "IBRAttn.15", "IBRAttn.24",                                   
                    "B18Raw.6", "B18Raw.15", "B18Raw.24", "B18Raw.58",                                           
                    "HOMEETA1.6", "HOMEETA1.15", "HOMEETA1.24", "HOMEETA1.35", "HOMEETA1.58",                               
                    "InRatioCor.6", "InRatioCor.15", "InRatioCor.24", "InRatioCor.35", "InRatioCor.58",                         
                    "ESETA1.6", "ESETA1.15", "ESETA1.24", "ESETA1.35", "ESETA1.58",  #exposure variables required               
                    "CORTB.6", "CORTB.15", "CORTB.24",                                                                  
                    "EARS_TJo.24", "EARS_TJo.35",                                        
                    "LESMnPos.24", "LESMnPos.35",                                  
                    "LESMnNeg.24", "LESMnNeg.35",       
                    "StrDif_Tot.35", "StrDif_Tot.58",    
                    "fscore.35", "fscore.58"
                    # , "ESETA1.6:B18Raw.6", "ESETA1.6:B18Raw.15:RHasSO.6", "state:EARS_TJo.35" #testing interactions
) 

#required
ti_confounders <- c("state", "BioDadInHH2", "PmAge2", "PmBlac2", "TcBlac2", "PmMrSt2", "PmEd2", "KFASTScr",
                    "RMomAgeU", "RHealth", "HomeOwnd", "SWghtLB", "SurpPreg", "SmokTotl", "DrnkFreq",
                    "peri_health", "caregiv_health", "gov_assist"
                    #, "state:SmokTotl", "PmAge2:PmBlac2", "PmAge2:PmEd2" #testing interaction terms
)
```


## STEP P: Preliminary Steps for Reading in, Formatting, & Inspecting Data
Choose from the following preliminary steps with the goal of assigning to 'data' one of the following for use in the package:
- a single data frame of data in wide format with no missing data 
- a mids object (output from mice::mice()) of data imputed in wide format
- a list of data imputed in wide format as data frames

Data columns should be either numeric or factor form and the ID column should be numeric.


### P1. Format Data
#### P1a. Format single data frame of long data 
These data can be complete or have missingness. 

```{r}

#reading a long data file here for use in subsequent steps
data_long <- read.csv("/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/testing data/continuous outcome/continuous exposure/FLP_long_missing_unformatted.csv", #add path to your long data file here if you want to begin with long data
                      header = TRUE)


#check for character variables
any(sapply(data_long, class) == "character") #if this is TRUE, run next lines
names(data_long)[sapply(data_long, class) == "character"] #find names of any character variables
data_long[, "state"] <- factor(data_long[, "state"], labels = c(1, 0)) #run this for each variable that needs char -> factor


# if you have long data with wrong time, id, and/or missing indicators and need to format
data_long_f <- formatLongData(data = data_long, exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, 
                              time_var = "Tage", #list original time variable here if it's not "WAVE"
                              id_var = "S_ID", #list original id variable here if it's not "ID"
                              missing = -9999, #list missing value here
                              factor_confounders = c("state", "TcBlac2","BioDadInHH2","HomeOwnd", "PmBlac2",       
                                                     "PmMrSt2", "SurpPreg", "RHealth", "SmokTotl", "DrnkFreq",
                                                     "RHasSO"), #list factor variables in long format here
                              home_dir = home_dir, save.out = TRUE) 

```


#### P1b. Convert single long data frame to wide format

```{r}

v <- sapply(strsplit(tv_confounders[!grepl("\\:", tv_confounders)], "\\."), "[", 1)
v <- v[!duplicated(v)]
library(stats)
data_wide <- stats::reshape(data = data_long_f, 
                            idvar = "ID", #list ID variable in your dataset
                            v.names = v, 
                            timevar = "WAVE", # list time variable in your long dataset
                            times = c(6, 15, 24, 35, 58), # list all time points in your dataset
                            direction = "wide")
data_wide <- data_wide[, colSums(is.na(data_wide)) < nrow(data_wide)]



# read in formatted wide data with missing values
data_wide <- read.csv("/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/merged_tutorial_filtered.csv", #add path to your wide, formatted data file here 
                      header = TRUE)


#check for character variables
any(sapply(data_wide, class) == "character") #if this is TRUE, run next lines
names(data_wide)[sapply(data_wide, class) == "character"] #find names of any character variables
data_wide[, "state"] <- factor(data_wide[, "state"], labels = c(1, 0)) #run this for each variable that needs char -> factor

#make factor variables factor 
factor_covars <- c("state", "TcBlac2","BioDadInHH2","HomeOwnd", "PmBlac2",       
                   "PmMrSt2", "SurpPreg", "RHealth", "SmokTotl", "DrnkFreq",
                   "RHasSO.6", "RHasSO.15", "RHasSO.24", "RHasSO.35", "RHasSO.58")
data_wide[, factor_covars] <- as.data.frame(lapply(data_wide[, factor_covars], as.factor))


#or, read in from rds to preserve variable classes
data_wide <- readRDS("/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/merged_tutorial_filtered.rds" )


#if you have no missing data and want to use the package with a single wide data frame
data <- data_wide

```


### P2. Impute Data to Account for Missingness
#### P2a. Multiply impute single wide, formatted data frame using mice

```{r}

#optional; number of imputations (default is 5)
m <- NA
m <- 5 #empirical example

#optional; provide an imputation method pmm, midastouch, sample, cart , rf (default)
method <- NA
method <- "rf" #empirical example

#optional maximum iterations for imputation (default is 5)
maxit <- NA
maxit <- 5 #empirical example

#optional
#please see the mice::mice() documentation for more optimal input to customize mice(): https://www.rdocumentation.org/packages/mice/versions/3.16.0/topics/mice


imputed_data <- imputeData(data = data_wide, exposure = exposure, outcome = outcome, 
                           m = m, method = method, maxit = maxit, para_proc = FALSE, read_imps_from_file = FALSE, 
                           home_dir = home_dir, save.out = TRUE)


#if you want to use the package with imputed data
data <- imputed_data



#OR, read in a saved mids object
imputed_data <- readRDS("/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/testing data/continuous outcome/continuous exposure/FLP_wide_imputed_mids.rds") # final imputations for empirical example; place your .rds file in your home directory and change the name of file here

#if you want to use the package with imputed data
data <- imputed_data



#optional: extract first imputed dataset for testing
library(mice)
data <- mice::complete(imputed_data, 1) #just for testing purposes
anyNA(data) #make sure this is false, meaning no NAs


#read in wide, single imputed dataset
data <- read.csv('/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/testing data/continuous outcome/continuous exposure/FLP_wide_imputed.csv')



#check for character variables
any(sapply(data, class) == "character") #if this is TRUE, run next lines
names(data)[sapply(data, class) == "character"] #find names of any character variables
data[, "state"] <- factor(data[, "state"], labels = c(1, 0)) #run this for each variable that needs char -> factor


#make factors
factor_covars <- c("state", "TcBlac2","BioDadInHH2","HomeOwnd", "PmBlac2",       
                   "PmMrSt2", "SurpPreg", "RHealth", "SmokTotl", "DrnkFreq",
                   "RHasSO.6", "RHasSO.15", "RHasSO.24", "RHasSO.35", "RHasSO.58")
data[, factor_covars] <- as.data.frame(lapply(data[, factor_covars], as.factor))


```


#### P2b. Read in as a list wide imputed data saved locally 

```{r}

#read in imputed csv files to list
folder <- "/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/testing data/continuous outcome/continuous exposure/imputations/" # these are final imputations for empirical example; change this to match your local folder

files <- list.files(folder, full.names = TRUE, pattern = "\\.csv") #make sure pattern matches suffix of your data


#if you want to use the package with a list of imputed data from above
data <- lapply(files, function(file) {
  imp_data <- read.csv(file)
  imp_data
})


#check for character variables
any(as.logical(unlist(lapply(data, function(x) { #if this is TRUE, run next lines
  any(sapply(x, class) == "character") }))))
names(data[[1]])[sapply(data[[1]], class) == "character"] #find names of any character variables
data <- lapply(data, function(x){
  x[, "state"] <- factor(x[, "state"], labels = c(1, 0)) #run this for each variable that needs char -> factor
})


#make factors
factor_covars <- c("state", "TcBlac2","BioDadInHH2","HomeOwnd", "PmBlac2",       
                   "PmMrSt2", "SurpPreg", "RHealth", "SmokTotl", "DrnkFreq",
                   "RHasSO.6", "RHasSO.15", "RHasSO.24", "RHasSO.35", "RHasSO.58")
data <- lapply(data, function(x) {
  x[, factor_covars] <- as.data.frame(lapply(x[, factor_covars], as.factor))
  x })

```




### P3. Optional: Identify Exposure Epochs
If you specify exposure epochs, we recommend doing so consistently throughout this workflow.

```{r}

#change this to match your data/theory 
epochs <- data.frame(epochs = c("Infancy", #list user-specified names
                                "Toddlerhood", 
                                "Childhood"), 
                     values = I(list(c(6, 15), #list corresponding time points from data
                                     c(24, 35), 
                                     c(58)
                     ))) 

```


### P4. Recommended: Specify and Inspect Exposure Histories
#### P4a. Create high an dlow cutoff values for continuous exposures
If you specify high and low cutoffs, we recommend doing so consistently throughout this workflow. 

```{r}

#optional list of quantiles specifying high and low cutoff values, respectively, for continuous exposures; default is median
hi_lo_cut <- c(0.6, 0.3) #empirical example 

```


#### P4b. Specify hypotheses-relevant exposure histories
If you specify reference and comparison histories, please do so consistently throughout this workflow. 

```{r}

#optional reference history (required if comparisons are specified)
reference <- NULL
reference <- "l-l-l" #empirical example final choice
reference <- c("l-l-l", "l-l-h")


#optional comparison history/histories
comparison <- NULL 
comparison <- "h-h-h" #single
comparison <- c("h-h-h", "h-l-l", "l-l-h", "h-h-l", "l-h-h") #empirical example final choice

```


#### P4c. Inspect exposure histories and data

```{r}

inspectData(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, # required input
            ti_confounders = ti_confounders, tv_confounders = tv_confounders, # required input
            epochs = epochs, hi_lo_cut = hi_lo_cut, reference = reference, comparison = comparison, #optional input
            home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional input

```



## PHASE 1: Confounder Adjustment

### STEP 1: Create Full Balancing Formulas & Conduct Pre-Balance Checking

#### 1a. Create full balancing formulas at each exposure time point
If you specify concurrent confounders to retain, we recommend doing so consistently throughout this workflow. 

```{r}

#optional concurrent confounders
concur_conf <- NULL #empirical example 
concur_conf <- "B18Raw.15"


#optional custom formulas
custom <- NULL #empirical example 
#note: below is an example of just two of the entries in the list of a custom formula --you would need to make a list that contains entries for each exposure time point that mimics the output of createFormulas. <--Run createFormulas to see what it should look like.
custom <- list("full_form-6" = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_assist"),
               "full_form-15" = as.formula("ESETA1.15 ~ BioDadInHH2 + DrnkFreq + gov_assist")
) #add warning about future variables 


#required
type <- "full"

#all inputs
full_formulas <- createFormulas(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, #required
                                type = type, ti_confounders = ti_confounders, tv_confounders = tv_confounders, #required
                                concur_conf = concur_conf, custom = custom, #optional
                                home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


#### 1b. Conduct exploratory pre-balance assessment
If you specify balance threshold(s), we recommend doing so consistently throughout this workflow. 

```{r}

#optional balance threshold specification
balance_thresh <- NULL
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) #empirical example 

#optional list of important confounders
imp_conf <- NULL
imp_conf <- c("InRatioCor.6", "InRatioCor.15", "InRatioCor.24", "InRatioCor.35", "InRatioCor.58", "PmEd2") #empirical example 

#required
type <- "prebalance"
formulas <- full_formulas

#all inputs
prebalance_stats <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, 
                                  outcome = outcome, type = type, formulas = formulas, #required
                                  balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                                  home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


### STEP 2: Create Simplified Balancing Formulas & Determine Optimal Weighting Method

#### 2a. Create simplified balancing formulas
If you specify concurrent confounders to retain and/or confounders to keep in these short balancing formulas, we recommend doing so consistently throughout this workflow. 

```{r}

#optional list of concurrent confounder
concur_conf <-  NULL #empirical example 
concur_conf <- "B18Raw.15"

#optional list of tv confounders to always retain (lag t-1)
keep_conf  <-  NULL #empirical example 
keep_conf <- "InRatioCor.6"

#optional custom formulas
custom <- NULL #empirical example 
#note: below is an example of just two of the entries in the list of a custom formula --you would need to make a list that contains entries for each exposure time point that mimics the output of createFormulas. <--Run createFormulas to see what it should look like.
custom <- list("short_form-6" = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_assist"),
               "short_form-15" = as.formula("ESETA1.15 ~ BioDadInHH2 + DrnkFreq + gov_assist")
)


#required
type <- "short" 

#all inputs
short_formulas <- createFormulas(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, #required
                                 type = type, ti_confounders = ti_confounders, tv_confounders = tv_confounders, #required
                                 concur_conf = concur_conf, keep_conf = keep_conf, custom = custom, #optional
                                 home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


#### 2b. Create IPTW balancing weights using multiple weighting methods

```{r}

#required; say what default estimand is in weightitMSM(); some dont work for all methods --add to supplement
formulas <- short_formulas

# optional weighting method "glm", "gbm", "bart", "super", "cbps"  (default is cbps)

method <- "cbps"
weights.cbps <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required
                              method = method, read_in_from_file = FALSE,  #optional
                              # ints = TRUE,  #trying out optional weightitMSM inputs
                              home_dir = home_dir, verbose = TRUE, save.out = TRUE)  #optional

method <- "glm"
weights.glm <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required
                             method = method, read_in_from_file = FALSE, #optional
                             home_dir = home_dir, verbose = TRUE, save.out = TRUE)  #optional

method <- "gbm"
weights.gbm <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required
                             method = method, read_in_from_file = FALSE,  #optional
                             home_dir = home_dir, verbose = TRUE, save.out = TRUE)  #optional
# testing additional arguments
# weights.gbm <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required
#                              method = method, read_in_from_file = FALSE, #optional
#                              home_dir = home_dir, verbose = TRUE, save.out = TRUE, #optional
#                              criterion = "p.max", distribution = "laplace") ##optional; can now add any input that weightitMSM() takes for "gbm

method <- "bart"
weights.bart <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required
                              method = method, read_in_from_file = FALSE, #optional
                              home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

method <- "super"
weights.super <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required
                               method = method, read_in_from_file = FALSE, #optional
                               home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional
# #testing library specification
# weights.super <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required
#                                method = method, read_in_from_file = FALSE, #optional
#                                home_dir = home_dir, verbose = TRUE, save.out = TRUE,
#                                SL.library = "SL.mean") #can now specify SuperLearner library (default is "SL.glm")

```


#### 2c. Assess all weighting methods to determien optimal method
If you specify balance threshold(s), we recommend doing so consistently throughout this workflow. 

```{r}

#optional balance threshold specification
balance_thresh <- NULL
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) #empirical example 

#optional list of important confounders
imp_conf <- NULL
imp_conf <- c("InRatioCor.6", "InRatioCor.15", "InRatioCor.24", "InRatioCor.35", "InRatioCor.58", "PmEd2") #empirical example 

#required
type <- "weighted"
formulas <- short_formulas

weights <- weights.cbps 
balance_stats.cbps <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required
                                    outcome = outcome, type = type, formulas = formulas, weights = weights, #required
                                    balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                                    home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

weights <- weights.glm
balance_stats.glm <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required
                                   outcome = outcome, type = type, formulas = formulas, weights = weights, #required
                                   balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                                   home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional
weights <- weights.gbm
balance_stats.gbm <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required
                                   outcome = outcome, type = type, formulas = formulas, weights = weights, #required
                                   balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                                   home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

weights <- weights.bart
balance_stats.bart <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required
                                    outcome = outcome, type = type, formulas = formulas, weights = weights, #required
                                    balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                                    home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

weights <- weights.super 
balance_stats.super <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required
                                     outcome = outcome, type = type, formulas = formulas, weights = weights, #required
                                     balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                                     home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


### STEP 3: Create Updated Formulas & Re-Specify Weights Using Optimal Weighting Method

#### 3a. Assess balance with full balancing formulas
If you specify balance threshold(s), we recommend doing so consistently throughout this workflow. 

```{r}

#optional balance threshold specification
balance_thresh <- NULL
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1) #empirical example 

#optional list of important confounders
imp_conf <- NULL
imp_conf <- c("InRatioCor.6", "InRatioCor.15", "InRatioCor.24", "InRatioCor.35", "InRatioCor.58", "PmEd2") #empirical example 

#required
type <- "weighted"
formulas <- full_formulas

weights <- weights.cbps

#all inputs
balance_stats <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required
                               outcome = outcome, type = type, formulas = formulas, weights = weights, #required
                               balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                               home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


#### 3b. Update simplified formulas 
If you specify concurrent confounders to retain and/or confounders to keep in balancing formulas, we recommend doing so consistently throughout this workflow. 

```{r}

#optional custom formulas
custom <- NULL #empirical example 
#note: below is an example of just two of the entries in the list of a custom formula --you would need to make a list that contains entries for each exposure time point that mimics the output of createFormulas. <--Run createFormulas to see what it should look like.
custom <- list("update_form-6" = as.formula("ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_assist"),
               "update_form-15" = as.formula("ESETA1.15 ~ BioDadInHH2 + DrnkFreq + gov_assist")
)

#optional list of concurrent confounder
concur_conf <-  NULL #empirical example 
concur_conf <- "B18Raw.15"

#optional list of tv confounders to always retain (lag t-1)
keep_conf <- NULL #empirical example 
keep_conf <- "InRatioCor.6"


#required
type <- "update"
bal_stats <- balance_stats

#all inputs
updated_formulas <- createFormulas(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, #required
                                   type = type, ti_confounders = ti_confounders, tv_confounders = tv_confounders, bal_stats = bal_stats, #required
                                   concur_conf = concur_conf, keep_conf = keep_conf, #optional
                                   home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


#### 3c. Create final balancing weights

```{r}

#required
formulas <- updated_formulas

method <- "cbps"

#all inputs
final_weights <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required
                               method = method, read_in_from_file = FALSE, #optional
                               home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


#### 3d. Trim final balancing weights

##### Main

```{r}

# optional quantile of weights above which weights are trimmed (default is 0.95)
quantile <- NA 
quantile <- 0.95 #empirical example 

#required
weights <- final_weights

#all inputs
trim_weights <- trimWeights(exposure = exposure, outcome = outcome, weights = weights, #required
                            quantile = quantile, #optional
                            home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```

##### Sensitvity analyses

```{r}

quantile <- 0.92 #optional quantile of weights above which weights are trimmed (default is 0.95)
trim_weights.s1 <- trimWeights(exposure = exposure, outcome = outcome, weights = weights, #required
                               quantile = quantile, #optional
                               home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

quantile <- 0.98 #optional quantile of weights above which weights are trimmed (default is 0.95)
trim_weights.s2 <- trimWeights(exposure = exposure, outcome = outcome, weights = weights, #required
                               quantile = quantile, #optional
                               home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


### STEP 4: Conduct Final Balance Assessment

#### Main
If you specify balance threshold(s), we recommend doing so consistently throughout this workflow. 

```{r}

#optional balance threshold specification
balance_thresh <- NULL
balance_thresh <- 0.1 
balance_thresh <- c(0.05, 0.1)  #empirical example 

#optional list of important confounders
imp_conf <- NULL
imp_conf <- c("InRatioCor.6", "InRatioCor.15", "InRatioCor.24", "InRatioCor.35", "InRatioCor.58", "PmEd2") #empirical example 

#required
type <- "weighted"
formulas <- full_formulas
weights <- trim_weights

#all input
final_balance_stats <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required
                                     outcome = outcome, type = type, formulas = formulas, weights = weights, #required
                                     balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                                     home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional


#manually list remaining imbalanced covariates that are time-invariant or time-varying at t=1 for use in Step 5
covariates <- c("ESETA1.6", "InRatioCor.6", "gov_assist", "PMEd2") 

```


#### Sensitvity analyses
We recommend specifying sensitivity analyses to match the main analyses above. 
Note: Please run the above main analysis and then rename or relocate the following output, before running each sensitivity test and renaming/relocating each one in the same manner:

In the balance -> weighted folder, .csv/.html tables of:
- balance statistics
- imbalanced statistics
- overall balance summary

In the balance -> weighted -> plots folder, .jpeg images of:
- summary balance plots

```{r}

#sensitivity tests
weights <- trim_weights.s1
final_balance_stats.s1 <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required
                                        outcome = outcome, type = type, formulas = formulas, weights = weights, #required
                                        balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                                        home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

weights <- trim_weights.s2
final_balance_stats.s2 <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required
                                        outcome = outcome, type = type, formulas = formulas, weights = weights, #required
                                        balance_thresh = balance_thresh, imp_conf = imp_conf, #optional
                                        home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional
```


## PHASE 2: Assess Substantive Associations between Exposure and Outcome

### STEP 5: Fit Marginal Structural Model & Summarize  & Visualize Results

#### 5a. Select and fit a marginal outcome model

##### Main
If you specify exposure epochs, we recommend doing so consistently throughout this workflow. 

```{r}

#optional family/link information for glm
family <- NULL #empirical example
family <- gaussian

link <- NA  #empirical example
link <- "identity" 

# max interaction order (required for interaction models m2-3)
int_order <- NA
int_order <- 2

#covariates (required for covariate models m1, m3)
covariates <- NULL
covariates <- imbalanced_covariates 
covariates <- c("ESETA1.6", "gov_assist", "B18Raw.6") 
covariates <- c("ESETA1.6", "state:SmokTotl", "PmAge2:PmBlac2", "ESETA1.6:B18Raw.6:RHasSO.6") #testing interactions
covariates <- c("ESETA1.6", "InRatioCor.6", "gov_assist","PmEd2")  #empirical example
covariates <- c("PmEd2")  #empirical example


#optional specification of epochs
epochs <- NULL
epochs <- data.frame(epochs = c("Infancy", "Toddlerhood", "Childhood"),  #empirical example
                     values = I(list(c(6, 15), c(24, 35), c(58)))) 

#required
weights <- trim_weights

# all inputs
#required
model <- "m1"
models <- fitModel(data = data, weights = weights, exposure = exposure, #required
                   exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required
                   family = family, link = link, int_order = int_order, covariates = covariates, epochs = epochs, #optional
                   home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


##### Sensitvity analyses
We recommend specifying sensitivity analyses to match the main analyses above. 
Note: We recommend specifying sensitivity analyses to match the main analyses above. 
Note: Please run the above main analysis and then rename or relocate the following output, before running each sensitivity test and renaming/relocating each one in the same manner:

in the model folder:
- .rds model file
- .docx table of model evidence

```{r}

weights <- trim_weights.s1
models.s1 <- fitModel(data = data, weights = weights, exposure = exposure, #required
                      exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required
                      family = family, link = link, int_order = int_order, covariates = covariates, epochs = epochs, #optional
                      home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

weights <- trim_weights.s2
models.s2 <- fitModel(data = data, weights = weights, exposure = exposure, #required
                      exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required
                      family = family, link = link, int_order = int_order, covariates = covariates, epochs = epochs, #optional
                      home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional
```


#### 5b. Estimate, compare, & visualize model-predicted outcome as a function of history

##### Main
If you specify exposure epochs, we recommend doing so consistently throughout this workflow. 

```{r}

#optional specification of epochs; only specify this if you did in model fitting (5a) --must be identical
epochs <- NULL
epochs <- data.frame(epochs = c("Infancy", "Toddlerhood", "Childhood"), 
                     values = I(list(c(6, 15), c(24, 35), c(58)))) #empirical example 

#optional list of quantiles specifying high and low cutoff values for continuous exposures; 
hi_lo_cut <- NULL
hi_lo_cut <- c(0.6, 0.3) #empirical example final choice

#optional reference history (required if comparisons are specified)
reference <- NULL
reference <- "l-l-l" #empirical example final choice
reference <- c("l-l-l", "l-l-h") #multiple

#optional comparison history/histories (required if reference specified)
comparison <- NULL 
comparison <- "h-h-h" #single
comparison <- c("h-h-h", "h-h-l") #multiple
comparison <- c("h-h-h", "h-l-l", "l-l-h", "h-h-l", "l-h-h") #empirical example final choice


#optional multiple comparion method; default is Benjamini-Hochburg, ("holm", "hochberg","hommel", "bonferroni", "BH", "BY", "fdr", "none" (see stats::p.adjust() documentation)
mc_comp_method <- NA
mc_comp_method <- "BH" #empirical example 

#optional specification of dose level (high or low) for dose count (default is "h")
dose_level <- NA
dose_level <- "h" #empirical example 

#optional exposure label for plotting
exp_lab <- NA
exp_lab <- "Economic Strain" #empirical example 

#optional outcome label for plotting 
out_lab <- NA
out_lab <- "Behavior Problems" #empirical example 

# optional list of colors (equal to number of epochs +1) or brewer palette for plotting #(see RColorBrewer::display.brewer.all() or https://r-graph-gallery.com/38-rcolorbrewers-palettes.html) for plotting default is 'Dark2'); 
colors <- NULL
colors <- c("Dark2") #empirical example
colors <- c("blue4", "darkgreen", "darkgoldenrod", "red2") #list number-of-exposure-main-effects-+1 colors

#required
model <- models #output from fitModel

#all inputs
results <- compareHistories(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required
                            epochs = epochs, hi_lo_cut = hi_lo_cut, reference = reference, comparison = comparison, #optional
                            mc_comp_method = mc_comp_method, dose_level = dose_level, exp_lab = exp_lab, out_lab = out_lab, colors = colors, #optional
                            home_dir = home_dir, verbose = TRUE, save.out = TRUE) #optional

```


##### Sensitvity analyses
We recommend specifying sensitivity analyses to match the main analyses above. 
Note: Please run the above main analysis and then rename or relocate the following output, before running each sensitivity test and renaming/relocating each one in the same manner:

in the histories folder, .html tables of:
- estimated mean outcome values for each hisotry
- history comparisons

in the plots folder, .jpeg images of:
- predicted outcomes values for each history

```{r}

model <- models.s1 
results.s1 <- compareHistories(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required
                               epochs = epochs, hi_lo_cut = hi_lo_cut, reference = reference, comparison = comparison, #optional
                               mc_comp_method = mc_comp_method, dose_level = dose_level, exp_lab = exp_lab, out_lab = out_lab, colors = colors, #optional
                               home_dir = home_dir, verbose = FALSE, save.out = TRUE) #optional

model <- models.s2 
results.s2 <- compareHistories(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required
                               epochs = epochs, hi_lo_cut = hi_lo_cut, reference = reference, comparison = comparison, #optional
                               mc_comp_method = mc_comp_method, dose_level = dose_level, exp_lab = exp_lab, out_lab = out_lab, colors = colors, #optional
                               home_dir = home_dir, verbose = FALSE, save.out = TRUE) #optional

```


## Package citations :) 
We are grateful to the authors of many existing packages that devMSMs draws from!

```{r}

grateful::cite_packages(out.dir = home_dir, omit = c("devMSMs", "devMSMsHelpers"), 
                        out.format = "docx")

```

