[{"path":"https://istallworthy.github.io/devMSMs/articles/Data_Requirements.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Data Requirements","text":"Kainz, K., Greifer, N., Givens, ., Swietek, K., Lombardi, B. M., Zietz, S., & Kohn, J. L. (2017). Improving Causal Inference: Recommendations Covariate Selection Balance Propensity Score Methods. Journal Society Social Work Research, 8(2), 279–303. https://doi.org/10.1086/691464","code":""},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"load-data","dir":"Articles","previous_headings":"","what":"Load data","title":"Preliminary Steps","text":"","code":"# data <- read.csv('/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/testing data/continuous outcome/continuous exposure/FLP_wide_imputed.csv')  #temporary data until we get sim data wide <- data.frame(S_ID = 1:50,                    ESETA1.6 = rnorm(n = 50),                    ESETA1.15 = rnorm(n = 50),                    ESETA1.24 = rnorm(n = 50),                    peri_health = rnorm(n = 50),                    gov_assist = rnorm(n = 50),                    InRatioCor.6 = rnorm(n = 50),                    InRatioCor.15 = rnorm(n = 50),                    InRatioCor.24 = rnorm(n = 50),                    WndNbrhood.6 = rnorm(n = 50),                    WndNbrhood.15 = rnorm(n = 50),                    WndNbrhood.24 = rnorm(n = 50),                    StrDif_Tot.58 = rnorm(n = 50))  data_long <- stats::reshape(data = wide,                             idvar = \"S_ID\", #'list ID variable                             varying = c(\"ESETA1.6\", \"ESETA1.15\", \"ESETA1.24\",                                         \"InRatioCor.6\", \"InRatioCor.15\", \"InRatioCor.24\",                                         \"WndNbrhood.6\", \"WndNbrhood.15\", \"WndNbrhood.24\"),                             direction = \"long\")  data_long_missing <- missMethods::delete_MAR_1_to_x(as.data.frame(data_long), p = 0.20,                                                     cols_mis = c(\"ESETA1\",                                                                  \"WndNbrhood\"),                                                     cols_ctrl = c(rep(\"InRatioCor\", 2)), 2)"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"core-inputs","dir":"Articles","previous_headings":"","what":"Core inputs","title":"Preliminary Steps","text":"Please see Specifying Core Inputs vignette detail following core inputs.","code":"#set seed for reproducibility  set.seed(1234)  #required if you wish to use save.out = TRUE in the functions home_dir <- NA # home_dir <- '/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/isa' #note: no / after  #required exposure <- \"ESETA1\"  #required exposure_time_pts <- c(6, 15, 24)  #required outcome <- \"StrDif_Tot.58\"  #required; list in wide format tv_confounders <- c(                     # \"SAAmylase.6\",\"SAAmylase.15\", \"SAAmylase.24\",                     # \"MDI.6\", \"MDI.15\",                                                                 # \"RHasSO.6\", \"RHasSO.15\", \"RHasSO.24\",\"RHasSO.35\", \"RHasSO.58\",                                                              \"WndNbrhood.6\",\"WndNbrhood.15\", \"WndNbrhood.24\", #\"WndNbrhood.35\", \"WndNbrhood.58\",                                                            # \"IBRAttn.6\", \"IBRAttn.15\", \"IBRAttn.24\",                                                        # \"B18Raw.6\", \"B18Raw.15\", \"B18Raw.24\", \"B18Raw.58\",                                                                # \"HOMEETA1.6\", \"HOMEETA1.15\", \"HOMEETA1.24\", \"HOMEETA1.35\", \"HOMEETA1.58\",                                                    \"InRatioCor.6\", \"InRatioCor.15\", \"InRatioCor.24\", #\"InRatioCor.35\", \"InRatioCor.58\",                                              \"ESETA1.6\", \"ESETA1.15\", \"ESETA1.24\"# \"ESETA1.35\", \"ESETA1.58\",  #exposure variables required                                    # \"CORTB.6\", \"CORTB.15\", \"CORTB.24\",                                                                                       # \"EARS_TJo.24\", \"EARS_TJo.35\",                                                             # \"LESMnPos.24\", \"LESMnPos.35\",                                                       # \"LESMnNeg.24\", \"LESMnNeg.35\",                            # \"StrDif_Tot.35\",                      # \"StrDif_Tot.58\"                         # \"fscore.35\", \"fscore.58\"                     # , \"ESETA1.6:B18Raw.6\", \"ESETA1.6:B18Raw.15:RHasSO.6\", \"state:EARS_TJo.35\" #testing interactions )   #required ti_confounders <- c(                     # \"state\", \"BioDadInHH2\", \"PmAge2\", \"PmBlac2\", \"TcBlac2\", \"PmMrSt2\", \"PmEd2\", \"KFASTScr\",                     # \"RMomAgeU\", \"RHealth\", \"HomeOwnd\", \"SWghtLB\", \"SurpPreg\", \"SmokTotl\", \"DrnkFreq\",                     \"peri_health\",                      # \"caregiv_health\",                      \"gov_assist\"                     #, \"state:SmokTotl\", \"PmAge2:PmBlac2\", \"PmAge2:PmEd2\" #testing interaction terms )"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p1--format-data","dir":"Articles","previous_headings":"","what":"P1. Format Data","title":"Preliminary Steps","text":"data must wide format contain “ID” column subject identifier exposure, outcome, confounders separate columns (shown Figure 1). Column names can include underscore special characters time-varying variables suffix consists period followed time point (e.g., “variable.6”). variables classed integer, numeric, factor (character). Auxiliary nuisance covariates confounders (e.g, assessment version) can included dataset use specification final modeling step (Workflow vignettes Step 5). insert Figure 1 .","code":""},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p1a--format-single-data-frame-of-long-data","dir":"Articles","previous_headings":"P1. Format Data","what":"P1a. Format single data frame of long data","title":"Preliminary Steps","text":"Users beginning single data frame long format (without missingness) can utilize helper function formatLongData() summarize exposure outcome data convert required variable names. function takes dataset long format variables time (time_var), ID (id_var), missing data (missing) alternative variables re-labels according required package. also classes factor confounders (factor_confounders) factors data others numeric.","code":"data_long_f <- formatLongData(data = data_long_missing, exposure = exposure,                                exposure_time_pts = exposure_time_pts, outcome = outcome,                                time_var = \"time\", id_var = \"S_ID\",                                                               missing = NA,                               factor_confounders = NULL,                               home_dir = home_dir,                                save.out = save.out)  #> Table: Summary of ESETA1 Exposure Information #>  #> | WAVE|       mean|       sd|       min|      max| #> |----:|----------:|--------:|---------:|--------:| #> |    6|  0.1264997| 1.116395| -2.139237| 2.317149| #> |   15|  0.3015417| 1.048391| -2.385369| 2.378024| #> |   24| -0.1589964| 0.846074| -1.714266| 1.448161| #>  #> Table: Summary of Outcome StrDif_Tot.58 Information #>  #> | WAVE|       mean|        sd|       min|      max| #> |----:|----------:|---------:|---------:|--------:| #> |    6| -0.0542388| 0.9444387| -2.516846| 1.785305| #> |   15| -0.0542388| 0.9444387| -2.516846| 1.785305| #> |   24| -0.0542388| 0.9444387| -2.516846| 1.785305|  data_long_f_no_missing <- formatLongData(data = data_long, exposure = exposure,                                exposure_time_pts = exposure_time_pts, outcome = outcome,                                time_var = \"time\", id_var = \"S_ID\",                                                               missing = NA,                               factor_confounders = NULL,                               home_dir = home_dir,                                save.out = save.out)  #> Table: Summary of ESETA1 Exposure Information #>  #> | WAVE|       mean|        sd|       min|      max| #> |----:|----------:|---------:|---------:|--------:| #> |    6|  0.1615894| 1.0021265| -2.139237| 2.317149| #> |   15|  0.2661542| 1.0661488| -2.385369| 2.378024| #> |   24| -0.1736901| 0.8146827| -1.714266| 1.448161| #>  #> Table: Summary of Outcome StrDif_Tot.58 Information #>  #> | WAVE|       mean|        sd|       min|      max| #> |----:|----------:|---------:|---------:|--------:| #> |    6| -0.0542388| 0.9444387| -2.516846| 1.785305| #> |   15| -0.0542388| 0.9444387| -2.516846| 1.785305| #> |   24| -0.0542388| 0.9444387| -2.516846| 1.785305|"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p1b--convert-single-long-data-frame-to-wide-format","dir":"Articles","previous_headings":"P1. Format Data","what":"P1b. Convert single long data frame to wide format","title":"Preliminary Steps","text":"Users correctly formatted variables long format option using following code transform data wide format, proceed using package (missing data) imputing (< 20% missing data MAR). , can start wide data missingness already formatted. Alternatively, missing data, user can read formatted, wide dataset ready use devMSMs.","code":"# v <- sapply(strsplit(tv_confounders[!grepl(\"\\\\:\", tv_confounders)], \"\\\\.\"), \"[\", 1) # v <- v[!duplicated(v)] v <- c(\"WndNbrhood\", \"InRatioCor\", \"ESETA1\")  data_wide <- stats::reshape(data = data_long_f,                              idvar = \"ID\", #list ID variable in your dataset                             v.names = v,                              timevar = \"WAVE\", # list time variable in your long dataset                             times = c(6, 15, 24), # list all time points in your dataset                             direction = \"wide\")  data_wide <- data_wide[, colSums(is.na(data_wide)) < nrow(data_wide)] # data_wide <- readRDS(\"/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/Tutorial paper/merged_tutorial_filtered.rds\" )  data_wide_missing <- missMethods::delete_MAR_1_to_x(as.data.frame(data_wide), p = 0.20,                                                     cols_mis = c(\"InRatioCor.15\", \"InRatioCor.24\",                                                                  \"ESETA1.6\", \"ESETA1.15\", \"ESETA1.24\",                                                                  \"WndNbrhood.6\", \"WndNbrhood.15\", \"WndNbrhood.24\"),                                                     cols_ctrl = c(rep(\"InRatioCor.6\", 8)), 8) v <- c(\"WndNbrhood\", \"InRatioCor\", \"ESETA1\")  data_wide_no_missing <- stats::reshape(data = data_long_f_no_missing,                              idvar = \"ID\", #list ID variable in your dataset                             v.names = v,                              timevar = \"WAVE\", # list time variable in your long dataset                             times = c(6, 15, 24), # list all time points in your dataset                             direction = \"wide\")  data_wide_no_missing <- data_wide[, colSums(is.na(data_wide)) < nrow(data_wide)]  data <- data_wide_no_missing"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p2--impute-data-to-account-for-missingness","dir":"Articles","previous_headings":"","what":"P2. Impute Data to Account for Missingness","title":"Preliminary Steps","text":"functions devMSMs package accept data form single data frame missing values m imputed datasets form either mids object (output mice package via imputeData()) list imputed datasets. developmental data humans amount missing data. Given creation IPTW balancing weights requires complete data, recommend imputing data. Imputation assumes missing data mechanism missing random (MAR) 20% missing data total (Leyrat et al., 2021). Given existing work demonstrating superiority, devMSMS implements ‘within’ approach imputed data, conducting steps imputed dataset pooling estimates using Rubin’s rules create final average predictions contrast comparisons Worfklows vignettes Step 5 (Leyrat et al, 2021; Granger et al., 2019).","code":""},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p2a--multiply-impute-single-wide-formatted-data-frame-using-mice","dir":"Articles","previous_headings":"P2. Impute Data to Account for Missingness","what":"P2a. Multiply impute single wide, formatted data frame using mice","title":"Preliminary Steps","text":"Users option using helper imputeData() function impute correctly formatted wide data. step can take run. user can specify many imputed datasets create (default m = 5). imputeData() draws mice() function mice package (van Buuren & Oudshoorn, 2011) conduct multiple imputation chained equations (mice). variables present dataset used impute missing data column. user can specify imputation method method field drawing following list: “pmm” (predictive mean matching), “midastouch” (weighted predictive mean matching), “sample” (random sample observed values), “rf” (random forest) “cart” (classification regression trees). Random forest imputation default given evidence efficiency superior performance (Shah et al., 2014). parameter read_imps_from_file allow read already imputed data local storage (TRUE) re-run imputation code multiple times (FALSE; default). Users may use parameter supply mids object imputed data mice package (title ‘all_imp.rds’). sure inspect console warnings well resulting imputed datasets. variables missing data following imputation may need removed due high collinearity /low variability. required inputs function data frame wide format (formatted according pre-requirements listed ), m number imputed datasets create, path home directory, (save.= TRUE), exposure (e.g., “variable”), outcome (e.g., “variable.t”). home directory path, exposure, outcome already defined user completed Specifying Core Inputs vignette. Optional inputs follows. user can specify imputation method compatible mice() (see ). Additionally, user can specify maxit number interactions mice::mice() conduct (default 5). user can also specify para_proc, logical indicator indicating whether speed imputing using parallel processing (default = TRUE). uses 2 cores using functions parallel, doRNG, doParallel packages. user may also specify additional inputs accepted mice::mice() advise consulting [mice documentation] information. user can also indicate already created imputed datasets function wish read (read_imps_from_file = TRUE rather recreate (default). can also set save.= FALSE suppress saving intermediate final output local home directory (recommended default = TRUE). example, create 5 imputed datasets using default random forest method 5 iterations assign output data use devMSMs. can also read previously saved imputed data.","code":"m <- 5   method <- \"rf\"   maxit <- 5   imputed_data <- imputeData(data = data_wide_missing, exposure = exposure, outcome = outcome,                             m = m, method = method, maxit = maxit, para_proc = FALSE,                             read_imps_from_file = FALSE,                             home_dir = home_dir, save.out = save.out) #> Creating 5 imputed datasets using the rf imputation method in mice::mice(). This may take some time to run.  #>  #>  #> USER ALERT: Please view any logged events from the imputation below:  #> Table: Logged Events from mice::mice  data <- imputed_data # data <- readRDS(\"/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/testing data/continuous outcome/continuous exposure/FLP_wide_imputed_mids.rds\")"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p2b--read-in-as-a-list-wide-imputed-data-saved-locally","dir":"Articles","previous_headings":"P2. Impute Data to Account for Missingness","what":"P2b. Read in as a list wide imputed data saved locally","title":"Preliminary Steps","text":"Users can also read , list, imputed data created using different function saved locally .csv files (labeled “1”:m) single folder.","code":"# folder <- \"/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/testing data/continuous outcome/continuous exposure/imputations/\"  #  # files <- list.files(folder, full.names = TRUE, pattern = \"\\\\.csv\") #make sure pattern matches suffix of your data #  # data <- lapply(files, function(file) { #   imp_data <- read.csv(file) #   imp_data # })"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p3--optional-identify-exposure-epochs","dir":"Articles","previous_headings":"","what":"P3. Optional: Identify Exposure Epochs","title":"Preliminary Steps","text":"Users option specify exposure epochs input fitModel() compareHistories() devMSMs functions (see Workflows vignettes). specification exposure epochs kept consistent throughout preliminary steps two functions. exposure time points specified core inputs section constitute time points IPTW weights created assessed. Unless user specifies separate exposure epochs, time points also constitute main effects variables modeling relation exposure outcome (Workflows vignettes Step 5a) form basis estimating comparing exposure histories (Workflows vignettes Step 5b). user option draw theory structure data specify developmental epochs exposure differ time points exposure collected. specify epochs, users utilize optional epochs argument providing data frame contains two variables: epochs: provide, quotations, list user-created names epoch; values: list, named epoch, provide single integer list integers (exposure time points) constitute epoch. named epoch must corresponding value (values epoch can differ number entries, shown ). user ensure epoch values included exposure_time_pts field (see ). specified epochs applied final modeling step MSM process exposure levels averaged across values (Workflows vignettes Step 5). epochs specified, time points exposure measured used Step 5 Workflows vignettes.","code":"epochs <- data.frame(epochs = c(\"Infancy\", #list user-specified names                                 \"Toddlerhood\",                                  \"Childhood\"),                       values = I(list(c(6), #list corresponding time points from data                                      c(15),                                       c(24)                      )))"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p4--recommended-specify-inspect-exposure-histories","dir":"Articles","previous_headings":"","what":"P4. Recommended: Specify & Inspect Exposure Histories","title":"Preliminary Steps","text":"Exposure histories units users test substantive hypotheses construction determined theoretical practical reasoning. strongly recommend users verify inspect exposure histories priori relation data hypotheses.","code":""},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p4a--create-high-and-low-cutoff-values-for-continuous-exposures","dir":"Articles","previous_headings":"","what":"P4a. Create high and low cutoff values for continuous exposures","title":"Preliminary Steps","text":"First, continuously distributed exposures (regardless whether exposure epochs specified), recommend users indicate high low cutoff values optional input compareHistories()) devMSMs function (see Workflows vignettes). , specify hi_lo_cut, list, quantile value (0-1) considered high levels exposure, followed quantile value (0-1) considered low levels exposure (default median split). values may revised following inspection sample distribution across resulting exposure histories subsequent steps. final values used creating exposure histories Step 5 Workflows vignettes.","code":"hi_lo_cut <- c(0.6, 0.3) #empirical example"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p4b--specify-hypotheses-relevant-exposure-histories","dir":"Articles","previous_headings":"","what":"P4b. Specify hypotheses-relevant exposure histories","title":"Preliminary Steps","text":"strongly recommend users selective histories, developmental sequences high low exposure (exposure time points epochs), vital testing hypotheses. units exposure histories exposure time points epochs specified. recommend user estimates compares subset possible exposure histories (.e., sequences high low levels exposure epoch time point) using reference comparison fields (rather comparing possible exposure histories). user can specify custom subset user-specified exposure histories (.e., sequences high low levels exposure epoch time point) using reference comparison fields optional inputs compareHistories() devMSMs function (see Workflows vignettes). conduct customized comparisons, users must provide least one unique valid history (e.g., “l-l-l”) reference , quotations, provide string (list strings) lowercase l’s h’s (separated -), corresponding exposure epoch (time point), signify sequence exposure levels (“low” “high”, respectively). supply reference history, comparisons provide least one unique valid history comparison , quotations, providing string (list strings) l’s h’s (separated “-”), corresponding exposure epoch, signify sequence exposure levels (“low” “high”, respectively) constitutes comparison exposure history/histories compared reference. supply one comparisons, least one reference must specified. reference exposure history compared comparison history comparisons supplied multiple comparison correction. reference comparison specified, histories compared . final reference comparison values established step used estimating comparing exposure histories Step 5b Workflows vignettes. 4 exposure main effects (either epochs exposure time points), user required select subset history comparisons (Step 5b Workflows vignettes), given base code (see hypotheses() function marginaleffects package) accommodate pairwise history comparisons 5 time points).","code":"reference <- c(\"l-l-l\")  comparison <- c(\"h-h-h\", \"h-l-l\")"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"p4c--inspect-exposure-histories-and-data","dir":"Articles","previous_headings":"","what":"P4c. Inspect exposure histories and data","title":"Preliminary Steps","text":"users, highly recommend use helper inspectData() function (original dataset long wide format imputed data case missingness) summarize exposure, outcome, confounders inspect sample distribution among exposure histories. Based user-specified exposure epochs high low quantile values (continuous exposures), function outputs table showing sample distribution across histories. strongly suggest visually inspecting table revising designation epochs /high low quantile values (continuous exposures) history contains reasonable number participants. gold standard required number per history cell, users guard extrapolation beyond scope data. example, data, using 75th 25th percentile cutoffs, histories represented less two cases thus re-evaluated cutoffs. Users may wish revise epoch designation high low cutoff values, applicable. function conducts summaries history distribution inspection imputed dataset imputed data supplied. insert Table 2  required inputs inspectData() : data (data frame wide long format, list imputed data frames wide format, mids object), path home directory, exposure (e.g., “variable”), outcome (e.g., “variable.t”). Optional inputs time-varying confounders (e.g., “variable.t”), epochs, high/low cutoff values continuous exposures, specification reference comparison histories (see ). specification exposure epochs kept consistent throughout use devMSMs package (see Workflows vignettes). home directory path, exposure, exposure time points, confounders, outcome already defined user completed Specifying Core Inputs vignette. helper inspectData() function outputs following files home directory: correlation plot variables dataset, tables exposure outcome descriptive statistics, two summary tables confounders considered time point.","code":"inspectData(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, # required input             ti_confounders = ti_confounders, tv_confounders = tv_confounders, # required input             epochs = epochs, hi_lo_cut = hi_lo_cut, reference = reference, comparison = comparison, #optional input             home_dir = home_dir, verbose = verbose, save.out = save.out) #optional input #> Using github PAT from envvar GITHUB_PAT #> Skipping install of 'devMSMs' from a github remote, the SHA1 (efc74dea) has not changed since last install. #>   Use `force = TRUE` to force installation #> Imputation 1 #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 5 (10%) individuals that fall into 3 out of the 3 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure ESETA1, respectively, across Infancy, Toddlerhood, Childhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure ESETA1 histories based on exposure main effects Infancy, Toddlerhood, Childhood containing time points 6, 15, 24: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  1| #> |h-l-l   |  3| #> |l-l-l   |  1| #> Imputation 2 #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 7 (14%) individuals that fall into 3 out of the 3 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure ESETA1, respectively, across Infancy, Toddlerhood, Childhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure ESETA1 histories based on exposure main effects Infancy, Toddlerhood, Childhood containing time points 6, 15, 24: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  1| #> |h-l-l   |  4| #> |l-l-l   |  2| #> Imputation 3 #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 10 (20%) individuals that fall into 3 out of the 3 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure ESETA1, respectively, across Infancy, Toddlerhood, Childhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure ESETA1 histories based on exposure main effects Infancy, Toddlerhood, Childhood containing time points 6, 15, 24: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  6| #> |h-l-l   |  2| #> |l-l-l   |  2| #> Imputation 4 #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 11 (22%) individuals that fall into 3 out of the 3 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure ESETA1, respectively, across Infancy, Toddlerhood, Childhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure ESETA1 histories based on exposure main effects Infancy, Toddlerhood, Childhood containing time points 6, 15, 24: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  4| #> |h-l-l   |  4| #> |l-l-l   |  3| #> Imputation 5 #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 5 (10%) individuals that fall into 3 out of the 3 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure ESETA1, respectively, across Infancy, Toddlerhood, Childhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure ESETA1 histories based on exposure main effects Infancy, Toddlerhood, Childhood containing time points 6, 15, 24: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  2| #> |h-l-l   |  1| #> |l-l-l   |  2| #> The following inspection is conducted on the first imputed dataset. #> USER ALERT: Below are the 11 variables spanning 5 unique domains that will be treated as confounding variables for the relation between ESETA1 and StrDif_Tot.58. #> Please inspect this list carefully. It should include all time-varying covariates, time invariant covariates, as well as lagged levels of exposure and outcome variables if they were collected at time points earlier than the outcome time point. #>  [1] \"ESETA1.15\"     \"ESETA1.24\"     \"ESETA1.6\"      \"gov_assist\"    #>  [5] \"InRatioCor.15\" \"InRatioCor.24\" \"InRatioCor.6\"  \"peri_health\"   #>  [9] \"WndNbrhood.15\" \"WndNbrhood.24\" \"WndNbrhood.6\"  #>  #> The following variables are designated as numeric:  #> [1] \"ID, peri_health, gov_assist, StrDif_Tot.58, WndNbrhood.6, InRatioCor.6, ESETA1.6, WndNbrhood.15, InRatioCor.15, ESETA1.15, WndNbrhood.24, InRatioCor.24, ESETA1.24\" #>  #> The following variables are designated as factors:  #> [1] \"\" #>  #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 5 (10%) individuals that fall into 3 out of the 3 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure ESETA1, respectively, across Infancy, Toddlerhood, Childhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure ESETA1 histories based on exposure main effects Infancy, Toddlerhood, Childhood containing time points 6, 15, 24: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  1| #> |h-l-l   |  3| #> |l-l-l   |  1| #>  #> Your outcome variable(s) have the following type(s): numeric"},{"path":"https://istallworthy.github.io/devMSMs/articles/Preliminary_Steps.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Preliminary Steps","text":"Arel-Bundock, Vincent. 2023. marginaleffects: Predictions, Comparisons, Slopes, Marginal Means, Hypothesis Tests. https://CRAN.R-project.org/package=marginaleffects. Granger, E., Sergeant, J. C., & Lunt, M. (2019). Avoiding pitfalls combining multiple imputation propensity scores. Statistics Medicine, 38(26), 5120–5132. https://doi.org/10.1002/sim.8355 Leyrat, C., Carpenter, J. R., Bailly, S., & Williamson, E. J. (2021). Common Methods Handling Missing Data Marginal Structural Models: Works . American Journal Epidemiology, 190(4), 663–672. https://doi.org/10.1093/aje/kwaa225 Shah, . D., Bartlett, J. W., Carpenter, J., Nicholas, O., & Hemingway, H. (2014). Comparison Random Forest Parametric Imputation Models Imputing Missing Data Using MICE: CALIBER Study. American Journal Epidemiology, 179(6), 764–774. https://doi.org/10.1093/aje/kwt312 van Buuren, Stef, Karin Groothuis-Oudshoorn. 2011. “mice: Multivariate Imputation Chained Equations r.” Journal Statistical Software 45 (3): 1–67. https://doi.org/10.18637/jss.v045.i03.","code":""},{"path":"https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html","id":"home-directory","dir":"Articles","previous_headings":"","what":"Home Directory","title":"Specify Core Inputs","text":"Users required specify home directory, quotations, path designated folder output package, plan save intermediary final outputs package (default) setting save.= TRUE functions. sub directories created within home directory devMSMs functions automatically save.’ = TRUE.","code":"home_dir <- NA home_dir <- '/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/isa' #note: no / after"},{"path":"https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html","id":"exposure-variable","dir":"Articles","previous_headings":"","what":"Exposure Variable","title":"Specify Core Inputs","text":"Users required specify exposure variable input functions devMSMs. user must specify exposure, variable name exposure quotations, without time information appended (e.g., “variable”). Note dataset, exposure variables wide format labeled “.time” suffix (e.g., “variable.t”).","code":"exposure <- \"ESETA1\""},{"path":"https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html","id":"exposure-time-points","dir":"Articles","previous_headings":"","what":"Exposure Time Points","title":"Specify Core Inputs","text":"Next, users required provide information time points exposure assessed exposure_time_pts, required input createFormulas(), assessBalance(), fitModel(), compareHistories() devMSMs functions (see Workflows vignettes). user two options specifying exposure time points select option best serves theory regarding developmental timing practical constraints data modeling process. First, may specify time points exposure measured data. means balancing formulas created (Steps 1a, 2a, 3b Workflows vignettes) IPTW weights created (Steps 2b, 3c Workflows vignettes) assessed (Steps 2c, 3a, 4 Workflows vignettes) time points. case, epochs specified, time points included exposure main effects final substantive model history comparison (Step 5 Workflows vignettes). Second, may specify subset theoretically important time points exposure measured data. means balancing formulas created IPTW weights created assessed time points. , epochs specified, subsetted time points included exposure main effects final substantive models. Importantly, exposure variables time points exposure assessed included time-varying confounders balancing purposes . specification exposure epochs kept consistent throughout use devMSMs package. user intends specify exposure epochs (Preliminary Steps vignette Step P3), user include time points encompassed epochs exposure_time_pts. user intend specify exposure epochs (Preliminary Steps vignette Step P3), exposure_time_pts constitute exposure main effects final outcome model form basis histories used history comparison. case, user specifies 4 exposure time points, required conduct subset history comparisons (Step 5b Workflows vignettes), given base code (see hypotheses() function marginaleffects package) accommodate pairwise history comparisons 5 time points. elected create epochs infancy (6 15 months), toddlerhood (24 35 months), early childhood (58 months). Thus, input 6, 15, 24, 35, 58 exposure_time_pts.","code":"exposure_time_pts <- c(6, 15, 24, 35, 58)"},{"path":"https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html","id":"outcome-variable","dir":"Articles","previous_headings":"","what":"Outcome Variable","title":"Specify Core Inputs","text":"Users also required specify outcome variable designated final time point, required input functions devMSMs package. final time point equal (, ideally greater ) final exposure time point. Note instances outcome variable measured prior time points included time-varying confounders balancing purposes. Specifying outcome, variable name outcome time point collected appended following period (e.g., “variable.t”) corresponding variable name wide data, required package. Outcome variables dataset wide format labeled “.time” suffix.","code":"outcome <- \"StrDif_Tot.58\""},{"path":[]},{"path":"https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html","id":"time-invariant-confounders","dir":"Articles","previous_headings":"Confounders","what":"Time invariant confounders","title":"Specify Core Inputs","text":"Specifying least one time invariant confounder required use package required input createFormulas() function. Time invariant confounders include core demographic birth characteristics (e.g., sex, racial group membership, birth complications) might cause either exposure outcome, either directly proxy, suggested theory /evidenced strong associations existing literature. , user can also include interaction terms time invariant variables (e.g., “variable:variable”) inclusion balancing formula. Keep mind interactions include factor variables decomposed interactions factor level. ti_confounders, list, quotations, provide names confounders (e.g., “variable”, “variable:variable”) dataset time invariant.","code":"ti_confounders <- c(\"state\", \"BioDadInHH2\", \"PmAge2\", \"PmBlac2\", \"TcBlac2\", \"PmMrSt2\", \"PmEd2\", \"KFASTScr\",                     \"RMomAgeU\", \"RHealth\", \"HomeOwnd\", \"SWghtLB\", \"SurpPreg\", \"SmokTotl\", \"DrnkFreq\",                     \"peri_health\", \"caregiv_health\", \"gov_assist\" )"},{"path":"https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html","id":"time-varying-confounders","dir":"Articles","previous_headings":"Confounders","what":"Time-varying confounders","title":"Specify Core Inputs","text":"Specifying least time-varying exposures time-varying confounders required use package required input createFormulas() devMSMs function (see Workflows vignettes). tv_confounders list, quotations, provide names variables wide format (e.g., “variable.t”) dataset time-varying (including time-varying confounders, exposures, outcomes). include time-varying exposure variables outcome variables present dataset (e.g., “variable.t”). Note time-varying confounders also include confounders measured repeatedly time points (e.g., InRatioCor) collected one several specific time points, missing time points, time invariant. , user can also include interaction terms time-varying variables (e.g., “variable.t:variable.t”) time invariant time-varying variables (e.g., “variable.t:variable”) inclusion balancing formula. Keep mind interactions include factor variables decomposed interactions factor level.","code":"tv_confounders <- c(\"SAAmylase.6\",\"SAAmylase.15\", \"SAAmylase.24\",                     \"MDI.6\", \"MDI.15\",                                                                 \"RHasSO.6\", \"RHasSO.15\", \"RHasSO.24\",\"RHasSO.35\", \"RHasSO.58\",                                                              \"WndNbrhood.6\",\"WndNbrhood.24\", \"WndNbrhood.35\", \"WndNbrhood.58\",                                                            \"IBRAttn.6\", \"IBRAttn.15\", \"IBRAttn.24\",                                                        \"B18Raw.6\", \"B18Raw.15\", \"B18Raw.24\", \"B18Raw.58\",                                                                \"HOMEETA1.6\", \"HOMEETA1.15\", \"HOMEETA1.24\", \"HOMEETA1.35\", \"HOMEETA1.58\",                                                    \"InRatioCor.6\", \"InRatioCor.15\", \"InRatioCor.24\", \"InRatioCor.35\", \"InRatioCor.58\",                                              \"ESETA1.6\", \"ESETA1.15\", \"ESETA1.24\", \"ESETA1.35\", \"ESETA1.58\",  #exposure variables required                                    \"CORTB.6\", \"CORTB.15\", \"CORTB.24\",                                                                                       \"EARS_TJo.24\", \"EARS_TJo.35\",                                                             \"LESMnPos.24\", \"LESMnPos.35\",                                                       \"LESMnNeg.24\", \"LESMnNeg.35\",                            \"StrDif_Tot.35\", \"StrDif_Tot.58\",                         \"fscore.35\", \"fscore.58\" )"},{"path":"https://istallworthy.github.io/devMSMs/articles/Specify_Core_Inputs.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Specify Core Inputs","text":"Arel-Bundock, Vincent. 2023. marginaleffects: Predictions, Comparisons, Slopes, Marginal Means, Hypothesis Tests. https://CRAN.R-project.org/package=marginaleffects.","code":""},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"load-data","dir":"Articles","previous_headings":"","what":"Load data","title":"Workflow: Continuous Exposure","text":"first load data frame complete data. (See Preliminary Steps vignette beginning data types, including missing data). check see character variables present data convert integers. make factor variables factor class.","code":"# data <- read.csv('/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/testing data/continuous outcome/continuous exposure/FLP_wide_imputed.csv') #temporary data until we get sim data data <- data.frame(ID = 1:50,                    ESETA1.6 = rnorm(n = 50),                    ESETA1.15 = rnorm(n = 50),                    ESETA1.24 = rnorm(n = 50),                    peri_health = rnorm(n = 50),                    gov_assist = rnorm(n = 50),                    InRatioCor.6 = rnorm(n = 50),                    InRatioCor.15 = rnorm(n = 50),                    InRatioCor.24 = rnorm(n = 50),                    WndNbrhood.6 = rnorm(n = 50),                    WndNbrhood.15 = rnorm(n = 50),                    WndNbrhood.24 = rnorm(n = 50),                    StrDif_Tot.58 = rnorm(n = 50)) any(sapply(data, class) == \"character\") #if this is TRUE, run next lines #> [1] FALSE  names(data)[sapply(data, class) == \"character\"] #find names of any character variables #> character(0)  #data[, \"state\"] <- factor(data[, \"state\"], labels = c(1, 0)) #run this for each variable that needs char -> factor # factor_covars <- c(\"state\", \"TcBlac2\",\"BioDadInHH2\",\"HomeOwnd\", \"PmBlac2\",        #                    \"PmMrSt2\", \"SurpPreg\", \"RHealth\", \"SmokTotl\", \"DrnkFreq\", #                    \"RHasSO.6\", \"RHasSO.15\", \"RHasSO.24\", \"RHasSO.35\", \"RHasSO.58\") #  # data[, factor_covars] <- as.data.frame(lapply(data[, factor_covars], as.factor))"},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"core-inputs","dir":"Articles","previous_headings":"","what":"Core inputs","title":"Workflow: Continuous Exposure","text":"Please see Specifying Core Inputs vignette detail following core inputs.","code":"#set seed for reproducibility  set.seed(1234)  #required if you wish to use save.out = TRUE in the functions home_dir <- NA # home_dir <- '/Users/isabella/Library/CloudStorage/Box-Box/BSL General/MSMs/testing/isa' #note: no / after  #required exposure <- \"ESETA1\"  #required exposure_time_pts <- c(6, 15, 24)  #required outcome <- \"StrDif_Tot.58\"  #required; list in wide format tv_confounders <- c(                     # \"SAAmylase.6\",\"SAAmylase.15\", \"SAAmylase.24\",                     # \"MDI.6\", \"MDI.15\",                                                                 # \"RHasSO.6\", \"RHasSO.15\", \"RHasSO.24\",\"RHasSO.35\", \"RHasSO.58\",                                                              \"WndNbrhood.6\",\"WndNbrhood.15\", \"WndNbrhood.24\", #\"WndNbrhood.35\", \"WndNbrhood.58\",                                                            # \"IBRAttn.6\", \"IBRAttn.15\", \"IBRAttn.24\",                                                        # \"B18Raw.6\", \"B18Raw.15\", \"B18Raw.24\", \"B18Raw.58\",                                                                # \"HOMEETA1.6\", \"HOMEETA1.15\", \"HOMEETA1.24\", \"HOMEETA1.35\", \"HOMEETA1.58\",                                                    \"InRatioCor.6\", \"InRatioCor.15\", \"InRatioCor.24\", #\"InRatioCor.35\", \"InRatioCor.58\",                                              \"ESETA1.6\", \"ESETA1.15\", \"ESETA1.24\"# \"ESETA1.35\", \"ESETA1.58\",  #exposure variables required                                    # \"CORTB.6\", \"CORTB.15\", \"CORTB.24\",                                                                                       # \"EARS_TJo.24\", \"EARS_TJo.35\",                                                             # \"LESMnPos.24\", \"LESMnPos.35\",                                                       # \"LESMnNeg.24\", \"LESMnNeg.35\",                            # \"StrDif_Tot.35\",                      # \"StrDif_Tot.58\"                         # \"fscore.35\", \"fscore.58\"                     # , \"ESETA1.6:B18Raw.6\", \"ESETA1.6:B18Raw.15:RHasSO.6\", \"state:EARS_TJo.35\" #testing interactions )   #required ti_confounders <- c(                     # \"state\", \"BioDadInHH2\", \"PmAge2\", \"PmBlac2\", \"TcBlac2\", \"PmMrSt2\", \"PmEd2\", \"KFASTScr\",                     # \"RMomAgeU\", \"RHealth\", \"HomeOwnd\", \"SWghtLB\", \"SurpPreg\", \"SmokTotl\", \"DrnkFreq\",                     \"peri_health\",                      # \"caregiv_health\",                      \"gov_assist\"                     #, \"state:SmokTotl\", \"PmAge2:PmBlac2\", \"PmAge2:PmEd2\" #testing interaction terms )"},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"phase-1-confounder-adjustment","dir":"Articles","previous_headings":"","what":"Phase 1: Confounder Adjustment","title":"Workflow: Continuous Exposure","text":"goal first phase minimize associations confounders exposure using IPTW balancing weights. strongly advise user carefully inspect balancing formula ensure weights created evaluated appropriately step.","code":""},{"path":[]},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"step-1a--create-full-balancing-formulas-conduct-pre-balance-checking","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment > Step 1. Create Full Balancing Formulas & Conduct Pre-Balance Checking","what":"Step 1a. Create Full Balancing Formulas & Conduct Pre-Balance Checking","title":"Workflow: Continuous Exposure","text":"first create comprehensive, full balancing formulas relating exposure confounders time point using createFormulas() function (type = “full”). step creates full formulas containing measured confounding variables exposure time point, including time-invariant confounders, lagged time-varying confounders, well past levels exposure outcome (make sure listed time-varying confounders). code automatically excludes time-varying confounders contemporaneous time point given decisively differentiated mediators balanced (Thoemmes & Ong, 2016), although can modified user strong reason believe concurrent variable mediator (see ). include interactions covariates balancing formulas, please list composed time invariant covariates (e.g., “variable:variable” “variable.t:variable.t”) time invariant confounders, composed time-varying covariates (e.g., “variable.t:variable” “variable.t:variable.t”) time-varying confounders list. Interactions containing time-varying covariates treated time-varying confounders measured highest measurement time point constituent time points. note, interactions factor variables multiple levels can produce large number additional variables balancing formulas. required input create full balancing formulas using createFormulas() function : exposure (e.g., “variable”), exposure time points, outcome (e.g., “variable.time”), list time-varying confounders (e.g. “variable.time”), list time invariant confounders (e.g., “variable”), setting type = “full”. Optional inputs create full balancing formulas using createFormulas() function follows. concur_conf: list, provide names time-varying confounders (e.g., “variable.time”) wish included concurrently balancing formulas (overriding default include lagged confounders). user may also specify list custom formulas specifying custom list formulas, one exposure time point (e.g., “exposure.time ~ variable.time + variable +…”) formula format, entry named formula type exposure time point (e.g., “full_form-6”). abridged example shown . createFormulas() function automatically check custom formulas ensure correctly formatted formula exposure time point exposure dependent variable. However, user responsible ensuring custom formulas contain appropriate confounders formula type generating. createFormulas function saves .csv .rds files containing balancing formulas exposure time point specified type (“full”) ‘formulas/full/’ folder. function returns list formulas labeled type, exposure, outcome, exposure time point.","code":"concur_conf <- \"B18Raw.15\"  concur_conf <- NULL #empirical example custom <- list(\"full_form-6\" = as.formula(\"ESETA1.6 ~ BioDadInHH2 + DrnkFreq + gov_assist\"),                \"full_form-15\" = as.formula(\"ESETA1.15 ~ BioDadInHH2 + DrnkFreq + gov_assist\") )   custom <- NULL type <- \"full\"  full_formulas <- createFormulas(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, #required                                 type = type, ti_confounders = ti_confounders, tv_confounders = tv_confounders, #required                                 concur_conf = concur_conf, custom = custom, #optional                                 home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for ESETA1 - StrDif_Tot.58 at ESETA1 time point 6 is:  #> ESETA1.6 ~ gov_assist + peri_health #> <environment: 0x55f8565c2db8> #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for ESETA1 - StrDif_Tot.58 at ESETA1 time point 15 is:  #> ESETA1.15 ~ ESETA1.6 + gov_assist + InRatioCor.6 + peri_health +  #>     WndNbrhood.6 #> <environment: 0x55f8565c2db8> #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for ESETA1 - StrDif_Tot.58 at ESETA1 time point 24 is:  #> ESETA1.24 ~ ESETA1.15 + ESETA1.6 + gov_assist + InRatioCor.15 +  #>     InRatioCor.6 + peri_health + WndNbrhood.15 + WndNbrhood.6 #> <environment: 0x55f8565c2db8>"},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"b--conduct-exploratory-pre-balance-assessment","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment > Step 1. Create Full Balancing Formulas & Conduct Pre-Balance Checking","what":"1b. Conduct Exploratory Pre-Balance Assessment","title":"Workflow: Continuous Exposure","text":"next step examines initial imbalance, strongly exposure relates confounder time point, measured confounders prior weighting using assessBalance() function (type = “prebalance”). function draws calcBalStats() function (see Assessing Balance Time-Varying Exposure section accompanyingm manuscript. assessBalance() function outputs balance statistics (correlations continuous exposures standardized mean differences binary exposures) relating exposure time point confounders table well plots. function also provides summary balance statistics averaging across time points (imputed datasets supplied). required inputs using assessBalance() function conduct pre balance testing : data (data frame, mids object, list imputed datasets dataframes wide format), exposure (e.g., “variable”), exposure time points, outcome (e.g., “variable.time”), full formulas (see Step 1a), set type = “prebalance”. optional inputs follows. user may specify balance_thresh: provide single number value (0-1) absolute value standardized balance statistic (either correlation continuous exposures standardized group mean difference binary exposures) exposure confounders confounders considered balanced considered imbalanced (default 0.1; Stuart, 2010). user also option supply list two values indicating different thresholds important less important confounders, respectively, accompanied list important confounders (time-varying: “variable.t”, time invariant: “variable”) imp_conf field. recommend thresholds 0.05 0.1 important less important confounders, respectively. relative importance confounders determined based existing theory conceptual consideration. specification balance threshold(s) kept consistent throughout use devMSMs package. assessBalance() function saves following .csv .html files ‘balance/prebalance’ folder: tables balance statistics confounders, tables balance statistics covariates imbalanced, overall balance summary table (averaged across imputed datasets). Within ‘balance/prebalance/plots’ folder, function outputs .jpeg files summary love plots depicting confounder balance exposure time point. function returns data frame (list) balance statistics, balance thresholds, binary balanced tag confounder relevant exposure time point.  ### Step 2: Create Simplified Balancing Formulas & Determine Optimal Weighting Method goal second step create shortened, parsimonious balancing formulas determining optimal IPTW weighting method successfully reduces imbalance.","code":"balance_thresh <- c(0.05, 0.1)   imp_conf <- c(\"InRatioCor.6\", \"InRatioCor.15\", \"InRatioCor.24\") #\"InRatioCor.35\", \"InRatioCor.58\", \"PmEd2\") type <- \"prebalance\"  formulas <- full_formulas  prebalance_stats <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts,                                    outcome = outcome, type = type, formulas = formulas, #required                                   balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                   home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point prior to weighting, using full formulas. #> As shown below, 9 out of 15 (60%) covariates across time points, corresponding to 4 out of 5 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.16 (range= -0.29-0.2): #>  #> Table: Imbalanced covariates using no weights and full formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        6|          2|            0|  2| #> |       15|          1|            4|  5| #> |       24|          3|            5|  8| #>  #>  #> USER ALERT: For exposure ESETA1 using the full formulas and no weights : #> The median absolute value relation between exposure and confounder is 0.11 (range = -0.29 -0.2).  #> As shown below, the following 9 covariates across time points out of 15 total (60%) spanning 4 domains out of 5 (80%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to ESETA1 of 0.16 (range=-0.29-0.2) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate     |    avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:-------------|----------:|----------:|--------:| #> |3  |ESETA1   |       15|          6|ESETA1.6      | -0.1036733|       0.10|        0| #> |4  |ESETA1   |       15|          0|gov_assist    | -0.2855708|       0.10|        0| #> |5  |ESETA1   |       15|          6|InRatioCor.6  | -0.2211794|       0.05|        0| #> |7  |ESETA1   |       15|          6|WndNbrhood.6  | -0.1575828|       0.10|        0| #> |8  |ESETA1   |       24|         15|ESETA1.15     |  0.1060069|       0.10|        0| #> |10 |ESETA1   |       24|          0|gov_assist    |  0.2007857|       0.10|        0| #> |11 |ESETA1   |       24|         15|InRatioCor.15 | -0.1510357|       0.05|        0| #> |12 |ESETA1   |       24|          6|InRatioCor.6  |  0.1280941|       0.05|        0| #> |14 |ESETA1   |       24|         15|WndNbrhood.15 | -0.2424655|       0.10|        0|"},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"a--create-simplified-balancing-formulas","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment > Step 1. Create Full Balancing Formulas & Conduct Pre-Balance Checking","what":"2a. Create Simplified Balancing Formulas","title":"Workflow: Continuous Exposure","text":"First, create shorter, parsimonious balancing formulas relating exposure confounders time point using createFormulas() function (type = ”short”). formulas contain time-varying confounders measured t-1 lag exposure time point. logic balancing confounders recent prior time point (t-1 ) may achieve balance levels distal time points given stability many confounders time. Importantly, empirically assess relax assumption needed subsequent step. See Step 1a instructions include confounder interactions. required input create shortened balancing formulas using createFormulas() function exposure (e.g., “variable”), exposure time points, outcome (e.g., “variable.time”), list time-varying confounders (e.g., “variable.time”), list time invariant confounders, setting type = “short”. addition optional input outlined Step 1a, user also option specify keep_conf, list time-varying confounders (e.g., “variable.t”) always retain formulas exposure measured subsequent time point. user may use argument retain specific time-varying confounders otherwise may excluded step occur lags greater t-1 formula. createFormulas() function saves .csv .rds files containing balancing formulas exposure time point (e.g., see ) specified type (case, “short”) ‘formulas/short’ folder. function returns list balancing formulas labeled type, exposure, outcome, exposure time point.","code":"keep_conf <- \"InRatioCor.6\"  keep_conf  <-  NULL type <- \"short\"   short_formulas <- createFormulas(exposure = exposure, exposure_time_pts = exposure_time_pts,                                   outcome = outcome, type = type, ti_confounders = ti_confounders,                                   tv_confounders = tv_confounders, concur_conf = concur_conf,                                   keep_conf = keep_conf, custom = custom,                                   home_dir = home_dir, verbose = verbose, save.out = save.out)  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for ESETA1 - StrDif_Tot.58 at ESETA1 time point 6 is:  #> ESETA1.6 ~ gov_assist + peri_health #> <environment: 0x55f8550c5428> #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for ESETA1 - StrDif_Tot.58 at ESETA1 time point 15 is:  #> ESETA1.15 ~ ESETA1.6 + gov_assist + InRatioCor.6 + peri_health +  #>     WndNbrhood.6 #> <environment: 0x55f8550c5428> #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for ESETA1 - StrDif_Tot.58 at ESETA1 time point 24 is:  #> ESETA1.24 ~ ESETA1.15 + gov_assist + InRatioCor.15 + peri_health +  #>     WndNbrhood.15 #> <environment: 0x55f8550c5428>"},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"b--create-iptw-balancing-weights-using-multiple-weighting-methods","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment > Step 1. Create Full Balancing Formulas & Conduct Pre-Balance Checking","what":"2b. Create IPTW Balancing Weights using Multiple Weighting Methods","title":"Workflow: Continuous Exposure","text":"created shorter, simplified balancing formulas now create first round IPTW balancing weights (Thoemmes & Ong, 2016) using createWeights() function, shortened balancing formulas, available weighting methods. function calls weightitMSM() function WeightIt package (Greifer, 2023) uses time-specific formulas create weights time point automatically multiplies together create one weight per person. Weights stabilized, recommended (Cole & Hernan, 2008; Thoemmes & Ong, 2016), distributions saved inspection. required inputs using createWeights() function create initial around IPTW balancing weights : data (data frame, mids object, list imputed datasets dataframes wide format), exposure (e.g., “variable”), outcome (e.g., “variable.time”), provide short formulas (see Step 2a). optional inputs follows. method, provide one following methods calculating balancing weights use weightitMSM() validated longitudinal exposures: “cbps” (Covariate Balancing Propensity Score weighting; default), “gbm” (generalized boosted model), “glm” (generalized linear model), “super” (SuperLearner via SuperLearner package; Polley et al., 2013). createWeights() function can also take number additional arguments passed weightitMSM () function (e.g., ‘ints’, ‘criterion’, distribution’, ‘SL.library’). instance, user wishes include first-order interactions supplied covariates weights model, can include argument ints = TRUE. user selects SuperLearner (“super”) method, default super learner library (‘SL.library’) xx alternative library can entered input createWeights function. binary exposures, “cbps” method allows specify estimand either ATE, ATT, ATC. “glm”, “super”, “bart” can specify ATE, ATT, ATC, ATO, ATM, ATOS. “gbm” can specify ATE, ATT, ATC, ATO, ATM. default estimand binary exposures ATE. advise interested user review WeightIt documentation information additional optional arguments available weighting methods. user can also specify read_in_from_file = TRUEif user previously created weights data, formula, weight type using function wishes read local file instead recreating . createWeights() function automatically conducts basic checks saved weights match data type, weights method, number formulas provided. user responsible making sure weights created appropriately. createWeights() function saves .rds file weights ‘weights’ folder, histogram weights distribution ‘weights/histograms’ folder, .csv file data weights appended ‘weights/values/’ folder. function returns list weights objects form WeightItMSM output single nested list (labeled “0” data data frame format) nested lists imputed dataset (data imputed).  create IPTW balancing weights using available methods.","code":"method <- \"cbps\" weights.cbps <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required                               method = method, read_in_from_file = FALSE,  #optional                               home_dir = home_dir, verbose = verbose, save.out = save.out)  #optional #> For the cbps weighting method, the median weight value is 0.98 (SD = 1; range = 0.16-6). method <- \"glm\" weights.glm <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required                              method = method, read_in_from_file = FALSE, #optional                              home_dir = home_dir, verbose = verbose, save.out = save.out)  #optional #> For the glm weighting method, the median weight value is 0.86 (SD = 0.69; range = 0.37-5). method <- \"gbm\" weights.gbm <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required                              method = method, read_in_from_file = FALSE,  #optional                              home_dir = home_dir, verbose = verbose, save.out = save.out)  #optional #> For the gbm weighting method, the median weight value is 0.29 (SD = 0.17; range = 0.15-1). method <- \"bart\" weights.bart <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required                               method = method, read_in_from_file = FALSE, #optional                               home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> For the bart weighting method, the median weight value is 0.67 (SD = 0.22; range = 0.37-1). method <- \"super\" weights.super <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required                                method = method, read_in_from_file = FALSE, #optional                                home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Loading required package: nnls #> Warning: All algorithms have zero weight #> Warning: All metalearner coefficients are zero, predictions will all be equal #> to 0 #> Warning: All algorithms have zero weight #> Warning: All metalearner coefficients are zero, predictions will all be equal #> to 0 #> Warning: All algorithms have zero weight #> Warning: All metalearner coefficients are zero, predictions will all be equal #> to 0 #> For the super weighting method, the median weight value is 0.99 (SD = 0.14; range = 0.8-2)."},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"c--assess-all-weighting-methods-to-determine-optimal-method","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment > Step 1. Create Full Balancing Formulas & Conduct Pre-Balance Checking","what":"2c. Assess All Weighting Methods to Determine Optimal Method","title":"Workflow: Continuous Exposure","text":"Next, evaluate well weights created using different weighting methods reduced imbalance confounders provided short balancing formula using assessBalance() function (type = “weighted”). function calls calcBalStats() function using short formulas specifying balance statistics calculated using IPTW weights just created. assessBalance() function outputs balance statistics (correlations continuous exposures standardized mean differences binary exposures) relating exposure time point confounders table well plots. function also provides summary balance statistics averaging across time points (imputed datasets supplied). required inputs using assessBalance() function assess balance first round IPTW weights : data (data frame, mids object, list imputed datasets dataframes wide format), exposure (e.g., “variable”), exposure time points, outcome (e.g., “variable.time”), providing short formulas (see Step 2a), setting type = “weighted”, providing weights just created. optional inputs described Step 1b. assessBalance() function saves following .csv .html files ‘balance/weighted’ folder: tables balance statistics confounders, tables balance statistics covariates imbalanced, overall balance summary table (averaged across imputed datasets). Within ‘balance/weighted/plots’ folder, function outputs .jpeg files summary love plots depicting confounder balance exposure time point. function returns data frame (list) balance statistics, balance thresholds, binary balanced tag (1 = balanced, 0 = imbalanced) confounder relevant exposure time point. next assess balance weighting method.  CBPS weighting method, …  GLM weighting method, …  GBM weighting method, …  BART weighting method, …  SuperLearner weighting method, … optimal weighting method dataset method yields best confounder balance. iterations, identify best performing weighting method reduces imbalance exposure confounder indicated lowest median correlation/standardized mean difference fewest number confounders left imbalanced. example, …","code":"type <- \"weighted\"  formulas <- short_formulas  weights <- weights.cbps   balance_stats.cbps <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required                                     outcome = outcome, type = type, formulas = formulas, weights = weights, #required                                     balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                     home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using short formulas. #> No covariates remain imbalanced using cbps and short formulas.  #>  #>  #> USER ALERT: For exposure ESETA1 using the short formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.04 (range = -0.07 -0.08).  #> There are no imbalanced covariates.  #> There are no imbalanced covariates. weights <- weights.glm  balance_stats.glm <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required                                    outcome = outcome, type = type, formulas = formulas, weights = weights, #required                                    balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                    home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using short formulas. #> As shown below, 5 out of 12 (42%) covariates across time points, corresponding to 4 out of 4 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.11 (range= -0.13-0.13): #>  #> Table: Imbalanced covariates using glm and short formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        6|          2|            0|  2| #> |       15|          4|            1|  5| #> |       24|          1|            4|  5| #>  #>  #> USER ALERT: For exposure ESETA1 using the short formulas and glm : #> The median absolute value relation between exposure and confounder is 0.06 (range = -0.13 -0.13).  #> As shown below, the following 5 covariates across time points out of 12 total (41.67%) spanning 4 domains out of 5 (80%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to ESETA1 of 0.11 (range=-0.13-0.13) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate     |    avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:-------------|----------:|----------:|--------:| #> |4  |ESETA1   |       15|          0|gov_assist    | -0.1271898|       0.10|        0| #> |8  |ESETA1   |       24|         15|ESETA1.15     |  0.1046704|       0.10|        0| #> |9  |ESETA1   |       24|          0|gov_assist    |  0.1271220|       0.10|        0| #> |10 |ESETA1   |       24|         15|InRatioCor.15 | -0.0638417|       0.05|        0| #> |12 |ESETA1   |       24|         15|WndNbrhood.15 | -0.1057293|       0.10|        0| weights <- weights.gbm  balance_stats.gbm <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required                                    outcome = outcome, type = type, formulas = formulas, weights = weights, #required                                    balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                    home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using short formulas. #> As shown below, 6 out of 12 (50%) covariates across time points, corresponding to 4 out of 4 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.19 (range= -0.21-0.21): #>  #> Table: Imbalanced covariates using gbm and short formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        6|          2|            0|  2| #> |       15|          2|            3|  5| #> |       24|          2|            3|  5| #>  #>  #> USER ALERT: For exposure ESETA1 using the short formulas and gbm : #> The median absolute value relation between exposure and confounder is 0.09 (range = -0.21 -0.21).  #> As shown below, the following 6 covariates across time points out of 12 total (50%) spanning 4 domains out of 5 (80%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to ESETA1 of 0.19 (range=-0.21-0.21) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate     |    avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:-------------|----------:|----------:|--------:| #> |3  |ESETA1   |       15|          6|ESETA1.6      | -0.1198117|       0.10|        0| #> |4  |ESETA1   |       15|          0|gov_assist    | -0.1895557|       0.10|        0| #> |5  |ESETA1   |       15|          6|InRatioCor.6  | -0.0689999|       0.05|        0| #> |9  |ESETA1   |       24|          0|gov_assist    |  0.2143327|       0.10|        0| #> |10 |ESETA1   |       24|         15|InRatioCor.15 | -0.2080718|       0.05|        0| #> |12 |ESETA1   |       24|         15|WndNbrhood.15 | -0.1968617|       0.10|        0| weights <- weights.bart  balance_stats.bart <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required                                     outcome = outcome, type = type, formulas = formulas, weights = weights, #required                                     balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                     home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using short formulas. #> As shown below, 5 out of 12 (42%) covariates across time points, corresponding to 3 out of 4 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.18 (range= -0.25-0.18): #>  #> Table: Imbalanced covariates using bart and short formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        6|          2|            0|  2| #> |       15|          3|            2|  5| #> |       24|          2|            3|  5| #>  #>  #> USER ALERT: For exposure ESETA1 using the short formulas and bart : #> The median absolute value relation between exposure and confounder is 0.09 (range = -0.25 -0.18).  #> As shown below, the following 5 covariates across time points out of 12 total (41.67%) spanning 3 domains out of 5 (60%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to ESETA1 of 0.18 (range=-0.25-0.18) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate     |    avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:-------------|----------:|----------:|--------:| #> |4  |ESETA1   |       15|          0|gov_assist    | -0.1949788|       0.10|        0| #> |5  |ESETA1   |       15|          6|InRatioCor.6  | -0.1323095|       0.05|        0| #> |9  |ESETA1   |       24|          0|gov_assist    |  0.1843212|       0.10|        0| #> |10 |ESETA1   |       24|         15|InRatioCor.15 | -0.1312711|       0.05|        0| #> |12 |ESETA1   |       24|         15|WndNbrhood.15 | -0.2469846|       0.10|        0| weights <- weights.super   balance_stats.super <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required                                      outcome = outcome, type = type, formulas = formulas, weights = weights, #required                                      balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                      home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using short formulas. #> As shown below, 8 out of 12 (67%) covariates across time points, corresponding to 4 out of 4 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.2 (range= -0.29-0.21): #>  #> Table: Imbalanced covariates using super and short formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        6|          2|            0|  2| #> |       15|          1|            4|  5| #> |       24|          1|            4|  5| #>  #>  #> USER ALERT: For exposure ESETA1 using the short formulas and super : #> The median absolute value relation between exposure and confounder is 0.14 (range = -0.29 -0.21).  #> As shown below, the following 8 covariates across time points out of 12 total (66.67%) spanning 4 domains out of 5 (80%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to ESETA1 of 0.2 (range=-0.29-0.21) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate     |    avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:-------------|----------:|----------:|--------:| #> |3  |ESETA1   |       15|          6|ESETA1.6      | -0.1138513|       0.10|        0| #> |4  |ESETA1   |       15|          0|gov_assist    | -0.2946042|       0.10|        0| #> |5  |ESETA1   |       15|          6|InRatioCor.6  | -0.2129990|       0.05|        0| #> |7  |ESETA1   |       15|          6|WndNbrhood.6  | -0.1584391|       0.10|        0| #> |8  |ESETA1   |       24|         15|ESETA1.15     |  0.1277776|       0.10|        0| #> |9  |ESETA1   |       24|          0|gov_assist    |  0.2078415|       0.10|        0| #> |10 |ESETA1   |       24|         15|InRatioCor.15 | -0.1892340|       0.05|        0| #> |12 |ESETA1   |       24|         15|WndNbrhood.15 | -0.2667074|       0.10|        0|"},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"step-3-create-updated-formulas-re-specify-weights-using-optimal-weighting-method","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment","what":"Step 3: Create Updated Formulas & Re-Specify Weights Using Optimal Weighting Method","title":"Workflow: Continuous Exposure","text":"goal next step assess weights best-performing weights method, created shortened balancing formulas (containing time-varying confounders t-1), relative full balancing formulas, add shortened formulas time-varying confounders lags > t-1 successfully balanced create final round weights.","code":""},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"a--assess-balance-with-full-balancing-formulas","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment > Step 3: Create Updated Formulas & Re-Specify Weights Using Optimal Weighting Method","what":"3a. Assess balance with full balancing formulas","title":"Workflow: Continuous Exposure","text":"next assess whether weights created previous step best-performing weights method (e.g., x) using simplified balancing formulas also achieve balance confounders full formulas. use assessBalance() function (type = “weighted”) full balancing formulas examine successfully best-performing weights created previous step achieve balance time-varying confounders. revisit assumption balancing proximal time-varying confounders (t-1) confers balance confounders distal prior time points (t-1+). assessing time point well weights just created using short formulas successfully balance confounders (including time-varying confounders time points prior) original, full formulas. required inputs using assessBalance() function assess best weights achieve balance full formulas : data (data frame, mids object, list imputed datasets dataframes wide format), exposure (e.g., “variable”), exposure time points, outcome (e.g., “variable.time”), providing full formulas (see Step 1a), setting type = “weighted”, providing best weights (see Step 2c). optional inputs detailed Step 1b. assessBalance() function saves following .csv .html files ‘balance/weighted’ folder: tables balance statistics confounders, tables balance statistics covariates imbalanced, overall balance summary table (averaged across imputed datasets). Within ‘balance/type/plots’ folder, function outputs .jpeg files summary love plots depicting confounder balance exposure time point. function returns data frame (list) balance statistics, balance thresholds, binary balanced tag confounder relevant exposure time point.  Using x weighting method full formulas, find… #### 3b. Update simplified formulas Subsequently, create final round balancing formulas using createFormulas() function (setting type = “update\" providing balance statistics bal_stats field). update shortened formulas include time-varying confounders (t-1 +) successfully balanced weights created using original simplified formulas. createFormulas() function draws user-provided balance statistics automatically identify add formulas exposure time point time-varying confounders lags greater 1 remain imbalanced weighting. function displays balancing formula console message user time-varying confounders added. required input update shortened balancing formulas imbalanced time-varying confounders greater lags using createFormulas() function : exposure (e.g., “variable”), exposure time points, outcome (e.g., “variable.time”), list time-varying confounders (e.g., “variable.time”), list time invariant confounders, setting type = “update”, providing bal_stats balance statistics just created. optional input detailed Step 1a. createFormulas() function saves .csv .rds files containing balancing formulas exposure time point specified type ‘formulas/update’ folder. function returns list balancing formulas labeled type, exposure, outcome, exposure time point.","code":"type <- \"weighted\"  formulas <- full_formulas  weights <- weights.cbps  balance_stats <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required                                outcome = outcome, type = type, formulas = formulas, weights = weights, #required                                balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using full formulas. #> As shown below, 1 out of 15 (7%) covariates across time points, corresponding to 1 out of 5 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.11 (range= 0.11-0.11): #>  #> Table: Imbalanced covariates using cbps and full formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        6|          2|            0|  2| #> |       15|          5|            0|  5| #> |       24|          7|            1|  8| #>  #>  #> USER ALERT: For exposure ESETA1 using the full formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.04 (range = -0.07 -0.11).  #> As shown below, the following 1 covariates across time points out of 15 total (6.67%) spanning 1 domains out of 5 (20%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to ESETA1 of 0.11 (range=0.11-0.11) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate    |   avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:------------|---------:|----------:|--------:| #> |12 |ESETA1   |       24|          6|InRatioCor.6 | 0.1076746|       0.05|        0| type <- \"update\"  bal_stats <- balance_stats  updated_formulas <- createFormulas(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, #required                                    type = type, ti_confounders = ti_confounders, tv_confounders = tv_confounders, bal_stats = bal_stats, #required                                    concur_conf = concur_conf, keep_conf = keep_conf, #optional                                    home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: Please manually inspect the updated balancing formula below that includes time-varying confounders at t-1 and those greater at further lags that remained imbalanced: #> The update formula for ESETA1 - StrDif_Tot.58 at ESETA1 time point 6 is:  #> ESETA1.6 ~ gov_assist + peri_health #> <environment: 0x55f85aefbdb8> #> USER ALERT: Please manually inspect the updated balancing formula below that includes time-varying confounders at t-1 and those greater at further lags that remained imbalanced: #> For ESETA1 at exposure time point 15 no time-varying confounders at additional lags were added.  #>  #> The update formula for ESETA1 - StrDif_Tot.58 at ESETA1 time point 15 is:  #> ESETA1.15 ~ ESETA1.6 + gov_assist + InRatioCor.6 + peri_health +  #>     WndNbrhood.6 #> <environment: 0x55f85aefbdb8> #> USER ALERT: Please manually inspect the updated balancing formula below that includes time-varying confounders at t-1 and those greater at further lags that remained imbalanced: #> For ESETA1 at exposure time point 24 the following covariate(s) will be added to the short balancing formula: #>                           InRatioCor.6  #>  #> The update formula for ESETA1 - StrDif_Tot.58 at ESETA1 time point 24 is:  #> ESETA1.24 ~ ESETA1.15 + gov_assist + InRatioCor.15 + InRatioCor.6 +  #>     peri_health + WndNbrhood.15 #> <environment: 0x55f85aefbdb8>"},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"c--create-final-balancing-weights","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment > Step 3: Create Updated Formulas & Re-Specify Weights Using Optimal Weighting Method","what":"3c. Create final balancing weights","title":"Workflow: Continuous Exposure","text":"Next, create final set balancing weights using optimal weighting method identified Step 2c final, updated simplified formulas previous step using createWeights() function (method = “x’), ‘x’ optimal weighting method identified Step 2c. function calls weightitMSM() function WeightIt package (Greifer, 2023) uses time-specific formulas create weights time point automatically multiplies together create one weight per person. Weights stabilized, recommended (Cole & Hernan, 2008; Thoemmes & Ong, 2016) distributions saved home directory inspection. required inputs using createWeights() function create final round IPTW balancing weights using updated short balancing formulas : data (data frame, mids object, list imputed datasets dataframes wide format), exposure (variable time points), outcome (e.g., “variable.time”), providing best-performing weights method, providing updated formulas (see Step 3a). optional input createWeights() function listed Step 2b. createWeights function saves .rds file weights ‘weights’ folder, histogram weights distribution ‘weights/histograms’ folder, .csv file data weights appended ‘weights/values/’ folder. function returns list weights objects form WeightItMSM output list weights either single nested list (labeled “0” data data frame format) nested lists imputed dataset (data imputed).","code":"formulas <- updated_formulas  method <- \"cbps\"  #all inputs final_weights <- createWeights(data = data, exposure = exposure, outcome = outcome, formulas = formulas, #required                                method = method, read_in_from_file = FALSE, #optional                                home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> For the cbps weighting method, the median weight value is 0.92 (SD = 0.99; range = 0.19-7)."},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"d--trim-final-balancing-weights","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment > Step 3: Create Updated Formulas & Re-Specify Weights Using Optimal Weighting Method","what":"3d. Trim final balancing weights","title":"Workflow: Continuous Exposure","text":"next step trim winsorize final set weights eliminate heavy right tail distribution using trimWeights() function draws Weightit package (Griefer, 2023) plots summarizes trimmed weights. function outputs list trimmed weights either single nested list (labeled “0” data data frame format) nested lists imputed dataset (data imputed). required inputs trimWeights() function : exposure (variable time points), outcome (e.g., “variable.time”), final weights just created. optional inputs follows. user option specify quantile value (0-1; default 0.95) weights replaced weight value quantile reduce heavy right tail. trimWeights function saves .rds file trimmed weights ‘weights/values’ folder histogram trimmed weights (Figure x) ‘weights/histograms’ folder. function returns list weights objects, containing trimmed weights, form weightitMSM output.  create trimmed weights using two quantile values + /- ~0.3 previously chosen quantile value order conduct recommended sensitivity analyses subsequent steps. first create weights 92nd quantile value.  98th quantile value.  find comparable descriptive statistics sets weights, upper range value varying quantile cutoff. sets weights heavy right tails, expected real-world data. tails represent individuals experienced statistically unexpected levels exposure given levels confounders.","code":"quantile <- 0.95 weights <- final_weights  trim_weights <- trimWeights(exposure = exposure, outcome = outcome, weights = weights, #required                             quantile = quantile, #optional                             home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Trimming weights to 95%. #>  #> For the ESETA1-StrDif_Tot.58 relation, following trimming at the 0.95 quantile, the median weight value is 0.92 (SD= 0.58; range= 0.19-2). quantile <- 0.92   trim_weights.s1 <- trimWeights(exposure = exposure, outcome = outcome, weights = weights, #required                                quantile = quantile, #optional                                home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Trimming weights to 92%. #>  #> For the ESETA1-StrDif_Tot.58 relation, following trimming at the 0.92 quantile, the median weight value is 0.92 (SD= 0.58; range= 0.19-2). quantile <- 0.98   trim_weights.s2 <- trimWeights(exposure = exposure, outcome = outcome, weights = weights, #required                                quantile = quantile, #optional                                home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Trimming weights to 98%. #>  #> For the ESETA1-StrDif_Tot.58 relation, following trimming at the 0.98 quantile, the median weight value is 0.92 (SD= 0.65; range= 0.19-3)."},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"step-4-conduct-final-balance-assessment","dir":"Articles","previous_headings":"Phase 1: Confounder Adjustment","what":"Step 4: Conduct Final Balance Assessment","title":"Workflow: Continuous Exposure","text":"created trimmed finalized set IPTW balancing weights, next step conduct final evaluation well reduce imbalance possible confounders. assess performance final weights previous step using assessBalance() function (type = “weighted”) full formulas. required inputs using assessBalance() function assess final, trimmed weights achieve balance full formulas : data (data frame, mids object, list imputed datasets dataframes wide format), exposure (e.g., “variable”), exposure time points, outcome (e.g., “variable.time”), provide full formulas (see Step 1a), set type = “weighted”, provide final, trimmed weights (see Step 3b). optional inputs assessBalance() function detailed Step 1b. assessBalance() function saves following .csv .html files ‘balance/weighted’ folder: tables balance statistics confounders, tables balance statistics covariates imbalanced, overall balance summary table (averaged across imputed datasets). Within ‘balance/weighted/plots’ folder, function outputs .jpeg files summary love plots depicting confounder balance exposure time point. function returns data frame (list) balance statistics, balance thresholds, binary balanced tag confounder relevant exposure time point.  assessment, find… step, user must manually list confounders time invariant measured first time point (6 months) remain imbalanced following final balance assessment covariates. can supplied selecting covariate model Step 5 account remaining confounding. also assess balance weights trimmed two additional quantile values assess whether final balance assessment sensitive trim value. Importantly, save.= TRUE, running analyses overwrite output main history comparison main output rename re-located new folder first. Additionally, running first sensitivity check, output check overwritten second sensitivity check renamed re-located new folder first. first assess balance weights trimmed 93rd quantile value.  , find… next assess balance weights trimmed 98th quantile value.  , find… Overall, sensitivity analyses indicate….","code":"type <- \"weighted\"  formulas <- full_formulas  weights <- trim_weights  final_balance_stats <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required                                      outcome = outcome, type = type, formulas = formulas, weights = weights, #required                                      balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                      home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using full formulas. #> As shown below, 2 out of 15 (13%) covariates across time points, corresponding to 2 out of 5 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.14 (range= -0.11-0.18): #>  #> Table: Imbalanced covariates using cbps and full formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        6|          2|            0|  2| #> |       15|          4|            1|  5| #> |       24|          7|            1|  8| #>  #>  #> USER ALERT: For exposure ESETA1 using the full formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.06 (range = -0.11 -0.18).  #> As shown below, the following 2 covariates across time points out of 15 total (13.33%) spanning 2 domains out of 5 (40%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to ESETA1 of 0.14 (range=-0.11-0.18) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate    |    avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:------------|----------:|----------:|--------:| #> |4  |ESETA1   |       15|          0|gov_assist   | -0.1079103|       0.10|        0| #> |12 |ESETA1   |       24|          6|InRatioCor.6 |  0.1776353|       0.05|        0| covariates <- c(\"ESETA1.6\", \"gov_assist\")# \"B18Raw.6\") weights <- trim_weights.s1  final_balance_stats.s1 <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required                                         outcome = outcome, type = type, formulas = formulas, weights = weights, #required                                         balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                         home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using full formulas. #> As shown below, 2 out of 15 (13%) covariates across time points, corresponding to 2 out of 5 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.14 (range= -0.11-0.18): #>  #> Table: Imbalanced covariates using cbps and full formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        6|          2|            0|  2| #> |       15|          4|            1|  5| #> |       24|          7|            1|  8| #>  #>  #> USER ALERT: For exposure ESETA1 using the full formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.06 (range = -0.11 -0.18).  #> As shown below, the following 2 covariates across time points out of 15 total (13.33%) spanning 2 domains out of 5 (40%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to ESETA1 of 0.14 (range=-0.11-0.18) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate    |    avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:------------|----------:|----------:|--------:| #> |4  |ESETA1   |       15|          0|gov_assist   | -0.1083011|       0.10|        0| #> |12 |ESETA1   |       24|          6|InRatioCor.6 |  0.1777094|       0.05|        0| weights <- trim_weights.s2  final_balance_stats.s2 <- assessBalance(data = data, exposure = exposure, exposure_time_pts = exposure_time_pts, #required                                         outcome = outcome, type = type, formulas = formulas, weights = weights, #required                                         balance_thresh = balance_thresh, imp_conf = imp_conf, #optional                                         home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using full formulas. #> As shown below, 1 out of 15 (7%) covariates across time points, corresponding to 1 out of 5 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.18 (range= 0.18-0.18): #>  #> Table: Imbalanced covariates using cbps and full formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        6|          2|            0|  2| #> |       15|          5|            0|  5| #> |       24|          7|            1|  8| #>  #>  #> USER ALERT: For exposure ESETA1 using the full formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.06 (range = -0.09 -0.18).  #> As shown below, the following 1 covariates across time points out of 15 total (6.67%) spanning 1 domains out of 5 (20%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to ESETA1 of 0.18 (range=0.18-0.18) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate    |   avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:------------|---------:|----------:|--------:| #> |12 |ESETA1   |       24|          6|InRatioCor.6 | 0.1846974|       0.05|        0|"},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"phase-2-assess-substantive-associations-between-exposure-outcome","dir":"Articles","previous_headings":"","what":"Phase 2: Assess Substantive Associations between Exposure & Outcome","title":"Workflow: Continuous Exposure","text":"created IPTW balancing weights minimize attentuate associations confounders exposure time point, can move substantive modeling phase.","code":""},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"step-5-fit-marginal-structural-model-summarize-visualize-results","dir":"Articles","previous_headings":"Phase 2: Assess Substantive Associations between Exposure & Outcome","what":"Step 5: Fit Marginal Structural Model & Summarize & Visualize Results","title":"Workflow: Continuous Exposure","text":"goal final step fit weighted model user’s choosing relating exposure meaningful epochs developmental time outcome, summarizing visualizing results. step, user models compares various counterfactuals, effects different developmental histories exposure outcome, test substantive hypotheses dose timing.","code":""},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"step-5a--select-fit-a-marginal-outcome-model","dir":"Articles","previous_headings":"Phase 2: Assess Substantive Associations between Exposure & Outcome > Step 5: Fit Marginal Structural Model & Summarize & Visualize Results","what":"Step 5a. Select & fit a marginal outcome model","title":"Workflow: Continuous Exposure","text":"First, use fitModel() function fit weighted generalized linear model user’s choosing relating exposure outcome. function draws svyglm() function survey package (Lumley, 2023). user specifies exposure epochs, exposure levels averaged epochs consist two time point values. One benefits creating balancing weights can used variety different marginal outcome models encompassed function subset possible models. Note models can get complex advise interpreting individual terms. required inputs using fitModel() function : data (data frame, mids object, list imputed datasets dataframes wide format), exposure (e.g., “variable”), exposure time points, outcome (e.g., “variable.time”), list trimmed weights, model list (“m0”, “m1”, “m2”, “m3”): M0: Baseline model regressing outcome main effects exposure (e.g., infancy, toddlerhood, childhood). M1: Covariate model regressing outcome main effects exposure, well user-specified covariates (e.g., confounders measured baseline first time point remained imbalanced weighting Step 4). M2: Interaction model regressing outcome main effects exposure, well user-specified interactions exposure main effects (e.g., infancy:toddlerhood) M3: Full model regressing outcome main effects exposure, user-specified covariates, well user-specified exposure main effect interactions. select covariate model (“m1” “m3”), required supply list covariates corresponds covariates wide data wish adjust . , recommend including confounders remain imbalanced final balance assessment (Step 4) time-invariant measured first time point. select interaction model (“m2” “m3”), required provide interaction order integer int_order field reflects maximum interaction (e.g., 3) (automatically include lower order interactions (e.g., 2-way)). interaction order exceed number exposure main effects. optional inputs fitModel() function follows. user option specify epochs differ measurement time points using optional epochs data frame field. epochs: provide list user-created names quotations (constitute meaningful developmental time period constitute time units exposure histories); values: list, epoch, provide single integer list integers time points exposure measured constitute epoch. epochs specified, time points exposure measured used creation exposure histories final step process. specified epoch must corresponding value (values can differ number entries shown ). Epochs must specified step used subsequent step comparing histories, specification exposure epochs kept consistent throughout use devMSMs package. user can also specify family (function, quotations; e.g., gaussian) link (quotations, e.g., “link”) functions generalized linear model (defaults gaussian “link”, respectively). possible families : binomial, gaussian, Gama, inverse.gaussian, poisson, quasi, quasibinomial, quasipoisson. binomial Poisson families, set family quasibinomial quasipoisson, respectively, avoid warning non-integer numbers successes. `quasi’ versions family objects give point estimates standard errors give warning. gaussian family accepts links: “identity”, “log” “inverse”; binomial family links “logit”, “probit”, “cauchit”, (corresponding logistic, normal Cauchy CDFs respectively) “log” “cloglog” (complementary log-log); Gamma family links “inverse”, “identity”, “log”; poisson family links “log”, “identity”, “sqrt”; inverse.gaussian family links 1/mu^2, inverse, identity log. quasi family accepts links “logit”, “probit”, “cloglog”, “identity”, “inverse”, “log”, “1/mu^2”, “sqrt”, function power can used create power link function. See survey stats R package documentations information. fitModel() function outputs .rds file fitted model(s) .html table model evidence (can display models 12 imputed datasets) ‘models’ folder. Importantly, function also outputs console result likelihood ratio test comparing user-specified model nested version model omits exposure variables test whether exposure predicts variation outcome. test significant evidence exposure predicts outcome, advise proceeding subsequent history comparison step. Models pooled prior conducting likelihood ratio test imputed data. function returns list fitted model objects, svyglm output (labeled “0” data data frame format). find, … conduct sensitivity analyses fitting model weights trimmed two different values. note, described Step 4, save.= TRUE, running analyses overwrite output main model fitting main output rename re-located new folder first. first fit model weights trimmed 92nd quantile. find, …. fit model weights trimmed 98th quantile. find, …. general, sensitivity analyeses, find…","code":"model <- \"m2\" int_order <- NA  int_order <- 2 epochs <- data.frame(epochs = c(\"Infancy\", \"Toddlerhood\", \"Childhood\"),                       values = I(list(c(6), c(15), c(24)))) family <- gaussian  link <- \"identity\" weights <- trim_weights  models <- fitModel(data = data, weights = weights, exposure = exposure, #required                    exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required                    family = family, link = link, int_order = int_order, covariates = covariates, epochs = epochs, #optional                    home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Please inspect the following likelihood ratio test to determine if the exposures collective predict significant variation in the outcome compared to a model without exposure terms. #> We strongly suggest not conducting history comparisons if the likelihood ratio test is non-significant. #> Working (Rao-Scott+F) LRT for ESETA1.Infancy ESETA1.Toddlerhood ESETA1.Childhood ESETA1.Infancy:ESETA1.Toddlerhood ESETA1.Infancy:ESETA1.Childhood ESETA1.Toddlerhood:ESETA1.Childhood #>  in svyglm(formula = as.formula(f), design = s, family = fam) #> Working 2logLR =  17.42214 p= 0.027212  #> (scale factors:  1.8 1.6 1 0.78 0.5 0.3 );  denominator df= 43 #>  #> The marginal model, m2, is summarized below: weights <- trim_weights.s1  models.s1 <- fitModel(data = data, weights = weights, exposure = exposure, #required                       exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required                       family = family, link = link, int_order = int_order, covariates = covariates, epochs = epochs, #optional                       home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Please inspect the following likelihood ratio test to determine if the exposures collective predict significant variation in the outcome compared to a model without exposure terms. #> We strongly suggest not conducting history comparisons if the likelihood ratio test is non-significant. #> Working (Rao-Scott+F) LRT for ESETA1.Infancy ESETA1.Toddlerhood ESETA1.Childhood ESETA1.Infancy:ESETA1.Toddlerhood ESETA1.Infancy:ESETA1.Childhood ESETA1.Toddlerhood:ESETA1.Childhood #>  in svyglm(formula = as.formula(f), design = s, family = fam) #> Working 2logLR =  17.41456 p= 0.027248  #> (scale factors:  1.8 1.6 1 0.78 0.5 0.3 );  denominator df= 43 #>  #> The marginal model, m2, is summarized below: weights <- trim_weights.s2  models.s2 <- fitModel(data = data, weights = weights, exposure = exposure, #required                       exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required                       family = family, link = link, int_order = int_order, covariates = covariates, epochs = epochs, #optional                       home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Please inspect the following likelihood ratio test to determine if the exposures collective predict significant variation in the outcome compared to a model without exposure terms. #> We strongly suggest not conducting history comparisons if the likelihood ratio test is non-significant. #> Working (Rao-Scott+F) LRT for ESETA1.Infancy ESETA1.Toddlerhood ESETA1.Childhood ESETA1.Infancy:ESETA1.Toddlerhood ESETA1.Infancy:ESETA1.Childhood ESETA1.Toddlerhood:ESETA1.Childhood #>  in svyglm(formula = as.formula(f), design = s, family = fam) #> Working 2logLR =  17.96889 p= 0.024448  #> (scale factors:  1.9 1.5 1 0.77 0.49 0.28 );  denominator df= 43 #>  #> The marginal model, m2, is summarized below:"},{"path":"https://istallworthy.github.io/devMSMs/articles/Workflow_Continuous_Exposure.html","id":"step-5b--estimate-compare-and-visualize-model-predicted-outcome-as-a-function-of-exposure-history","dir":"Articles","previous_headings":"Phase 2: Assess Substantive Associations between Exposure & Outcome > Step 5: Fit Marginal Structural Model & Summarize & Visualize Results","what":"Step 5b. Estimate, compare, and visualize model-predicted outcome as a function of exposure history","title":"Workflow: Continuous Exposure","text":"final step, use fitted model results test substantive hypotheses dose timing. estimate compare average marginal estimates outcome user-specified exposure history (.e., permutation high (“h) low (“l”) levels exposure exposure epoch) using compareHistories() function. draws primarily avg_predictions() hypotheses() functions marginaleffects package (Arel-Bundock, 2023). First, function creates average predictions outcome exposure history. n combinations user-specified exposure histories, set value predictors full dataset values combination, leaving variables . gives us n datasets, size original dataset used fit model. n datasets, compute predicted values given model taking average predicted value n datasets. n averaged predicted values expected potential outcomes combination. imputed data, function outputs pooled predicted values using Rubin’s Rules. Next, using predicted values (per imputed dataset, applicable), function conducts comparisons different histories (pooling across imputed datasets imputed data using Rubin’s Rules). Lastly, function implements correction multiple comparisons (treating iteration function family) plotting results. Box plots display outcome x-axis exposure history y-axis whiskers display standard errors. required inputs using compareHistories() function : exposure (e.g., “variable”), outcome (e.g., “variable.t”), list model output Step 5a. optional inputs follows. continuous exposures, hi_lo_cut user can specify list two quantile values (0-1; default median split +/- 0.001) demarcating high low levels exposure, respectively. Imputed data stacked calculate cutoff values. suggest drawing existing hypotheses examining variability exposure variable determine high low cutoffs. recommend users begin specifying meaningful high low percentile cutoffs examining many individuals sample fall user-specified exposure histories created percentile cutoffs (see Preliminary Steps vignette). gold standard recommendations sufficient cell numbers per history, users ensure reasonable coverage histories avoid extrapolation maximize precision. Additionally, user option specify epochs differ measurement time points using optional epochs data frame field (see Step 5a ). specified epochs Step 5a fitModel() function, must specify step. user also option estimate compare custom subset user-specified exposure histories (.e., sequences high low levels exposure epoch time point) using reference comparison fields. conduct customized comparisons, users must provide least one unique valid history (e.g., “l-l-l”) reference , quotations, provide string (list strings) lowercase l’s h’s (separated -), corresponding exposure epoch (time point), signify sequence exposure levels (“low” “high”, respectively). supply reference history, comparisons provide least one unique valid history comparison , quotations, providing string (list strings) l’s h’s (separated “-”), corresponding exposure epoch, signify sequence exposure levels (“low” “high”, respectively) constitutes comparison exposure history/histories compared reference. supply one comparisons, least one reference must specified. reference exposure history compared comparison history comparisons supplied multiple comparison correction. reference comparison specified, histories compared . 4 exposure main effects (either epochs exposure time points), user required select subset history comparisons (Step 5b), given base code (see hypotheses() function marginaleffects package; Arel-Bundock, 2023) accommodate pairwise history comparisons 5 time points. user can also specify multiple comparison method mc_method quotations, providing shorthand method (“holm”, “hochberg”,“hommel”, “bonferroni”, “BH”, “”, “fdr”, “n” (see stats::p.adjust documentation; R Core Team) multiple comparison correction applied final pooled contrasts comparing effects different exposure histories outcome (default Benjamini-Hochburg). code run considered family. user iterates function specifying different comparisons time, strongly recommend interpreting outcome inclusive set comparisons avoid false discovery. Based substantive interests, user also option choose level dosage (“h” “l”) tallied labels dose counts tables figures (dose_level; default “h”). example, exposure variable coded way lower levels conceptualized exposure (e.g., lower income), user may wish choose dosage level “l”. Lastly, user can provide alternate plotting labels exposure outcome exp_lab out_lab fields (defaults variable names) well list (equal number exposure main effects +1) colors Brewer color palette (colors; default “Dark2”). See RColorBrewer::display.brewer.() https://r-graph-gallery.com/38-rcolorbrewers-palettes.html). compareHistories() function saves .html tables estimated mean outcome values history history comparisons ‘histories’ folder boxplot predicted values histories ‘plots’ folder. function returns data frame user-specified history comparisons containing contrast estimates, standard errors, statistics, p-values, low high confidence intervals, corrected p-values, labeled history dose.  find, …. conduct sensitivity analyses assessing comparing histories drawing models used weights trimmed two different values. note, running analyses overwrite output main history comparison main output rename re-located new folder first. first compare histories using model fit weights trimmed 92nd quantile value.  find, … compare histories usign model fit weights trimmed 98th quantile value.  find, … general, sensitivity analyses, find… ## References Arel-Bundock, V. 2023. marginaleffects: Predictions, Comparisons, Slopes, Marginal Means,Hypothesis Tests. https://CRAN.R-project.org/package=marginaleffects. Cole, S. R., & Hernán, M. . (2008). Constructing Inverse Probability Weights Marginal Structural Models. American Journal Epidemiology, 168(6), 656–664. https://doi.org/10.1093/aje/kwn164. Greifer, Noah. 2023.WeightIt: Weighting Covariate Balance Observational Studies. https://CRAN.R-project.org/package=WeightIt. Lumley, Thomas. 2023. “survey: Analysis Complex Survey Samples.” Polley, Eric, Erin LeDell, Chris Kennedy, Mark van der Laan. 2023. SuperLearner: SuperLearner Prediction. https://CRAN.R-project.org/package=SuperLearner. R Core Team (2013). R: language environment statistical computing. R Foundation Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URLhttp://www.R-project.org/. Stuart, E. . (2010). Matching methods causal inference: review look forward. Statistical Science: Review Journal Institute Mathematical Statistics, 25(1), 1–21. https://doi.org/10.1214/09-STS313. Thoemmes, F., & Ong, . D. (2016). Primer Inverse Probability Treatment Weighting Marginal Structural Models. https://doi.org/10.1177/2167696815621645.","code":"hi_lo_cut <- c(0.6, 0.3) reference <- \"l-l-l\"   comparison <- c(\"h-h-h\", \"h-h-l\") mc_comp_method <- \"BH\" dose_level <- \"h\" exp_lab <- \"Economic Strain\" #empirical example   out_lab <- \"Behavior Problems\" #empirical example   colors <- c(\"blue4\", \"darkgreen\", \"darkgoldenrod\", \"red2\") model <- models   results <- compareHistories(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required                             epochs = epochs, hi_lo_cut = hi_lo_cut, reference = reference, comparison = comparison, #optional                             mc_comp_method = mc_comp_method, dose_level = dose_level, exp_lab = exp_lab, out_lab = out_lab, colors = colors, #optional                             home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 6 (12%) individuals that fall into 3 out of the 3 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure ESETA1, respectively, across Infancy, Toddlerhood, Childhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure ESETA1 histories based on exposure main effects Infancy, Toddlerhood, Childhood containing time points 6, 15, 24: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  3| #> |h-h-l   |  2| #> |l-l-l   |  1| #>  #>  #> Below are the average predictions by user-specified history:  #> |   | ESETA1.Infancy| ESETA1.Toddlerhood| ESETA1.Childhood| estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history | dose_count| #> |:--|--------------:|------------------:|----------------:|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-------|----------:| #> |1  |        -0.4074|            -0.6716|          -0.6573|  -0.2638|    0.2117|   -1.2461|  0.2127|  2.2330|  -0.6788|    0.1511|l-l-l   |          0| #> |4  |         0.1704|             0.1195|          -0.6573|   0.1983|    0.1746|    1.1356|  0.2561|  1.9651|  -0.1439|    0.5405|h-h-l   |          2| #> |8  |         0.1704|             0.1195|           0.4532|   0.1005|    0.1333|    0.7541|  0.4508|  1.1494|  -0.1607|    0.3617|h-h-h   |          3| #>  #>  #> Conducting multiple comparison correction for all pairings between comparison histories and each refernece history using the BH method.  #>  #>  #> USER ALERT: please inspect the following comparisons:  #> |term                                                    | estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history        |dose   | p.value_corr| #> |:-------------------------------------------------------|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:--------------|:------|------------:| #> |(-0.4074, -0.6716, -0.6573) - (0.1704, 0.1195, 0.4532)  |     0.36|      0.19|      1.90|    0.06|    4.11|    -0.01|      0.74|l-l-l vs h-h-h |0 vs 3 |         0.06| #> |(-0.4074, -0.6716, -0.6573) - (0.1704, 0.1195, -0.6573) |     0.46|      0.15|      3.01|    0.00|    8.59|     0.16|      0.76|l-l-l vs h-h-l |0 vs 2 |         0.01| model <- models.s1   results.s1 <- compareHistories(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required                                epochs = epochs, hi_lo_cut = hi_lo_cut, reference = reference, comparison = comparison, #optional                                mc_comp_method = mc_comp_method, dose_level = dose_level, exp_lab = exp_lab, out_lab = out_lab, colors = colors, #optional                                home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 6 (12%) individuals that fall into 3 out of the 3 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure ESETA1, respectively, across Infancy, Toddlerhood, Childhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure ESETA1 histories based on exposure main effects Infancy, Toddlerhood, Childhood containing time points 6, 15, 24: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  3| #> |h-h-l   |  2| #> |l-l-l   |  1| #>  #>  #> Below are the average predictions by user-specified history:  #> |   | ESETA1.Infancy| ESETA1.Toddlerhood| ESETA1.Childhood| estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history | dose_count| #> |:--|--------------:|------------------:|----------------:|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-------|----------:| #> |1  |        -0.4074|            -0.6716|          -0.6573|  -0.2643|    0.2117|   -1.2487|  0.2118|  2.2395|  -0.6792|    0.1506|l-l-l   |          0| #> |4  |         0.1704|             0.1195|          -0.6573|   0.1979|    0.1746|    1.1331|  0.2572|  1.9592|  -0.1444|    0.5401|h-h-l   |          2| #> |8  |         0.1704|             0.1195|           0.4532|   0.1005|    0.1333|    0.7539|  0.4509|  1.1490|  -0.1608|    0.3618|h-h-h   |          3| #>  #>  #> Conducting multiple comparison correction for all pairings between comparison histories and each refernece history using the BH method.  #>  #>  #> USER ALERT: please inspect the following comparisons:  #> |term                                                    | estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history        |dose   | p.value_corr| #> |:-------------------------------------------------------|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:--------------|:------|------------:| #> |(-0.4074, -0.6716, -0.6573) - (0.1704, 0.1195, 0.4532)  |     0.36|      0.19|      1.90|    0.06|    4.12|    -0.01|      0.74|l-l-l vs h-h-h |0 vs 3 |         0.06| #> |(-0.4074, -0.6716, -0.6573) - (0.1704, 0.1195, -0.6573) |     0.46|      0.15|      3.01|    0.00|    8.59|     0.16|      0.76|l-l-l vs h-h-l |0 vs 2 |         0.01| model <- models.s2   results.s2 <- compareHistories(exposure = exposure, exposure_time_pts = exposure_time_pts, outcome = outcome, model = model, #required                                epochs = epochs, hi_lo_cut = hi_lo_cut, reference = reference, comparison = comparison, #optional                                mc_comp_method = mc_comp_method, dose_level = dose_level, exp_lab = exp_lab, out_lab = out_lab, colors = colors, #optional                                home_dir = home_dir, verbose = verbose, save.out = save.out) #optional #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 6 (12%) individuals that fall into 3 out of the 3 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure ESETA1, respectively, across Infancy, Toddlerhood, Childhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure ESETA1 histories based on exposure main effects Infancy, Toddlerhood, Childhood containing time points 6, 15, 24: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  3| #> |h-h-l   |  2| #> |l-l-l   |  1| #>  #>  #> Below are the average predictions by user-specified history:  #> |   | ESETA1.Infancy| ESETA1.Toddlerhood| ESETA1.Childhood| estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history | dose_count| #> |:--|--------------:|------------------:|----------------:|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-------|----------:| #> |1  |        -0.4074|            -0.6716|          -0.6573|  -0.2423|    0.2133|   -1.1358|  0.2560|  1.9655|  -0.6604|    0.1758|l-l-l   |          0| #> |4  |         0.1704|             0.1195|          -0.6573|   0.2134|    0.1756|    1.2149|  0.2244|  2.1557|  -0.1309|    0.5576|h-h-l   |          2| #> |8  |         0.1704|             0.1195|           0.4532|   0.0986|    0.1313|    0.7511|  0.4526|  1.1436|  -0.1587|    0.3559|h-h-h   |          3| #>  #>  #> Conducting multiple comparison correction for all pairings between comparison histories and each refernece history using the BH method.  #>  #>  #> USER ALERT: please inspect the following comparisons:  #> |term                                                    | estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history        |dose   | p.value_corr| #> |:-------------------------------------------------------|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:--------------|:------|------------:| #> |(-0.4074, -0.6716, -0.6573) - (0.1704, 0.1195, 0.4532)  |     0.34|      0.20|      1.75|    0.08|    3.63|    -0.04|      0.72|l-l-l vs h-h-h |0 vs 3 |         0.08| #> |(-0.4074, -0.6716, -0.6573) - (0.1704, 0.1195, -0.6573) |     0.46|      0.16|      2.91|    0.00|    8.09|     0.15|      0.76|l-l-l vs h-h-l |0 vs 2 |         0.01|"},{"path":"https://istallworthy.github.io/devMSMs/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Isabella Stallworthy. Author, maintainer. Noah Greifer. Author, contributor. Meriah DeJoseph. Author. Emily Padrutt. Author. Daniel Berry. Author.","code":""},{"path":"https://istallworthy.github.io/devMSMs/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Stallworthy , Greifer N, DeJoseph M, Padrutt E, Berry D (2023). devMSMs: Tools Conducting Marginal Structural Models Developmental Data. R package version 0.0.0.9000, https://github.com/istallworthy/devMSMs, https://istallworthy.github.io/devMSMs/.","code":"@Manual{,   title = {devMSMs: Tools for Conducting Marginal Structural Models with Developmental Data},   author = {Isabella Stallworthy and Noah Greifer and Meriah DeJoseph and Emily Padrutt and Daniel Berry},   year = {2023},   note = {R package version 0.0.0.9000, https://github.com/istallworthy/devMSMs},   url = {https://istallworthy.github.io/devMSMs/}, }"},{"path":"https://istallworthy.github.io/devMSMs/index.html","id":"devmsms","dir":"","previous_headings":"","what":"An R package for conducting marginal structural models (MSMs) with longitudinal data","title":"An R package for conducting marginal structural models (MSMs) with longitudinal data","text":"Scientists study humans fundamentally interested questions causation, yet conceptual, methodological, practical barriers historically prevented use methods causal inference developed fields. specifically, scientists, clinicians, educators, policymakers alike often interested causal processes, involving questions (timing) extent (dose) different factors influence human functioning development, order inform scientific understanding improve people’s lives.  Marginal structural models (MSMs; Robins et al., 2000), orginating epidemiology public health, represent one -utilized tool improving causal inference longitudinal observational data. brief, MSMs leverage inverse-probability--treatment-weights (IPTW) potential outcomes framework attenuate associations confounders exposure (e.g., experience, characteristic, evevent –biology broader environment) time, uncover causal relations time-varying exposure future outcome, given certain assumptions. devMSMs R package accompanying tutorial paper, Investigating Causal Questions Human Development using Marginal Structural Models: Tutorial Introduction devMSMs Package R (insert preprint link ), implementing MSMs longitudinal data answer causal questions dose timing effects given exposure future outcome. Core features package include: flexible functions built-guidance, drawing established expertise best practices implementing longitudinal IPTW weighting outcome modeling answer substantive causal questions dose timing accommodation data form either complete dataframe multiple imputation recommended workflow using devMSMs functions longitudinal data step--step user guidance deveMSMs worflow form vignettes R markdown template file users new MSM technique R programming accompanying suite helper functions assist users preparing inspecting data prior use devMSMs conceptual introduction example empirical application accompanying tutorial paper","code":""},{"path":"https://istallworthy.github.io/devMSMs/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"An R package for conducting marginal structural models (MSMs) with longitudinal data","text":"package contains 6 core functions conducting longitudinal confounder adjustment outcome modeling longitudinal data time-varying exposures.","code":""},{"path":"https://istallworthy.github.io/devMSMs/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"An R package for conducting marginal structural models (MSMs) with longitudinal data","text":"devMSMs can installed R Studio Github using devtools package:library(devtools)install_github(\"istallworthy/devMSMs\")library(devMSMs) helper functions can installed accompanying devMSMsHelpers repo:install_github(\"istallworthy/devMSMsHelpers\")library(devMSMsHelpers)","code":""},{"path":[]},{"path":"https://istallworthy.github.io/devMSMs/index.html","id":"additional-resources","dir":"","previous_headings":"","what":"Additional Resources","title":"An R package for conducting marginal structural models (MSMs) with longitudinal data","text":"Fong, C., Hazlett, C., & Imai, K. (2018). Covariate balancing propensity score continuous treatment: Application efficacy political advertisements. Annals Applied Statistics, 12(1), 156–177. https://doi.org/10.1214/17-AOAS1101 Hirano, K., & Imbens, G. W. (2004). Propensity Score Continuous Treatments. Applied Bayesian Modeling Causal Inference Incomplete-Data Perspectives (pp. 73–84). John Wiley & Sons, Ltd. https://doi.org/10.1002/0470090456.ch7 Robins, J. M., Hernán, M. Á., & Brumback, B. (2000). Marginal Structural Models Causal Inference Epidemiology. Epidemiology, 11(5), 550–560. Thoemmes, F., & Ong, . D. (2016). Primer Inverse Probability Treatment Weighting Marginal Structural Models. https://doi.org/10.1177/2167696815621645","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/add_dose.html","id":null,"dir":"Reference","previous_headings":"","what":"Add dose tally to table — add_dose","title":"Add dose tally to table — add_dose","text":"Add dose tally table","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/add_dose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add dose tally to table — add_dose","text":"","code":"add_dose(p, dose_level)"},{"path":"https://istallworthy.github.io/devMSMs/reference/add_dose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add dose tally to table — add_dose","text":"p table output marginaleffects::avg_predictions() hypotheses() dose_level \"l\" \"h\" indicating whether low high doses tallied tables plots","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/add_dose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add dose tally to table — add_dose","text":"table dose level tally","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/add_histories.html","id":null,"dir":"Reference","previous_headings":"","what":"Add history labels to table — add_histories","title":"Add history labels to table — add_histories","text":"Add history labels table","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/add_histories.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add history labels to table — add_histories","text":"","code":"add_histories(p, d)"},{"path":"https://istallworthy.github.io/devMSMs/reference/add_histories.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add history labels to table — add_histories","text":"p table output marginaleffects::avg_predictions() hypotheses() d data frame high low values per exposure main effect","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/add_histories.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add history labels to table — add_histories","text":"table histories labeled","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/assessBalance.html","id":null,"dir":"Reference","previous_headings":"","what":"Assesses confounder balancing — assessBalance","title":"Assesses confounder balancing — assessBalance","text":"Draws functions cobalt package quantify relations exposure confounders exposure time point according guidelines Jackson, 2016 assess balance time-varying exposures.","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/assessBalance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assesses confounder balancing — assessBalance","text":"","code":"assessBalance(   data,   exposure,   exposure_time_pts,   outcome,   type,   formulas,   weights = NULL,   balance_thresh = NULL,   imp_conf = NULL,   home_dir = NULL,   verbose = TRUE,   save.out = TRUE )"},{"path":"https://istallworthy.github.io/devMSMs/reference/assessBalance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assesses confounder balancing — assessBalance","text":"data data wide format : data frame, list imputed data frames, mids object exposure name exposure variable exposure_time_pts list integers weights created/assessed correspond time points exposure wass measured outcome name outcome variable \".timepoint\" suffix type type balance assessment; 'prebalance' 'weighted' formulas list balancing formulas time point output createFormulas() weights list IPTW weights output createWeights, required type 'weighted' balance_thresh (optional) one two numbers 0 1 indicating single balancing threshold thresholds less important confounders, respectively (default = 0.1) imp_conf (optional) list variable names reflecting important confounders, required two balance thresholds supplied home_dir (optional) path home directory (required save.= TRUE) verbose (optiona) TRUE FALSE indicator user output (default TRUE) save.(optional) TRUE FALSE indicator save output intermediary output locally (default TRUE)","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/assessBalance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assesses confounder balancing — assessBalance","text":"data frame balance statistics","code":""},{"path":[]},{"path":"https://istallworthy.github.io/devMSMs/reference/assessBalance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assesses confounder balancing — assessBalance","text":"","code":"test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50)) test[, c(\"A.1\", \"A.2\", \"A.3\")] <- lapply(test[, c(\"A.1\", \"A.2\", \"A.3\")], as.numeric)  f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"short\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x5593493077a0> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x5593493077a0> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.2 + B.2 + C #> <environment: 0x5593493077a0> #>   #Prebalance b <- assessBalance(data = test,                    exposure = \"A\",                    exposure_time_pts = c(1, 2, 3),                    outcome = \"D.3\",                    type = \"prebalance\",                    formulas = f,                    save.out = FALSE) #> USER ALERT: The following statistics display covariate imbalance at each exposure time point prior to weighting, using short formulas. #>     #> As shown below, 1 out of 7 (14%) covariates across time points, corresponding to 1 out of 2 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.11 (range= 0.11-0.11): #>  #> Table: Imbalanced covariates using no weights and short formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        1|          1|            0|  1| #> |        2|          2|            1|  3| #> |        3|          3|            0|  3| #>  #>  #> USER ALERT: For exposure A using the short formulas and no weights : #> The median absolute value relation between exposure and confounder is 0.03 (range = -0.07 -0.11).  #> As shown below, the following 1 covariates across time points out of 7 total (14.29%) spanning 1 domains out of 3 (33.33%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to A of 0.11 (range=0.11-0.11) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate |   avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:---------|---------:|----------:|--------:| #> |4  |A        |        2|          0|C         | 0.1094988|        0.1|        0| #>  b <- assessBalance(data = test,                    exposure = \"A\",                    exposure_time_pts = c(1, 2, 3),                    outcome = \"D.3\",                    type = \"prebalance\",                    formulas = f,                    balance_thresh = 0.2,                    save.out = FALSE) #> USER ALERT: The following statistics display covariate imbalance at each exposure time point prior to weighting, using short formulas. #>     #> No covariates remain imbalanced using no weights and short formulas.  #>  #>  #> USER ALERT: For exposure A using the short formulas and no weights : #> The median absolute value relation between exposure and confounder is 0.03 (range = -0.07 -0.11).  #> There are no imbalanced covariates.  #> There are no imbalanced covariates. b <- assessBalance(data = test,                    exposure = \"A\",                    exposure_time_pts = c(1, 2, 3),                    outcome = \"D.3\",                    type = \"prebalance\",                    formulas = f,                    balance_thresh = c(0.1, 0.2),                    imp_conf = \"B.1\",                    save.out = FALSE) #> USER ALERT: The following statistics display covariate imbalance at each exposure time point prior to weighting, using short formulas. #>     #> No covariates remain imbalanced using no weights and short formulas.  #>  #>  #> USER ALERT: For exposure A using the short formulas and no weights : #> The median absolute value relation between exposure and confounder is 0.03 (range = -0.07 -0.11).  #> There are no imbalanced covariates.  #> There are no imbalanced covariates. f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\", \"A.1:B.1\"),                     ti_confounders = \"C\",                     type = \"short\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x559352b1e728> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + A.1:B.1 + B.1 + C #> <environment: 0x559352b1e728> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.2 + B.2 + C #> <environment: 0x559352b1e728> #>  b <- assessBalance(data = test,                    exposure = \"A\",                    exposure_time_pts = c(1, 2, 3),                    outcome = \"D.3\",                    type = \"prebalance\",                    formulas = f,                    save.out = FALSE) #> USER ALERT: The following statistics display covariate imbalance at each exposure time point prior to weighting, using short formulas. #>     #> As shown below, 2 out of 8 (25%) covariates across time points, corresponding to 2 out of 3 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.11 (range= -0.11-0.11): #>  #> Table: Imbalanced covariates using no weights and short formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        1|          1|            0|  1| #> |        2|          2|            2|  4| #> |        3|          3|            0|  3| #>  #>  #> USER ALERT: For exposure A using the short formulas and no weights : #> The median absolute value relation between exposure and confounder is 0.05 (range = -0.11 -0.11).  #> As shown below, the following 2 covariates across time points out of 8 total (25%) spanning 2 domains out of 3 (66.67%) are imbalanced with a remaining median absolute value correlation/std mean difference in relation to A of 0.11 (range=-0.11-0.11) : #>  #>  #> Table: Imbalanced Covariates #>  #> |   |exposure | exp_time| covar_time|covariate |    avg_bal| bal_thresh| balanced| #> |:--|:--------|--------:|----------:|:---------|----------:|----------:|--------:| #> |3  |A        |        2|          1|A.1:B.1   | -0.1086380|        0.1|        0| #> |5  |A        |        2|          0|C         |  0.1094988|        0.1|        0| #>   # Weighted w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 1.02 (SD = 0.69; range = 0.52-4).  #>    b <- assessBalance(data = test,                    exposure = \"A\",                    exposure_time_pts = c(1, 2, 3),                    outcome = \"D.3\",                    type = \"weighted\",                    weights = w,                    formulas = f,                    save.out = FALSE) #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using short formulas. #>     #> No covariates remain imbalanced using cbps and short formulas.  #>  #>  #> USER ALERT: For exposure A using the short formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.03 (range = -0.05 -0.05).  #> There are no imbalanced covariates.  #> There are no imbalanced covariates. b <- assessBalance(data = test,                    exposure = \"A\",                    exposure_time_pts = c(1, 2, 3),                    outcome = \"D.3\",                    type = \"weighted\",                    weights = w,                    formulas = f,                    balance_thresh = 0.2,                    save.out = FALSE) #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using short formulas. #>     #> No covariates remain imbalanced using cbps and short formulas.  #>  #>  #> USER ALERT: For exposure A using the short formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.03 (range = -0.05 -0.05).  #> There are no imbalanced covariates.  #> There are no imbalanced covariates. b <- assessBalance(data = test,                    exposure = \"A\",                    exposure_time_pts = c(1, 2, 3),                    outcome = \"D.3\",                    type = \"weighted\",                    weights = w,                    formulas = f,                    balance_thresh = c(0.1, 0.2),                    imp_conf = \"B.1\",                    save.out = FALSE) #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using short formulas. #>     #> No covariates remain imbalanced using cbps and short formulas.  #>  #>  #> USER ALERT: For exposure A using the short formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.03 (range = -0.05 -0.05).  #> There are no imbalanced covariates.  #> There are no imbalanced covariates."},{"path":"https://istallworthy.github.io/devMSMs/reference/calcBalStats.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate balance stats based on Jackson paper — calcBalStats","title":"Calculate balance stats based on Jackson paper — calcBalStats","text":"Calculate weighted unweighted standardized balance statistics given exposure time point, using relevant confounders. Draws Jackson, 2016 approaches assessing balance time-varying exposures weighting statistics based sample distribution exposure histories.","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/calcBalStats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate balance stats based on Jackson paper — calcBalStats","text":"","code":"calcBalStats(   data,   formulas,   exposure,   exposure_time_pts,   outcome,   balance_thresh,   k = 0,   weights = NULL,   imp_conf = NULL,   home_dir = NULL,   verbose = TRUE,   save.out = TRUE )"},{"path":"https://istallworthy.github.io/devMSMs/reference/calcBalStats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate balance stats based on Jackson paper — calcBalStats","text":"data data wide format : data frame, path folder imputed .csv files, mids object formulas list balancing formulas time point output createFormulas() exposure name exposure variable exposure_time_pts list integers weights created/assessed correspond time points exposure wass measured outcome name outcome variable \".timepoint\" suffix balance_thresh (optional) one two numbers 0 1 indicating single balancingn threshold thresholds less important confounders, respectively k (optional) imputation number weights (optional) list IPTW weights output createWeights imp_conf (optional) list variable names reflecting important confounders (required two balance thresholds provided) home_dir (optional) path home directory (required save.= TRUE) verbose (optional) TRUE FALSE indicator user output (default TRUE) save.(optional) TRUE FALSE indicator save output intermediary output locally","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/calcBalStats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate balance stats based on Jackson paper — calcBalStats","text":"data frame balance statistics","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/calcBalStats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate balance stats based on Jackson paper — calcBalStats","text":"","code":"test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50)) test[, c(\"A.1\", \"A.2\", \"A.3\")] <- lapply(test[, c(\"A.1\", \"A.2\", \"A.3\")], as.numeric)  f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"full\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55934ffdabb0> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x55934ffdabb0> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.1 + A.2 + B.1 + B.2 + C #> <environment: 0x55934ffdabb0> #>   w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 0.99 (SD = 0.4; range = 0.5-3).  #>    c <- calcBalStats(data = test,                   formulas = f,                   exposure = \"A\",                   exposure_time_pts = c(1, 2, 3),                   outcome = \"D.3\",                   balance_thresh = 0.1,                   save.out = FALSE)    #> As shown below, 4 out of 9 (44%) covariates across time points, corresponding to 3 out of 3 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.13 (range= -0.27-0.11): #>  #> Table: Imbalanced covariates using no weights and full formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        1|          1|            0|  1| #> |        2|          1|            2|  3| #> |        3|          3|            2|  5| #>  #>  c <- calcBalStats(data = test,                   formulas = f,                   exposure = \"A\",                   exposure_time_pts = c(1, 2, 3),                   outcome = \"D.3\",                   balance_thresh = c(0.05, 0.1),                   imp_conf = \"B2\",                   save.out = FALSE)    #> As shown below, 4 out of 9 (44%) covariates across time points, corresponding to 3 out of 3 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.13 (range= -0.27-0.11): #>  #> Table: Imbalanced covariates using no weights and full formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        1|          1|            0|  1| #> |        2|          1|            2|  3| #> |        3|          3|            2|  5| #>  #>  c <- calcBalStats(data = test,                   formulas = f,                   exposure = \"A\",                   exposure_time_pts = c(1, 2, 3),                   outcome = \"D.3\",                   balance_thresh = 0.1,                   weights = w[[1]],                   save.out = FALSE)    #> As shown below, 1 out of 9 (11%) covariates across time points, corresponding to 1 out of 3 domains, remain imbalanced with a remaining median absolute value correlation/std mean difference of 0.14 (range= 0.14-0.14): #>  #> Table: Imbalanced covariates using cbps and full formulas #>  #> | exp_time| balanced_n| imbalanced_n|  n| #> |--------:|----------:|------------:|--:| #> |        1|          1|            0|  1| #> |        2|          3|            0|  3| #> |        3|          4|            1|  5| #>  #>"},{"path":"https://istallworthy.github.io/devMSMs/reference/compareHistories.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate, compare, and visualize exposure histories — compareHistories","title":"Estimate, compare, and visualize exposure histories — compareHistories","text":"Takes fitted model output created predicted values user-specified histories (pooling imputed data), conducting contrast comparisons (pooling imputed data), correcting multiple comparisons, plotting results.","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/compareHistories.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate, compare, and visualize exposure histories — compareHistories","text":"","code":"compareHistories(   home_dir,   exposure,   exposure_time_pts,   outcome,   model,   epochs = NULL,   hi_lo_cut = NULL,   reference = NULL,   comparison = NULL,   mc_comp_method = NA,   dose_level = NA,   exp_lab = NA,   out_lab = NA,   colors = NULL,   verbose = TRUE,   save.out = TRUE )"},{"path":"https://istallworthy.github.io/devMSMs/reference/compareHistories.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate, compare, and visualize exposure histories — compareHistories","text":"home_dir path home directory (required 'save.' = TRUE) exposure name exposure variable exposure_time_pts list integers weights created/assessed correspond time points exposure wass measured outcome name outcome variable \".timepoint\" suffix model list model outputs fitModel() epochs (optional) data frame exposure epoch labels values hi_lo_cut (optional) list two numbers indicating quantile values reflect high low values, respectively, continuous exposure (default median split) reference (optional) list sof one strings \"-\"-separated \"l\" \"h\" values indicative reference exposure history compare comparison, required comparison supplied comparison (optional) list one strings \"-\"-separated \"l\" \"h\" values indicative comparison history/histories compare reference, required reference supplied mc_comp_method (optional) character abbreviation multiple comparison correction method stats::p.adjust, default Benjamini-Hochburg (\"BH\") dose_level (optional) \"l\" \"h\" indicating whether low high doses tallied tables plots (default high \"h\") exp_lab (optional) character label exposure variable plots (default variable name) out_lab (optional) character label outcome variable plots (default variable name) colors (optional) character specifying Brewer palette list colors (n(epochs)+1) plotting (default \"Dark2\" palette) verbose (optional) TRUE FALSE indicator user output (default TRUE) save.(optional) TRUE FALSE indicator save output intermediary output locally (default TRUE)","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/compareHistories.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate, compare, and visualize exposure histories — compareHistories","text":"data frame history comparisons","code":""},{"path":[]},{"path":"https://istallworthy.github.io/devMSMs/reference/compareHistories.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate, compare, and visualize exposure histories — compareHistories","text":"","code":"f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"full\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x559355162750> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x559355162750> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.1 + A.2 + B.1 + B.2 + C #> <environment: 0x559355162750> #>   test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50)) test[, c(\"A.1\", \"A.2\", \"A.3\")] <- lapply(test[, c(\"A.1\", \"A.2\", \"A.3\")], as.numeric)  w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 1.09 (SD = 0.41; range = 0.31-2).  #>    m <- fitModel(data = test,               weights = w,               exposure = \"A\",               exposure_time_pts = c(1, 2, 3),               outcome = \"D.3\",               model = \"m0\",               save.out = FALSE) #> Please inspect the following likelihood ratio test to determine if the exposures collective predict significant variation in the outcome compared to a model without exposure terms. #>  #> We strongly suggest not conducting history comparisons if the likelihood ratio test is non-significant. #>  #> Working (Rao-Scott+F) LRT for A.1 A.2 A.3 #>  in svyglm(formula = as.formula(f), design = s, family = fam) #> Working 2logLR =  3.266702 p= 0.35192  #> (scale factors:  1.4 1.1 0.53 );  denominator df= 46 #>  #> The marginal model, m0, is summarized below:  r <- compareHistories(exposure = \"A\",                       exposure_time_pts = c(1, 2, 3),                       outcome = \"D.3\",                       model = m,                       save.out = FALSE) #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 50 (100%) individuals that fall into 8 out of the 8 total user-defined exposure histories created from median split values for low and high levels of exposure A, respectively, across 1, 2, 3.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects 1, 2, 3 containing time points 1, 2, 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  8| #> |h-h-l   |  5| #> |h-l-h   |  7| #> |h-l-l   |  5| #> |l-h-h   |  6| #> |l-h-l   |  6| #> |l-l-h   |  4| #> |l-l-l   |  9| #>  #>  #> Below are the average predictions by user-specified history:  #> |    A.1|     A.2|     A.3| estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history | dose_count| #> |------:|-------:|-------:|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-------|----------:| #> | 0.1898| -0.1896| -0.0322|  -0.1930|    0.1195|   -1.6148|  0.1064|  3.2329|  -0.4272|    0.0413|l-l-l   |          0| #> | 0.1898| -0.1896| -0.0302|  -0.1934|    0.1195|   -1.6184|  0.1056|  3.2435|  -0.4276|    0.0408|l-l-h   |          1| #> | 0.1898| -0.1876| -0.0322|  -0.1930|    0.1195|   -1.6160|  0.1061|  3.2366|  -0.4272|    0.0411|l-h-l   |          1| #> | 0.1898| -0.1876| -0.0302|  -0.1935|    0.1195|   -1.6196|  0.1053|  3.2472|  -0.4276|    0.0407|l-h-h   |          2| #> | 0.1918| -0.1896| -0.0322|  -0.1930|    0.1194|   -1.6155|  0.1062|  3.2352|  -0.4270|    0.0411|h-l-l   |          1| #> | 0.1918| -0.1896| -0.0302|  -0.1934|    0.1194|   -1.6191|  0.1054|  3.2458|  -0.4275|    0.0407|h-l-h   |          2| #> | 0.1918| -0.1876| -0.0322|  -0.1930|    0.1194|   -1.6168|  0.1059|  3.2389|  -0.4271|    0.0410|h-h-l   |          2| #> | 0.1918| -0.1876| -0.0302|  -0.1935|    0.1194|   -1.6204|  0.1051|  3.2495|  -0.4275|    0.0405|h-h-h   |          3| #>  #>  #> Conducting multiple comparison correction for all pairings between comparison histories and each refernece history using the BH method.  #>  #>  #> USER ALERT: please inspect the following comparisons:  #> |term                                                    | estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history        |dose   | p.value_corr| #> |:-------------------------------------------------------|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:--------------|:------|------------:| #> |(0.1898, -0.1896, -0.0322) - (0.1898, -0.1896, -0.0302) |        0|         0|      1.52|    0.13|    2.96|        0|         0|l-l-l vs l-l-h |0 vs 1 |         0.51| #> |(0.1898, -0.1896, -0.0322) - (0.1898, -0.1876, -0.0322) |        0|         0|      0.50|    0.62|    0.70|        0|         0|l-l-l vs l-h-l |0 vs 1 |         0.84| #> |(0.1898, -0.1896, -0.0322) - (0.1898, -0.1876, -0.0302) |        0|         0|      1.78|    0.07|    3.75|        0|         0|l-l-l vs l-h-h |0 vs 2 |         0.51| #> |(0.1898, -0.1896, -0.0322) - (0.1918, -0.1896, -0.0322) |        0|         0|     -0.01|    0.99|    0.01|        0|         0|l-l-l vs h-l-l |0 vs 1 |         0.99| #> |(0.1898, -0.1896, -0.0322) - (0.1918, -0.1896, -0.0302) |        0|         0|      1.31|    0.19|    2.40|        0|         0|l-l-l vs h-l-h |0 vs 2 |         0.53| #> |(0.1898, -0.1896, -0.0322) - (0.1918, -0.1876, -0.0322) |        0|         0|      0.28|    0.78|    0.35|        0|         0|l-l-l vs h-h-l |0 vs 2 |         0.91| #> |(0.1898, -0.1896, -0.0322) - (0.1918, -0.1876, -0.0302) |        0|         0|      1.39|    0.17|    2.59|        0|         0|l-l-l vs h-h-h |0 vs 3 |         0.53| #> |(0.1898, -0.1896, -0.0302) - (0.1898, -0.1876, -0.0322) |        0|         0|     -0.90|    0.37|    1.45|        0|         0|l-l-h vs l-h-l |1 vs 1 |         0.68| #> |(0.1898, -0.1896, -0.0302) - (0.1898, -0.1876, -0.0302) |        0|         0|      0.50|    0.62|    0.70|        0|         0|l-l-h vs l-h-h |1 vs 2 |         0.84| #> |(0.1898, -0.1896, -0.0302) - (0.1918, -0.1896, -0.0322) |        0|         0|     -1.17|    0.24|    2.06|        0|         0|l-l-h vs h-l-l |1 vs 1 |         0.56| #> |(0.1898, -0.1896, -0.0302) - (0.1918, -0.1896, -0.0302) |        0|         0|     -0.01|    0.99|    0.01|        0|         0|l-l-h vs h-l-h |1 vs 2 |         0.99| #> |(0.1898, -0.1896, -0.0302) - (0.1918, -0.1876, -0.0322) |        0|         0|     -0.72|    0.47|    1.08|        0|         0|l-l-h vs h-h-l |1 vs 2 |         0.83| #> |(0.1898, -0.1896, -0.0302) - (0.1918, -0.1876, -0.0302) |        0|         0|      0.28|    0.78|    0.35|        0|         0|l-l-h vs h-h-h |1 vs 3 |         0.91| #> |(0.1898, -0.1876, -0.0322) - (0.1898, -0.1876, -0.0302) |        0|         0|      1.52|    0.13|    2.96|        0|         0|l-h-l vs l-h-h |1 vs 2 |         0.51| #> |(0.1898, -0.1876, -0.0322) - (0.1918, -0.1896, -0.0322) |        0|         0|     -0.44|    0.66|    0.59|        0|         0|l-h-l vs h-l-l |1 vs 1 |         0.84| #> |(0.1898, -0.1876, -0.0322) - (0.1918, -0.1896, -0.0302) |        0|         0|      0.90|    0.37|    1.45|        0|         0|l-h-l vs h-l-h |1 vs 2 |         0.68| #> |(0.1898, -0.1876, -0.0322) - (0.1918, -0.1876, -0.0322) |        0|         0|     -0.01|    0.99|    0.01|        0|         0|l-h-l vs h-h-l |1 vs 2 |         0.99| #> |(0.1898, -0.1876, -0.0322) - (0.1918, -0.1876, -0.0302) |        0|         0|      1.31|    0.19|    2.40|        0|         0|l-h-l vs h-h-h |1 vs 3 |         0.53| #> |(0.1898, -0.1876, -0.0302) - (0.1918, -0.1896, -0.0322) |        0|         0|     -1.56|    0.12|    3.07|        0|         0|l-h-h vs h-l-l |2 vs 1 |         0.51| #> |(0.1898, -0.1876, -0.0302) - (0.1918, -0.1896, -0.0302) |        0|         0|     -0.44|    0.66|    0.59|        0|         0|l-h-h vs h-l-h |2 vs 2 |         0.84| #> |(0.1898, -0.1876, -0.0302) - (0.1918, -0.1876, -0.0322) |        0|         0|     -1.17|    0.24|    2.06|        0|         0|l-h-h vs h-h-l |2 vs 2 |         0.56| #> |(0.1898, -0.1876, -0.0302) - (0.1918, -0.1876, -0.0302) |        0|         0|     -0.01|    0.99|    0.01|        0|         0|l-h-h vs h-h-h |2 vs 3 |         0.99| #> |(0.1918, -0.1896, -0.0322) - (0.1918, -0.1896, -0.0302) |        0|         0|      1.52|    0.13|    2.96|        0|         0|h-l-l vs h-l-h |1 vs 2 |         0.51| #> |(0.1918, -0.1896, -0.0322) - (0.1918, -0.1876, -0.0322) |        0|         0|      0.50|    0.62|    0.70|        0|         0|h-l-l vs h-h-l |1 vs 2 |         0.84| #> |(0.1918, -0.1896, -0.0322) - (0.1918, -0.1876, -0.0302) |        0|         0|      1.78|    0.07|    3.75|        0|         0|h-l-l vs h-h-h |1 vs 3 |         0.51| #> |(0.1918, -0.1896, -0.0302) - (0.1918, -0.1876, -0.0322) |        0|         0|     -0.90|    0.37|    1.45|        0|         0|h-l-h vs h-h-l |2 vs 2 |         0.68| #> |(0.1918, -0.1896, -0.0302) - (0.1918, -0.1876, -0.0302) |        0|         0|      0.50|    0.62|    0.70|        0|         0|h-l-h vs h-h-h |2 vs 3 |         0.84| #> |(0.1918, -0.1876, -0.0322) - (0.1918, -0.1876, -0.0302) |        0|         0|      1.52|    0.13|    2.96|        0|         0|h-h-l vs h-h-h |2 vs 3 |         0.51| #>  #>   r <- compareHistories(exposure = \"A\",                       exposure_time_pts = c(1, 2, 3),                       outcome = \"D.3\",                       model = m,                       reference = \"l-l-l\",                       comparison = \"h-h-h\",                       save.out = FALSE) #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 17 (34%) individuals that fall into 2 out of the 2 total user-defined exposure histories created from median split values for low and high levels of exposure A, respectively, across 1, 2, 3.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects 1, 2, 3 containing time points 1, 2, 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  8| #> |l-l-l   |  9| #>  #>  #> Below are the average predictions by user-specified history:  #> |   |    A.1|     A.2|     A.3| estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history | dose_count| #> |:--|------:|-------:|-------:|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-------|----------:| #> |1  | 0.1898| -0.1896| -0.0322|  -0.1930|    0.1195|   -1.6148|  0.1064|  3.2329|  -0.4272|    0.0413|l-l-l   |          0| #> |8  | 0.1918| -0.1876| -0.0302|  -0.1935|    0.1194|   -1.6204|  0.1051|  3.2495|  -0.4275|    0.0405|h-h-h   |          3| #>  #>  #> Conducting multiple comparison correction for all pairings between comparison histories and each refernece history using the BH method.  #>  #>  #> USER ALERT: please inspect the following comparisons:  #> |term                                                    | estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history        |dose   | p.value_corr| #> |:-------------------------------------------------------|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:--------------|:------|------------:| #> |(0.1898, -0.1896, -0.0322) - (0.1918, -0.1876, -0.0302) |        0|         0|     -1.39|    0.17|    2.59|        0|         0|l-l-l vs h-h-h |0 vs 3 |         0.17| #>  #>   r <- compareHistories(exposure = \"A\",                       exposure_time_pts = c(1, 2, 3),                       outcome = \"D.3\",                       model = m,                       reference = \"l-l-l\",                       comparison = c(\"h-h-h\", \"h-l-l\"),                       save.out = FALSE) #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 22 (44%) individuals that fall into 3 out of the 3 total user-defined exposure histories created from median split values for low and high levels of exposure A, respectively, across 1, 2, 3.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects 1, 2, 3 containing time points 1, 2, 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  8| #> |h-l-l   |  5| #> |l-l-l   |  9| #>  #>  #> Below are the average predictions by user-specified history:  #> |   |    A.1|     A.2|     A.3| estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history | dose_count| #> |:--|------:|-------:|-------:|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-------|----------:| #> |1  | 0.1898| -0.1896| -0.0322|  -0.1930|    0.1195|   -1.6148|  0.1064|  3.2329|  -0.4272|    0.0413|l-l-l   |          0| #> |5  | 0.1918| -0.1896| -0.0322|  -0.1930|    0.1194|   -1.6155|  0.1062|  3.2352|  -0.4270|    0.0411|h-l-l   |          1| #> |8  | 0.1918| -0.1876| -0.0302|  -0.1935|    0.1194|   -1.6204|  0.1051|  3.2495|  -0.4275|    0.0405|h-h-h   |          3| #>  #>  #> Conducting multiple comparison correction for all pairings between comparison histories and each refernece history using the BH method.  #>  #>  #> USER ALERT: please inspect the following comparisons:  #> |term                                                    | estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history        |dose   | p.value_corr| #> |:-------------------------------------------------------|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:--------------|:------|------------:| #> |(0.1898, -0.1896, -0.0322) - (0.1918, -0.1876, -0.0302) |        0|         0|     -1.39|    0.17|    2.59|        0|         0|l-l-l vs h-h-h |0 vs 3 |         0.33| #> |(0.1898, -0.1896, -0.0322) - (0.1918, -0.1896, -0.0322) |        0|         0|      0.01|    0.99|    0.01|        0|         0|l-l-l vs h-l-l |0 vs 1 |         0.99| #>  #>   r <- compareHistories(exposure = \"A\",                       exposure_time_pts = c(1, 2, 3),                       outcome = \"D.3\",                       model = m,                       reference = c(\"l-l-l\", \"l-h-h\"),                       comparison = c(\"h-h-h\"),                       save.out = FALSE) #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 23 (46%) individuals that fall into 3 out of the 3 total user-defined exposure histories created from median split values for low and high levels of exposure A, respectively, across 1, 2, 3.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects 1, 2, 3 containing time points 1, 2, 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  8| #> |l-h-h   |  6| #> |l-l-l   |  9| #>  #>  #> Below are the average predictions by user-specified history:  #> |   |    A.1|     A.2|     A.3| estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history | dose_count| #> |:--|------:|-------:|-------:|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-------|----------:| #> |1  | 0.1898| -0.1896| -0.0322|  -0.1930|    0.1195|   -1.6148|  0.1064|  3.2329|  -0.4272|    0.0413|l-l-l   |          0| #> |4  | 0.1898| -0.1876| -0.0302|  -0.1935|    0.1195|   -1.6196|  0.1053|  3.2472|  -0.4276|    0.0407|l-h-h   |          2| #> |8  | 0.1918| -0.1876| -0.0302|  -0.1935|    0.1194|   -1.6204|  0.1051|  3.2495|  -0.4275|    0.0405|h-h-h   |          3| #>  #>  #> Conducting multiple comparison correction for all pairings between comparison histories and each refernece history using the BH method.  #>  #>  #> USER ALERT: please inspect the following comparisons:  #> |term                                                    | estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|term.1                                                                                                                  | estimate.1| std.error.1| statistic.1| p.value.1| s.value.1| conf.low.1| conf.high.1|history        |dose   | p.value_corr| #> |:-------------------------------------------------------|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-----------------------------------------------------------------------------------------------------------------------|----------:|-----------:|-----------:|---------:|---------:|----------:|-----------:|:--------------|:------|------------:| #> |(0.1898, -0.1896, -0.0322) - (0.1918, -0.1876, -0.0302) |        0|         0|     -1.39|    0.17|    2.59|        0|         0|(0.189788343312334,-0.187580322595808,-0.0302425099691342) - (0.191788343312334,-0.187580322595808,-0.0302425099691342) |          0|           0|        0.01|      0.99|      0.01|          0|           0|l-l-l vs h-h-h |0 vs 3 |         0.17| #>  #>   r <- compareHistories(exposure = \"A\",                       exposure_time_pts = c(1, 2, 3),                       outcome = \"D.3\",                       model = m,                       reference = c(\"l-l-l\", \"l-h-h\"),                       comparison = c(\"h-h-h\", \"l-l-h\"),                       save.out = FALSE) #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 27 (54%) individuals that fall into 4 out of the 4 total user-defined exposure histories created from median split values for low and high levels of exposure A, respectively, across 1, 2, 3.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects 1, 2, 3 containing time points 1, 2, 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  8| #> |l-h-h   |  6| #> |l-l-h   |  4| #> |l-l-l   |  9| #>  #>  #> Below are the average predictions by user-specified history:  #> |   |    A.1|     A.2|     A.3| estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history | dose_count| #> |:--|------:|-------:|-------:|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-------|----------:| #> |1  | 0.1898| -0.1896| -0.0322|  -0.1930|    0.1195|   -1.6148|  0.1064|  3.2329|  -0.4272|    0.0413|l-l-l   |          0| #> |2  | 0.1898| -0.1896| -0.0302|  -0.1934|    0.1195|   -1.6184|  0.1056|  3.2435|  -0.4276|    0.0408|l-l-h   |          1| #> |4  | 0.1898| -0.1876| -0.0302|  -0.1935|    0.1195|   -1.6196|  0.1053|  3.2472|  -0.4276|    0.0407|l-h-h   |          2| #> |8  | 0.1918| -0.1876| -0.0302|  -0.1935|    0.1194|   -1.6204|  0.1051|  3.2495|  -0.4275|    0.0405|h-h-h   |          3| #>  #>  #> Conducting multiple comparison correction for all pairings between comparison histories and each refernece history using the BH method.  #>  #>  #> USER ALERT: please inspect the following comparisons:  #> |term                                                    | estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|term.1                                                                                                                  | estimate.1| std.error.1| statistic.1| p.value.1| s.value.1| conf.low.1| conf.high.1|history        |dose   | p.value_corr| #> |:-------------------------------------------------------|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-----------------------------------------------------------------------------------------------------------------------|----------:|-----------:|-----------:|---------:|---------:|----------:|-----------:|:--------------|:------|------------:| #> |(0.1898, -0.1896, -0.0322) - (0.1918, -0.1876, -0.0302) |        0|         0|     -1.39|    0.17|    2.59|        0|         0|(0.189788343312334,-0.187580322595808,-0.0302425099691342) - (0.191788343312334,-0.187580322595808,-0.0302425099691342) |          0|           0|        0.01|      0.99|      0.01|          0|           0|l-l-l vs h-h-h |0 vs 3 |         0.17| #> |(0.1898, -0.1896, -0.0322) - (0.1898, -0.1896, -0.0302) |        0|         0|     -1.52|    0.13|    2.96|        0|         0|(0.189788343312334,-0.187580322595808,-0.0302425099691342) - (0.189788343312334,-0.189580322595808,-0.0302425099691342) |          0|           0|        0.50|      0.62|      0.70|          0|           0|l-l-l vs l-l-h |0 vs 1 |         0.17| #>  #>   r <- compareHistories(exposure = \"A\",                       exposure_time_pts = c(1, 2, 3),                       outcome = \"D.3\",                       model = m,                       reference = c(\"l-l-l\", \"l-h-h\"),                       comparison = c(\"h-h-h\", \"l-l-h\"),                       hi_lo_cut = c(0.60, 0.30),                       mc_comp_method = \"BH\",                       dose_level = \"l\",                       exp_lab = \"Hello\",                       out_lab = \"Goodbye\",                       colors = \"Set1\",                       save.out = FALSE) #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 13 (26%) individuals that fall into 4 out of the 4 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure A, respectively, across 1, 2, 3.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects 1, 2, 3 containing time points 1, 2, 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  5| #> |l-h-h   |  2| #> |l-l-h   |  2| #> |l-l-l   |  4| #>  #>  #> Below are the average predictions by user-specified history:  #> |   |     A.1|     A.2|     A.3| estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|history | dose_count| #> |:--|-------:|-------:|-------:|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:-------|----------:| #> |1  | -0.0922| -0.7371| -0.3132|  -0.1062|    0.1523|   -0.6974|  0.4856|  1.0423|  -0.4048|    0.1923|l-l-l   |          3| #> |2  | -0.0922| -0.7371|  0.1736|  -0.2130|    0.1586|   -1.3434|  0.1792|  2.4807|  -0.5238|    0.0978|l-l-h   |          2| #> |4  | -0.0922|  0.1519|  0.1736|  -0.2543|    0.1293|   -1.9668|  0.0492|  4.3449|  -0.5077|   -0.0009|l-h-h   |          1| #> |8  |  0.8935|  0.1519|  0.1736|  -0.2531|    0.1260|   -2.0091|  0.0445|  4.4892|  -0.5000|   -0.0062|h-h-h   |          0| #>  #>  #> Conducting multiple comparison correction for all pairings between comparison histories and each refernece history using the BH method.  #>  #>  #> USER ALERT: please inspect the following comparisons:  #> |term                                                     | estimate| std.error| statistic| p.value| s.value| conf.low| conf.high|term.1                                                                                                                | estimate.1| std.error.1| statistic.1| p.value.1| s.value.1| conf.low.1| conf.high.1|history        |dose   | p.value_corr| #> |:--------------------------------------------------------|--------:|---------:|---------:|-------:|-------:|--------:|---------:|:---------------------------------------------------------------------------------------------------------------------|----------:|-----------:|-----------:|---------:|---------:|----------:|-----------:|:--------------|:------|------------:| #> |(-0.0922, -0.7371, -0.3132) - (0.8935, 0.1519, 0.1736)   |    -0.15|      0.15|     -0.95|    0.34|    1.56|    -0.45|      0.15|(-0.0922204725034013,0.15188377610981,0.173588266305756) - (0.893513929049986,0.15188377610981,0.173588266305756)     |       0.00|        0.10|        0.01|      0.99|      0.01|      -0.20|         0.2|l-l-l vs h-h-h |3 vs 0 |         0.34| #> |(-0.0922, -0.7371, -0.3132) - (-0.0922, -0.7371, 0.1736) |    -0.11|      0.07|     -1.52|    0.13|    2.96|    -0.24|      0.03|(-0.0922204725034013,0.15188377610981,0.173588266305756) - (-0.0922204725034013,-0.737141915781232,0.173588266305756) |       0.04|        0.08|        0.50|      0.62|      0.70|      -0.12|         0.2|l-l-l vs l-l-h |3 vs 2 |         0.26| #>  #>"},{"path":"https://istallworthy.github.io/devMSMs/reference/createFormulas.html","id":null,"dir":"Reference","previous_headings":"","what":"Create balancing formulas — createFormulas","title":"Create balancing formulas — createFormulas","text":"Creates balancing formulas relating exposure relevant time-varying time invariant confounders exposure time point used create IPTW weights.","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/createFormulas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create balancing formulas — createFormulas","text":"","code":"createFormulas(   exposure,   exposure_time_pts,   outcome,   type,   ti_confounders,   tv_confounders,   bal_stats = NULL,   concur_conf = NULL,   keep_conf = NULL,   home_dir = NULL,   custom = NULL,   verbose = TRUE,   save.out = TRUE )"},{"path":"https://istallworthy.github.io/devMSMs/reference/createFormulas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create balancing formulas — createFormulas","text":"exposure name exposure variable exposure_time_pts list integers weights created/assessed correspond time points exposure wass measured outcome name outcome variable \".timepoint\" suffix type type formula create 'full' (includes lagged time-varying confounders), 'short' (includes time-varying confounders t-1 lag ), 'update' (adds 'short' formulas imbalanced time-varying confounders lags great t-1) ti_confounders list time invariant confounders (least one required) tv_confounders list time-varying confounders \".timepoint\" suffix, include exposure outcome variables (least time-varying exposure variables required ) bal_stats list balance statistics assessBalance(), required 'update' type concur_conf (optional) list variable names reflecting time-varying confounders retain formulas contemporaneously (default none) keep_conf (optional) list variable names reflecting confounders always retain formulas (default depends type) home_dir path home directory (required 'save.' = TRUE) custom (optional) custom list formulas exposure time point (default create automatically according type) verbose (optional) TRUE FALSE indicator user output (default TRUE) save.(optional) TRUE FALSE indicator save output intermediary output locally (default TRUE)","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/createFormulas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create balancing formulas — createFormulas","text":"list balancing formulas exposure time point","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/createFormulas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create balancing formulas — createFormulas","text":"","code":"#Full Formulas f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\"),                     ti_confounders = \"C\",                     type = \"full\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55934ca77288> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + C #> <environment: 0x55934ca77288> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.1 + A.2 + C #> <environment: 0x55934ca77288> #>   f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"full\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55934c9168d8> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x55934c9168d8> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.1 + A.2 + B.1 + B.2 + C #> <environment: 0x55934c9168d8> #>   #Short Formulas f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\"),                     ti_confounders = \"C\",                     type = \"short\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55934c806a70> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + C #> <environment: 0x55934c806a70> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.2 + C #> <environment: 0x55934c806a70> #>  f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"short\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55934c6603b8> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x55934c6603b8> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.2 + B.2 + C #> <environment: 0x55934c6603b8> #>   c <- list(\"short_form-1\" = as.formula(A.1 ~ C),           \"short_form-2\" = as.formula(A.2 ~ A.1 + B.1 + C),           \"short_form-3\" = as.formula(A.3 ~ A.2 + B.2 + C))  f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"short\",                     custom = c,                     save.out = FALSE) #> The user-supplied custom balancing formula for each exposure time point are below:  #> Error in createFormulas(exposure = \"A\", exposure_time_pts = c(1, 2, 3),     outcome = \"D.3\", tv_confounders = c(\"A.1\", \"A.2\", \"A.3\",         \"B.1\", \"B.2\", \"B.3\"), ti_confounders = \"C\", type = \"short\",     custom = c, save.out = FALSE): object 'formulas' not found  #Update Formulas test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50)) test[, c(\"A.1\", \"A.2\", \"A.3\")] <- lapply(test[, c(\"A.1\", \"A.2\", \"A.3\")], as.numeric)  w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 0.92 (SD = 0.44; range = 0.21-2).  #>    b <- assessBalance(data = test,                    exposure = \"A\",                    exposure_time_pts = c(1, 2, 3),                    outcome = \"D.3\",                    type = \"weighted\",                    weights = w,                    formulas = f,                    save.out = FALSE) #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using short formulas. #>     #> No covariates remain imbalanced using cbps and short formulas.  #>  #>  #> USER ALERT: For exposure A using the short formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.03 (range = -0.06 -0).  #> There are no imbalanced covariates.  #> There are no imbalanced covariates. f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\"),                     ti_confounders = \"C\",                     type = \"update\",                     bal_stats = b,                     save.out = FALSE) #> USER ALERT: Please manually inspect the updated balancing formula below that includes time-varying confounders at t-1 and those greater at further lags that remained imbalanced: #> The update formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55934d0f1d60> #>  #> USER ALERT: Please manually inspect the updated balancing formula below that includes time-varying confounders at t-1 and those greater at further lags that remained imbalanced: #> For A at exposure time point 2 no time-varying confounders at additional lags were added.  #>  #> The update formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + C #> <environment: 0x55934d0f1d60> #>  #> USER ALERT: Please manually inspect the updated balancing formula below that includes time-varying confounders at t-1 and those greater at further lags that remained imbalanced: #> For A at exposure time point 3 no time-varying confounders at additional lags were added.  #>  #> The update formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.2 + C #> <environment: 0x55934d0f1d60> #>  f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"update\",                     bal_stats = b,                     save.out = FALSE) #> USER ALERT: Please manually inspect the updated balancing formula below that includes time-varying confounders at t-1 and those greater at further lags that remained imbalanced: #> The update formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55934ce554e0> #>  #> USER ALERT: Please manually inspect the updated balancing formula below that includes time-varying confounders at t-1 and those greater at further lags that remained imbalanced: #> For A at exposure time point 2 no time-varying confounders at additional lags were added.  #>  #> The update formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x55934ce554e0> #>  #> USER ALERT: Please manually inspect the updated balancing formula below that includes time-varying confounders at t-1 and those greater at further lags that remained imbalanced: #> For A at exposure time point 3 no time-varying confounders at additional lags were added.  #>  #> The update formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.2 + B.2 + C #> <environment: 0x55934ce554e0> #>"},{"path":"https://istallworthy.github.io/devMSMs/reference/createWeights.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates IPTW balancing weights — createWeights","title":"Creates IPTW balancing weights — createWeights","text":"Creates IPTW balancing weights user-specified exposure time point using balancing formulas relate exposure time point relevant confounders.","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/createWeights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates IPTW balancing weights — createWeights","text":"","code":"createWeights(   data,   exposure,   outcome,   formulas,   method = \"cbps\",   SL.library = \"SL.glm\",   criterion = NA,   home_dir = NULL,   read_in_from_file = FALSE,   verbose = TRUE,   save.out = TRUE,   ... )"},{"path":"https://istallworthy.github.io/devMSMs/reference/createWeights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates IPTW balancing weights — createWeights","text":"data data wide format : data frame, list imputed data frames, mids object exposure name exposure variable outcome name outcome variable \".timepoint\" suffix formulas list balancing formulas time point output createFormulas() method (optional) character string weightitMSM() balancing method abbreviation (default Covariate Balancing Propensity Score \"cbps\") SL.library required superLearner weighting method (\"super\"); see SuperLearner::listWrappers() options criterion (optional) criterion used select best weights (default \"p.mean\" minimizing avg Pearson correlation continuous exposures \"smd.mean\" binary exposures) (requird \"gbm\" method) home_dir path home directory (required 'save.' = TRUE) read_in_from_file (optional) TRUE FALSE indicator read weights previously run saved locally (default FALSE) verbose (optional) TRUE FALSE indicator user output (default TRUE) save.(optional) TRUE FALSE indicator save output intermediary output locally (default TRUE) ... inputs weightitMSM()","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/createWeights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates IPTW balancing weights — createWeights","text":"list IPTW balancing weights","code":""},{"path":[]},{"path":"https://istallworthy.github.io/devMSMs/reference/createWeights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates IPTW balancing weights — createWeights","text":"","code":"test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50)) test[, c(\"A.1\", \"A.2\", \"A.3\")] <- lapply(test[, c(\"A.1\", \"A.2\", \"A.3\")], as.numeric)  f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"short\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x559351fa5ca0> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x559351fa5ca0> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.2 + B.2 + C #> <environment: 0x559351fa5ca0> #>  w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 0.98 (SD = 0.37; range = 0.39-2).  #>                       f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\", \"A.1:B.1\"),                     ti_confounders = \"C\",                     type = \"short\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55934e3200f8> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + A.1:B.1 + B.1 + C #> <environment: 0x55934e3200f8> #>  #> USER ALERT: Please manually inspect the short balancing formula below that includes time-varying confounders at t-1 only: #> The short formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.2 + B.2 + C #> <environment: 0x55934e3200f8> #>  w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 0.98 (SD = 0.37; range = 0.4-2).  #>                       w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    method = \"cbps\",                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 0.98 (SD = 0.37; range = 0.4-2).  #>   w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    method = \"cbps\",                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 0.98 (SD = 0.37; range = 0.4-2).  #>   w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    method = \"gbm\",                    save.out = FALSE)                     #> For the gbm weighting method, the median weight value is 0.53 (SD = 0.25; range = 0.21-2).  #>   w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    method = \"bart\",                    save.out = FALSE) #> For the bart weighting method, the median weight value is 0.63 (SD = 0.32; range = 0.27-2).  #>   w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    method = \"super\",                    save.out = FALSE)    #> Loading required package: nnls #> Warning: All algorithms have zero weight #> Warning: All metalearner coefficients are zero, predictions will all be equal to 0 #> For the super weighting method, the median weight value is 1 (SD = 0.49; range = 0.32-3).  #>"},{"path":"https://istallworthy.github.io/devMSMs/reference/create_custom_comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates custom comparisons — create_custom_comparisons","title":"Creates custom comparisons — create_custom_comparisons","text":"Creates custom comparisons","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/create_custom_comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates custom comparisons — create_custom_comparisons","text":"","code":"create_custom_comparisons(preds, ref_vals, comp_vals, exposure)"},{"path":"https://istallworthy.github.io/devMSMs/reference/create_custom_comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates custom comparisons — create_custom_comparisons","text":"preds custom output marginaleffects::average_predictions() ref_vals reference values comp_vals comparison values exposure name exposure variable","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/create_custom_comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates custom comparisons — create_custom_comparisons","text":"custom comparisons","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/create_custom_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Create custom contrasts — create_custom_contrasts","title":"Create custom contrasts — create_custom_contrasts","text":"Create custom contrasts","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/create_custom_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create custom contrasts — create_custom_contrasts","text":"","code":"create_custom_contrasts(d, reference, comp_histories, exposure, preds)"},{"path":"https://istallworthy.github.io/devMSMs/reference/create_custom_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create custom contrasts — create_custom_contrasts","text":"d data frame high low values per exposure main effect reference reference sequence \"h\" /\"l\" (e.g., \"h-h-h\") comp_histories comparison sequence(s) \"h\" /\"l\" (e.g., \"h-h-h\") exposure name exposure variable preds custom output marginaleffects::average_predictions()","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/create_custom_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create custom contrasts — create_custom_contrasts","text":"contrasts","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/devMSMs-package.html","id":null,"dir":"Reference","previous_headings":"","what":"devMSMs: Tools for Conducting Marginal Structural Models with Developmental Data — devMSMs-package","title":"devMSMs: Tools for Conducting Marginal Structural Models with Developmental Data — devMSMs-package","text":"Functions preparing, assessing, implementing MSMS.","code":""},{"path":[]},{"path":"https://istallworthy.github.io/devMSMs/reference/devMSMs-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"devMSMs: Tools for Conducting Marginal Structural Models with Developmental Data — devMSMs-package","text":"Maintainer: Isabella Stallworthy istall@seas.upenn.edu Authors: Noah Greifer ngreifer@iq.harvard.edu [contributor] Meriah DeJoseph meriahd@stanford.edu Emily Padrutt padru004@umn.edu Daniel Berry dberry@umn.edu","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/eval_hist.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize distribution of sample across exposure histories — eval_hist","title":"Visualize distribution of sample across exposure histories — eval_hist","text":"Create customized, user-specified exposure histories tables displaying sample distribution across user inspection.","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/eval_hist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize distribution of sample across exposure histories — eval_hist","text":"","code":"eval_hist(   data,   exposure,   time_pts,   epochs = NULL,   hi_lo_cut = NULL,   ref = NULL,   comps = NULL )"},{"path":"https://istallworthy.github.io/devMSMs/reference/eval_hist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize distribution of sample across exposure histories — eval_hist","text":"data data wide format : data frame, list imputed data frames, mids object exposure name exposure variable time_pts list integers weights created/assessed correspond time points exposure measured epochs (optional) data frame exposure epoch labels values hi_lo_cut list two numbers indicating quantile values reflect high low values, respectively, continuous exposure ref (optional) list one strings \"-\"-separated \"l\" \"h\" values indicative reference exposure history compare comparison, required comparison supplied comps (optional) list one strings \"-\"-separated \"l\" \"h\" values indicative comparison history/histories compare reference, required reference supplied","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/eval_hist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize distribution of sample across exposure histories — eval_hist","text":"none","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/eval_hist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize distribution of sample across exposure histories — eval_hist","text":"","code":"test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50)) test[, c(\"A.1\", \"A.2\", \"A.3\")] <- lapply(test[, c(\"A.1\", \"A.2\", \"A.3\")], as.numeric)  h <- eval_hist(data = test,                exposure = \"A\",                time_pts = c(1, 2, 3)) #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 50 (100%) individuals that fall into 8 out of the 8 total user-defined exposure histories created from median split values for low and high levels of exposure A, respectively, across 1, 2, 3.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects 1, 2, 3 containing time points 1, 2, 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  9| #> |h-h-l   |  7| #> |h-l-h   |  3| #> |h-l-l   |  6| #> |l-h-h   |  5| #> |l-h-l   |  4| #> |l-l-h   |  8| #> |l-l-l   |  8| #>  h <- eval_hist(data = test,                exposure = \"A\",                time_pts = c(1, 2, 3),                epochs = data.frame(epochs = c(\"Infancy\", \"Toddlerhood\"),                                    values = I(list(c(1, 2), c(3))))) #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 50 (100%) individuals that fall into 4 out of the 4 total user-defined exposure histories created from median split values for low and high levels of exposure A, respectively, across Infancy, Toddlerhood.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects Infancy, Toddlerhood containing time points c(1, 2), 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h     | 13| #> |h-l     | 12| #> |l-h     | 12| #> |l-l     | 13| #>  h <- eval_hist(data = test,                exposure = \"A\",                time_pts = c(1, 2, 3),                hi_lo_cut = c(0.6, 0.3)) #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 17 (34%) individuals that fall into 8 out of the 8 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure A, respectively, across 1, 2, 3.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects 1, 2, 3 containing time points 1, 2, 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  4| #> |h-h-l   |  2| #> |h-l-h   |  2| #> |h-l-l   |  3| #> |l-h-h   |  1| #> |l-h-l   |  1| #> |l-l-h   |  3| #> |l-l-l   |  1| #>  h <- eval_hist(data = test,                exposure = \"A\",                time_pts = c(1, 2, 3),                hi_lo_cut = c(0.6, 0.3),                ref = \"l-l-l\",                comps = \"h-h-h\") #> Summary of Exposure Main Effects:  #>  #> USER ALERT: Out of the total of 50 individuals in the sample, below is the distribution of the 5 (10%) individuals that fall into 2 out of the 2 the total user-defined exposure histories created from 30th and 60th percentile values for low and high levels of exposure A, respectively, across 1, 2, 3.  #> USER ALERT: Please inspect the distribution of the sample across the following exposure histories and ensure there is sufficient spread to avoid extrapolation and low precision:  #>  #> Table: Summary of user-specified exposure A histories based on exposure main effects 1, 2, 3 containing time points 1, 2, 3: #>  #> |history |  n| #> |:-------|--:| #> |h-h-h   |  4| #> |l-l-l   |  1| #>"},{"path":"https://istallworthy.github.io/devMSMs/reference/fitModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit outcome model — fitModel","title":"Fit outcome model — fitModel","text":"Fits weighted marginal outcome model generalized linear model user's choosing, relating exposure main effects outcome using IPTW weights.","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/fitModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit outcome model — fitModel","text":"","code":"fitModel(   data,   weights,   exposure,   exposure_time_pts,   outcome,   model,   family = NULL,   link = NA,   int_order = NA,   covariates = NULL,   epochs = NULL,   home_dir = NULL,   verbose = TRUE,   save.out = TRUE )"},{"path":"https://istallworthy.github.io/devMSMs/reference/fitModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit outcome model — fitModel","text":"data data wide format : data frame, list imputed data frames, mids object weights list IPTW weights output createWeights() exposure name exposure variable exposure_time_pts list integers weights created/assessed correspond time points exposure measured outcome name outcome variable \".timepoint\" suffix model character indicating one following outcome models: \"m0\" (exposure main effects) \"m1\" (exposure main effects & covariates) \"m2\" (exposure main effects & interactions) \"m3\" (exposure main effects, interactions, & covariates) family (optional) family function specification svyglm model link (optional) character link function specification svyglm model int_order integer specification highest order exposure main effects interaction, required interaction models (\"m2\", \"m3\") covariates list characters reflecting variable names covariates, required covariate models (\"m1\", \"m3\") epochs (optional) data frame exposure epoch labels values home_dir path home directory (required 'save.' = TRUE) verbose (optional) TRUE FALSE indicator user output (default TRUE) save.(optional) TRUE FALSE indicator save output intermediary output locally (default TRUE)","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/fitModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit outcome model — fitModel","text":"list svyglm model output","code":""},{"path":[]},{"path":"https://istallworthy.github.io/devMSMs/reference/fitModel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit outcome model — fitModel","text":"","code":"f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"full\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55935c3ec270> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x55935c3ec270> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.1 + A.2 + B.1 + B.2 + C #> <environment: 0x55935c3ec270> #>   test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50)) test[, c(\"A.1\", \"A.2\", \"A.3\")] <- lapply(test[, c(\"A.1\", \"A.2\", \"A.3\")], as.numeric)  w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 1.05 (SD = 0.83; range = 0.19-4).  #>    m <- fitModel(data = test,               weights = w,               exposure = \"A\",               exposure_time_pts = c(1, 2, 3),               outcome = \"D.3\",               model = \"m0\",               save.out = FALSE) #> Please inspect the following likelihood ratio test to determine if the exposures collective predict significant variation in the outcome compared to a model without exposure terms. #>  #> We strongly suggest not conducting history comparisons if the likelihood ratio test is non-significant. #>  #> Working (Rao-Scott+F) LRT for A.1 A.2 A.3 #>  in svyglm(formula = as.formula(f), design = s, family = fam) #> Working 2logLR =  9.956656 p= 0.034132  #> (scale factors:  1.6 0.85 0.56 );  denominator df= 46 #>  #> The marginal model, m0, is summarized below: m <- fitModel(data = test,               weights = w,               exposure = \"A\",               exposure_time_pts = c(1, 2, 3),               outcome = \"D.3\",               model = \"m0\",               family = gaussian,               link = \"identity\",               epochs = data.frame(epochs = c(\"Infancy\", \"Toddlerhood\"),                                   values = I(list(c(1, 2), c(3)))),               save.out = FALSE) #> Please inspect the following likelihood ratio test to determine if the exposures collective predict significant variation in the outcome compared to a model without exposure terms. #>  #> We strongly suggest not conducting history comparisons if the likelihood ratio test is non-significant. #>  #> Working (Rao-Scott+F) LRT for A.Infancy A.Toddlerhood #>  in svyglm(formula = as.formula(f), design = s, family = fam) #> Working 2logLR =  12.6569 p= 0.0049356  #> (scale factors:  1.3 0.72 );  denominator df= 47 #>  #> The marginal model, m0, is summarized below: m <- fitModel(data = test,               weights = w,               exposure = \"A\",               exposure_time_pts = c(1, 2, 3),               outcome = \"D.3\",               model = \"m1\",               covariates = \"C\",               save.out = FALSE) #> Please inspect the following likelihood ratio test to determine if the exposures collective predict significant variation in the outcome compared to a model without exposure terms. #>  #> We strongly suggest not conducting history comparisons if the likelihood ratio test is non-significant. #>  #> Working (Rao-Scott+F) LRT for A.1 A.2 A.3 #>  in svyglm(formula = as.formula(f), design = s, family = fam) #> Working 2logLR =  9.933751 p= 0.034741  #> (scale factors:  1.6 0.84 0.56 );  denominator df= 45 #>  #> The marginal model, m1, is summarized below: m <- fitModel(data = test,               weights = w,               exposure = \"A\",               exposure_time_pts = c(1, 2, 3),               outcome = \"D.3\",               model = \"m2\",               int_order = 3,               save.out = FALSE) #> Please inspect the following likelihood ratio test to determine if the exposures collective predict significant variation in the outcome compared to a model without exposure terms. #>  #> We strongly suggest not conducting history comparisons if the likelihood ratio test is non-significant. #>  #> Working (Rao-Scott+F) LRT for A.1 A.2 A.3 A.1:A.2 A.1:A.3 A.2:A.3 A.1:A.2:A.3 #>  in svyglm(formula = as.formula(f), design = s, family = fam) #> Working 2logLR =  35.29923 p= 0.0010395  #> (scale factors:  2 1.6 1.1 0.8 0.68 0.58 0.38 );  denominator df= 42 #>  #> The marginal model, m2, is summarized below: m <- fitModel(data = test,               weights = w,               exposure = \"A\",               exposure_time_pts = c(1, 2, 3),               outcome = \"D.3\",               model = \"m3\",               int_order = 3,               covariates = \"C\",               save.out = FALSE) #> Please inspect the following likelihood ratio test to determine if the exposures collective predict significant variation in the outcome compared to a model without exposure terms. #>  #> We strongly suggest not conducting history comparisons if the likelihood ratio test is non-significant. #>  #> Working (Rao-Scott+F) LRT for A.1 A.2 A.3 A.1:A.2 A.1:A.3 A.2:A.3 A.1:A.2:A.3 #>  in svyglm(formula = as.formula(f), design = s, family = fam) #> Working 2logLR =  34.90057 p= 0.0010049  #> (scale factors:  1.9 1.5 1.1 0.85 0.74 0.58 0.39 );  denominator df= 41 #>  #> The marginal model, m3, is summarized below:"},{"path":"https://istallworthy.github.io/devMSMs/reference/getModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits outcome model — getModel","title":"Fits outcome model — getModel","text":"Fits outcome model","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/getModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits outcome model — getModel","text":"","code":"getModel(   d,   exposure,   exposure_time_pts,   outcome,   exp_epochs,   int_order,   model,   fam,   covariates,   verbose,   epochs = NULL )"},{"path":"https://istallworthy.github.io/devMSMs/reference/getModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits outcome model — getModel","text":"d wide data frame exposure name exposure variable exposure_time_pts list integers weights created/assessed correspond time points exposure measured outcome name outcome variable \".timepoint\" suffix exp_epochs list exposure epochs int_order integer specification highest order exposure main effects interaction interaction models model character indicating one following outcome models: \"m0\" (exposure main effects) \"m1\" (exposure main effects & covariates) \"m2\" (exposure main effects & interactions) \"m3\" (exposure main effects, interactions, & covariates) \"covs\" (covariate model) \"int\" (intercept model) fam function specification svyglm model covariates list characters reflecting variable names covariates covariate models verbose TRUE FALSE indicator user output (default TRUE) epochs data frame exposure epoch labels values","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/getModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits outcome model — getModel","text":"list fitted model(s)","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/getModel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fits outcome model — getModel","text":"","code":"test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50)) test[, c(\"A.1\", \"A.2\", \"A.3\")] <- lapply(test[, c(\"A.1\", \"A.2\", \"A.3\")], as.numeric)  f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"full\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55935289a170> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x55935289a170> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.1 + A.2 + B.1 + B.2 + C #> <environment: 0x55935289a170> #>   w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 0.96 (SD = 0.28; range = 0.6-2).  #>    epochs = data.frame(epochs = c(\"Infancy\", \"Toddlerhood\"),                     values = I(list(c(1, 2), c(3)))) e <- apply(expand.grid(\"A\", as.character(epochs[, 1])), 1,            paste, sep = \"\", collapse = \".\") test$weights <- w[[1]]$weights  g <- getModel(d = test,               exposure = \"A\",               exposure_time_pts = c(1, 2, 3),               outcome = \"D.3\",               epochs = epochs,               exp_epochs = e,               fam = gaussian,               model = \"m0\")"},{"path":"https://istallworthy.github.io/devMSMs/reference/get_comparison_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds custom comparison values — get_comparison_values","title":"Finds custom comparison values — get_comparison_values","text":"Finds custom comparison values","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/get_comparison_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds custom comparison values — get_comparison_values","text":"","code":"get_comparison_values(d, comp_histories)"},{"path":"https://istallworthy.github.io/devMSMs/reference/get_comparison_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds custom comparison values — get_comparison_values","text":"d data frame high low values per exposure main effect comp_histories comparison sequence(s) \"h\" /\"l\" (e.g., \"h-h-h\")","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/get_comparison_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finds custom comparison values — get_comparison_values","text":"comparison values","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/get_comparison_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Finds custom comparison values — get_comparison_values","text":"","code":"d <- data.frame(e = c(\"A.1\", \"A.2\", \"A.3\"),                l = c(0, 0, 0),                h = c(1, 1, 1)) r <- get_comparison_values(d = d,                           comp_histories = \"l-l-l\" ) r <- get_comparison_values(d = d,                           comp_histories = \"h-h-h\" ) r <- get_comparison_values(d = d,                          comp_histories = c(\"h-h-h\", \"h-h-l\"))"},{"path":"https://istallworthy.github.io/devMSMs/reference/get_reference_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds custom reference values — get_reference_values","title":"Finds custom reference values — get_reference_values","text":"Finds custom reference values","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/get_reference_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds custom reference values — get_reference_values","text":"","code":"get_reference_values(d, reference)"},{"path":"https://istallworthy.github.io/devMSMs/reference/get_reference_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds custom reference values — get_reference_values","text":"d data frame high low values per exposure main effect reference reference sequence \"h\" /\"l\" (e.g., \"h-h-h\")","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/get_reference_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finds custom reference values — get_reference_values","text":"reference values","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/get_reference_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Finds custom reference values — get_reference_values","text":"","code":"d <- data.frame(e = c(\"A.1\", \"A.2\", \"A.3\"),                l = c(0, 0, 0),                h = c(1, 1, 1)) r <- get_reference_values(d = d,                           reference = \"l-l-l\" ) r <- get_reference_values(d = d,                           reference = \"h-h-h\" )"},{"path":"https://istallworthy.github.io/devMSMs/reference/make_love_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create love plots showing balancing statistics — make_love_plot","title":"Create love plots showing balancing statistics — make_love_plot","text":"Create love plots showing balancing statistics","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/make_love_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create love plots showing balancing statistics — make_love_plot","text":"","code":"make_love_plot(   balance_stats,   exposure,   exposure_time_pt,   exposure_type,   k = 0,   form_name,   data_type,   balance_thresh,   weights_method,   imp_conf,   save.out = FALSE,   home_dir = NULL,   folder = NULL,   verbose = TRUE )"},{"path":"https://istallworthy.github.io/devMSMs/reference/make_love_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create love plots showing balancing statistics — make_love_plot","text":"balance_stats data frame balance statistics exposure name exposure variable exposure_time_pt exposure time point integer exposure_type character indicating binary continuous exposure type k imputation number form_name formula name data_type single imputed data type balance_thresh one two numbers 0 1 indicating single balancing threshold thresholds less important confounders, respectively weights_method method character string WeightItMSM() balancing method abbreviation imp_conf list variable names reflecting important confounders save.TRUE FALSE indicator save output intermediary output locally home_dir path home directory (required save.= TRUE) folder folder path saving verbose (optional) TRUE FALSE indicator user output (default TRUE)","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/make_love_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create love plots showing balancing statistics — make_love_plot","text":"none","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/make_love_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create love plots showing balancing statistics — make_love_plot","text":"","code":"f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"full\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55934b2c0858> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x55934b2c0858> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.1 + A.2 + B.1 + B.2 + C #> <environment: 0x55934b2c0858> #>   test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50)) test[, c(\"A.1\", \"A.2\", \"A.3\")] <- lapply(test[, c(\"A.1\", \"A.2\", \"A.3\")], as.numeric)  w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 0.99 (SD = 0.41; range = 0.35-2).  #>    b <- assessBalance(data = test,                    exposure = \"A\",                    exposure_time_pts = c(1, 2, 3),                    outcome = \"D.3\",                    type = \"weighted\",                    weights = w,                    formulas = f,                    save.out = FALSE) #> USER ALERT: The following statistics display covariate imbalance at each exposure time point following IPTW weighting, using full formulas. #>     #> No covariates remain imbalanced using cbps and full formulas.  #>  #>  #> USER ALERT: For exposure A using the full formulas and cbps : #> The median absolute value relation between exposure and confounder is 0.04 (range = -0.07 -0.08).  #> There are no imbalanced covariates.  #> There are no imbalanced covariates.  make_love_plot(balance_stats = b,                exposure = \"A\",                exposure_time_pt = 1,                exposure_type = \"continuous\",                form_name = \"form_name\",                data_type = \"single\",                balance_thresh = 0.1,                imp_conf = NULL,                weights_method = w[[1]]$method,                save.out = FALSE,                folder = \"prebalance/\")   make_love_plot(balance_stats = b,                exposure = \"A\",                exposure_time_pt = 2,                exposure_type = \"continuous\",                form_name = \"form_name\",                data_type = \"single\",                balance_thresh = c(0.05, 0.1),                imp_conf = \"A.2\",                weights_method = w[[1]]$method,                save.out = FALSE,                folder = \"weighted/\")"},{"path":"https://istallworthy.github.io/devMSMs/reference/perform_multiple_comparison_correction.html","id":null,"dir":"Reference","previous_headings":"","what":"Conduct multiple comparison correction — perform_multiple_comparison_correction","title":"Conduct multiple comparison correction — perform_multiple_comparison_correction","text":"Conduct multiple comparison correction","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/perform_multiple_comparison_correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conduct multiple comparison correction — perform_multiple_comparison_correction","text":"","code":"perform_multiple_comparison_correction(   comps,   reference,   comp_histories,   method,   verbose = TRUE )"},{"path":"https://istallworthy.github.io/devMSMs/reference/perform_multiple_comparison_correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conduct multiple comparison correction — perform_multiple_comparison_correction","text":"comps table reference reference sequence \"h\" /\"l\" (e.g., \"h-h-h\") comp_histories comparison sequence(s) \"h\" /\"l\" (e.g., \"h-h-h\") method character abbreviation multiple comparison correction method verbose (optional) TRUE FALSE indicator user output (default TRUE)","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/perform_multiple_comparison_correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conduct multiple comparison correction — perform_multiple_comparison_correction","text":"comparison table corrected p-values","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/trimWeights.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim IPTW balancing weights — trimWeights","title":"Trim IPTW balancing weights — trimWeights","text":"Trims IPTW balancing weights heavy right tails populating weight values given quantile weight value quantile.","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/trimWeights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim IPTW balancing weights — trimWeights","text":"","code":"trimWeights(   exposure,   outcome,   weights,   quantile = NA,   home_dir = NULL,   verbose = TRUE,   save.out = TRUE )"},{"path":"https://istallworthy.github.io/devMSMs/reference/trimWeights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim IPTW balancing weights — trimWeights","text":"exposure name exposure variable outcome name outcome variable \".timepoint\" suffix weights list IPTW weights output createWeights() quantile (optional) numeric value 0 1 quantile value trim weights (default 0.95) home_dir path home directory (required save.= TRUE) verbose (optional) TRUE FALSE indicator user output (default TRUE) save.(optional) TRUE FALSE indicator save output intermediary output locally (default TRUE)","code":""},{"path":"https://istallworthy.github.io/devMSMs/reference/trimWeights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trim IPTW balancing weights — trimWeights","text":"list model output trimmed weights","code":""},{"path":[]},{"path":"https://istallworthy.github.io/devMSMs/reference/trimWeights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trim IPTW balancing weights — trimWeights","text":"","code":"f <- createFormulas(exposure = \"A\",                     exposure_time_pts = c(1, 2, 3),                     outcome = \"D.3\",                     tv_confounders = c(\"A.1\", \"A.2\", \"A.3\", \"B.1\", \"B.2\", \"B.3\"),                     ti_confounders = \"C\",                     type = \"full\",                     save.out = FALSE) #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 1 is:  #> A.1 ~ C #> <environment: 0x55935ba68090> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 2 is:  #> A.2 ~ A.1 + B.1 + C #> <environment: 0x55935ba68090> #>  #> USER ALERT: Please manually inspect the full balancing formula below: #> The full formula for A - D.3 at A time point 3 is:  #> A.3 ~ A.1 + A.2 + B.1 + B.2 + C #> <environment: 0x55935ba68090> #>   test <- data.frame(ID = 1:50,                    A.1 = rnorm(n = 50),                    A.2 = rnorm(n = 50),                    A.3 = rnorm(n = 50),                    B.1 = rnorm(n = 50),                    B.2 = rnorm(n = 50),                    B.3 = rnorm(n = 50),                    C = rnorm(n = 50),                    D.3 = rnorm(n = 50))  w <- createWeights(data = test,                    exposure = \"A\",                    outcome = \"D.3\",                    formulas = f,                    save.out = FALSE) #> For the cbps weighting method, the median weight value is 0.9 (SD = 0.76; range = 0.17-4).  #>    t <- trimWeights(exposure = \"A\",                  outcome = \"D.3\",                  weights = w,                  save.out = FALSE) #> Trimming weights to 95%. #>  #> For the A-D.3 relation, following trimming at the 0.95 quantile, the median weight value is 0.9 (SD= 0.66; range= 0.17-3).  #>   t <- trimWeights(exposure = \"A\",                  outcome = \"D.3\",                  weights = w,                  quantile = 0.75,                  save.out = FALSE) #> Trimming weights to 75%. #>  #> For the A-D.3 relation, following trimming at the 0.75 quantile, the median weight value is 0.9 (SD= 0.41; range= 0.17-1).  #>"}]
